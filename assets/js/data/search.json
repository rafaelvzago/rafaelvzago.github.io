[ { "title": "OpenShift Service Mesh 3.0", "url": "/posts/openshift-service-mesh-3/", "categories": "OpenShift, Service Mesh, Istio", "tags": "openshift, service-mesh, Istio, kiali, ambient-mode, devops, security, observability, redhat, migration", "date": "2025-07-07 00:00:00 -0300", "content": "Overview O OpenShift Service Mesh 3 (OSSM3) marca uma nova era na gest√£o de service meshes no ecossistema Red Hat, trazendo mudan√ßas significativas e recursos avan√ßados para ambientes corporativos. A principal novidade √© a ado√ß√£o do Istio como n√∫cleo da solu√ß√£o, substituindo o Maistra e alinhando o OSSM3 com as tend√™ncias globais de service mesh. Entre os destaques, o OSSM3 oferece integra√ß√£o aprimorada com virtualiza√ß√£o, suporte robusto a upgrades (tanto in-place quanto revisados), e uma experi√™ncia de gerenciamento mais rica com a inclus√£o do Kiali Console como operador padr√£o e um console dedicado para administra√ß√£o do mesh. A solu√ß√£o tamb√©m amplia o suporte a ambientes multi-cluster, promovendo alta disponibilidade e resili√™ncia. No √¢mbito do Istio, o controle passa a ser realizado em n√≠vel de cluster, proporcionando visibilidade global. Mudan√ßas importantes incluem a remo√ß√£o do gerenciamento de gateways pelo operador (agora feito via inje√ß√£o por rota ou servi√ßo), a descontinua√ß√£o do Istio Operator Resource (IOR) e o fim do suporte √† federa√ß√£o de meshes, exigindo contato direto com a Red Hat para necessidades espec√≠ficas. Por fim, o OSSM3 traz o modo Istio Ambient Mode, com destaque para Zero Trust Tunnels (ztunnel), Waypoints (Envoy) para recursos avan√ßados de camada 7 e a opera√ß√£o sidecarless, que reduz o consumo de recursos e simplifica a arquitetura. Essas inova√ß√µes posicionam o OSSM3 como uma solu√ß√£o moderna, escal√°vel e alinhada √†s demandas de seguran√ßa, observabilidade e flexibilidade das organiza√ß√µes que utilizam o OpenShift. Compara√ß√£o entre OpenShift Service Mesh 2 e 3 OpenShift Service Mesh 2 OpenShift Service Mesh 3 Istioctl n√£o √© suportado Istioctl suportado - utilit√°rios de diagn√≥stico Gateways e Rotas criados automaticamente Gateways e rotas criados pelos usu√°rios Componentes de observabilidade gerenciados pelo operador do service mesh Componentes de observabilidade gerenciados independentemente Pol√≠ticas de Rede do Kubernetes isolam uma service mesh por padr√£o Pol√≠ticas de rede do Kubernetes n√£o s√£o criadas, podem ser definidas pelos usu√°rios M√∫ltiplos planos de controle por padr√£o Cluster-wide (abrangendo todo o cluster) por padr√£o Federa√ß√£o para m√∫ltiplos clusters Topologias multi-cluster do Istio + federa√ß√£o (em breve) Funcionalidades e Benef√≠cios Foco em Seguran√ßa Aproveite seguran√ßa abrangente no networking de aplica√ß√µes com criptografia mTLS transparente e pol√≠ticas granulares, facilitando a implementa√ß√£o de redes zero trust. Gerenciamento de Tr√°fego Controle o fluxo de tr√°fego e chamadas de API entre servi√ßos, tornando as comunica√ß√µes mais confi√°veis e a rede mais resiliente. Topologias Multicluster Implemente um √∫nico service mesh em m√∫ltiplos clusters OpenShift, garantindo alta disponibilidade entre clusters, zonas e regi√µes, com gest√£o unificada. Telemetria Compreenda as depend√™ncias entre servi√ßos e o fluxo de tr√°fego via OpenShift Console, permitindo r√°pida identifica√ß√£o de problemas. Aplica√ß√£o de Pol√≠ticas Implemente pol√≠ticas organizacionais nas intera√ß√µes entre servi√ßos, garantindo o cumprimento de regras de acesso e distribui√ß√£o justa de recursos. Observabilidade Visualize, valide e solucione problemas do service mesh com o OpenShift Service Mesh Console Plugin. Monitore a sa√∫de dos componentes e inspecione traces e logs em uma interface unificada. Principais Mudan√ßas e Recursos Istio substitui o Maistra A principal mudan√ßa do OSSM 3 em rela√ß√£o √† vers√£o 2.x √© a ado√ß√£o do Istio upstream como n√∫cleo da solu√ß√£o, substituindo o Maistra (que era uma distribui√ß√£o customizada do Istio). Essa transi√ß√£o alinha o OpenShift Service Mesh com o Istio padr√£o da comunidade, trazendo maior compatibilidade com o ecossistema Istio e acesso mais r√°pido a novos recursos e corre√ß√µes. Com o Istio upstream, o OSSM3 oferece uma base tecnol√≥gica mais alinhada com o projeto original, maior flexibilidade e suporte ampliado para integra√ß√µes, al√©m de simplificar opera√ß√µes e atualiza√ß√µes futuras. Estrat√©gias de Upgrade O OSSM3 oferece duas estrat√©gias de atualiza√ß√£o do control plane do Istio, configuradas pelo campo upgradeStrategy: InPlace: Atualiza o control plane existente no cluster. Ap√≥s a atualiza√ß√£o, √© necess√°rio reiniciar os workloads para que passem a utilizar a nova vers√£o do Istio. Essa abordagem √© mais simples, por√©m envolve uma breve indisponibilidade durante o processo de rein√≠cio dos pods. RevisionBased (Canary): Cria um novo control plane Istio ao lado do existente, permitindo uma migra√ß√£o gradual dos workloads da vers√£o antiga para a nova. Essa estrat√©gia reduz riscos, pois possibilita validar a nova vers√£o com parte dos workloads antes de migrar todo o ambiente, garantindo maior controle e seguran√ßa durante o upgrade. Exemplo de CR Istio para OSSM3 apiVersion: sailoperator.io/v1 kind: Istio metadata: name: default spec: version: v1.24.3 namespace: Istio-system updateStrategy: type: InPlace values: pilot: resources: requests: cpu: 100m memory: 1024Mi Observabilidade com Kiali Console O OSSM3 oferece suporte ao Kiali Console atrav√©s de operador separado para observabilidade. √â importante notar que o Kiali n√£o √© uma novidade exclusiva da v3, pois tamb√©m era suportado na v2. De fato, na v2 o Kiali era instalado por padr√£o, enquanto na v3 precisa ser instalado separadamente. Essa mudan√ßa reflete a ideia de que o OSSM 3 oferece maior flexibilidade e pode ser integrado com uma ampla gama de solu√ß√µes; o operador sail gerencia apenas o Istio. O Kiali proporciona: Visualiza√ß√£o da Topologia: Interface gr√°fica intuitiva para mapear depend√™ncias entre servi√ßos e compreender o fluxo de tr√°fego em tempo real. M√©tricas Integradas: Acesso direto √†s m√©tricas do Istio com dashboards pr√©-configurados para monitoramento de performance e lat√™ncia. Gest√£o de Configura√ß√µes: Interface centralizada para validar e gerenciar pol√≠ticas de tr√°fego, seguran√ßa e configura√ß√µes do Istio. Troubleshooting Avan√ßado: Ferramentas para identificar rapidamente problemas de conectividade, erros de configura√ß√£o e gargalos de performance. Console Dedicado: Um console espec√≠fico para administra√ß√£o do mesh, separado do OpenShift Console principal, permitindo foco exclusivo na gest√£o do service mesh. Com a instala√ß√£o separada do Kiali Operator, os usu√°rios t√™m maior controle sobre as funcionalidades de observabilidade, podendo configurar exatamente o que necessitam para seu ambiente espec√≠fico. Request Authentication usando JWT O OSSM3 oferece suporte robusto para autentica√ß√£o de requests baseada em JSON Web Tokens (JWT), permitindo valida√ß√£o segura de identidades em comunica√ß√µes entre servi√ßos. Esta funcionalidade √© essencial para implementar arquiteturas zero trust e garantir que apenas requests autenticados acessem recursos protegidos. Recursos Principais M√∫ltiplos Issuers: Suporte a diferentes provedores de JWT simultaneamente Valida√ß√£o JWKS: Recupera√ß√£o autom√°tica de chaves p√∫blicas via JWKS URI Claims Customizados: Acesso a claims espec√≠ficos para decis√µes de autoriza√ß√£o Audience Validation: Verifica√ß√£o de audi√™ncia para garantir que tokens sejam destinados ao servi√ßo correto Token Forwarding: Propaga√ß√£o segura de tokens JWT atrav√©s do service mesh A implementa√ß√£o JWT no OSSM3 garante autentica√ß√£o forte e flex√≠vel, integrando-se nativamente com provedores de identidade externos e oferecendo controle detalhado sobre polÔøΩÔøΩticas de acesso. Operators OSSM3 Operator O operador do OpenShift Service Mesh 3 foi redesenhado com um escopo mais focado e especializado. Diferentemente das vers√µes anteriores, o operador OSSM3 instala e gerencia exclusivamente o Istio, simplificando sua responsabilidade e melhorando a efici√™ncia operacional. Kiali Operator para Observabilidade Para funcionalidades de observabilidade, o OSSM3 utiliza o Kiali Operator como componente separado e dedicado. Esta separa√ß√£o de responsabilidades oferece: Especializa√ß√£o: Cada operador foca em sua √°rea espec√≠fica de expertise Flexibilidade: Permite atualiza√ß√µes independentes do Kiali sem afetar o n√∫cleo do Istio Modularidade: Facilita a manuten√ß√£o e troubleshooting de componentes espec√≠ficos Escalabilidade: Possibilita configura√ß√µes personalizadas de observabilidade conforme necessidades do ambiente Esta arquitetura modular resulta em uma solu√ß√£o mais robusta, onde o operador OSSM3 mant√©m foco total no gerenciamento do Istio, enquanto o Kiali Operator oferece toda a stack de observabilidade necess√°ria para monitoramento e an√°lise do service mesh. Gateways no OpenShift Service Mesh 3 Um gateway √© usado para gerenciar o tr√°fego que entra e sai do service mesh. Ele consiste em um proxy Envoy independente que √© gerenciado pelo plano de controle do service mesh. Pode ser configurado usando um recurso Istio Gateway como: Um gateway de entrada (ingress) - um ponto de entrada para o mesh. Um gateway de sa√≠da (egress) - um ponto de sa√≠da do mesh. A partir do Service Mesh 2.6, tamb√©m foi poss√≠vel configurar gateways usando a API de Gateway do Kubernetes. Embora tecnicamente verdadeiro, em retrospectiva, a implementa√ß√£o era bastante imatura. Recomendamos fortemente que usu√°rios interessados na API Gateway fa√ßam uso do OSSM v3 no OCP 4.19 ou superior, onde os CRDs s√£o adequadamente gerenciados e suportados na plataforma OpenShift subjacente. No OpenShift Service Mesh 3, os gateways n√£o s√£o mais gerenciados pelo operador. Isso proporciona maior simplicidade, flexibilidade e incentiva a pr√°tica recomendada de gateways gerenciados juntamente com as aplica√ß√µes. Os gateways podem ser criados com: Inje√ß√£o de Gateway usando um Deployment do Kubernetes e expostos via: Um recurso Route do OpenShift. Um Service do Kubernetes do tipo LoadBalancer. Recursos da API de Gateway do Kubernetes. Escalabilidade &amp; Multi-Tenancy no OpenShift Service Mesh Antes de implementer o service mesh em m√∫ltiplos clusters, √© importante considerar a motiva√ß√£o. As motiva√ß√µes podem incluir: Alta disponibilidade de servi√ßos entre clusters, regi√µes, zonas, etc. Gerenciar pol√≠ticas do Istio em m√∫ltiplos clusters a partir de um √∫nico plano de controle. Escalar pol√≠ticas do service mesh em uma grande organiza√ß√£o composta por m√∫ltiplas equipes. Gerenciar o compartilhamento de servi√ßos entre clusters sem exp√¥-los publicamente. Modelos de Multi-Cluster Modelo Descri√ß√£o Caracter√≠sticas Multi-Primary Cada cluster possui um plano de controle Istio que gerencia tanto os servi√ßos locais quanto os remotos. Maior disponibilidade.Mais configura√ß√£o entre clusters e sincroniza√ß√£o de estado. Primary-Remote Um √∫nico plano de controle gerencia toda a configura√ß√£o, incluindo aquelas em clusters remotos. Sem redund√¢ncia.Menos configura√ß√£o entre clusters e sincroniza√ß√£o de estado necess√°ria. External Control Plane Para maior isolamento, o plano de controle pode ser implantado em um cluster completamente independente dos clusters do plano de dados. Isola os componentes de gerenciamento dos componentes do plano de dados.Suporta um modelo de cluster hub. Migrando para o Red Hat OpenShift Service Mesh 3 Existem v√°rias coisas que os clientes podem fazer HOJE para se prepararem para a atualiza√ß√£o para o Service Mesh 3: Atualizar para a vers√£o mais recente dispon√≠vel do OpenShift Service Mesh 2.6 Mover para a Inje√ß√£o de Gateway (Gateway Injection) para criar e gerenciar todos os Gateways Desabilitar o IoR (Istio on Routes) e gerenciar explicitamente os Gateways com recursos de Rotas (Routes) Usar o monitoramento de projetos definido pelo usu√°rio do OpenShift para m√©tricas Migrar para OpenTelemetry e Tempo para rastreamento distribu√≠do (distributed tracing) Configurar um recurso Kiali externo para gerenciar o Kiali Desabilitar o gerenciamento de pol√≠ticas de rede (network policy) do OpenShift Service Mesh 2.6 Procedimentos detalhados para todos os itens acima fazem parte do guia de migra√ß√£o. Migrando cargas de trabalho (workloads) para o OpenShift Service Mesh 3 Os procedimentos de migra√ß√£o documentados visam mover as cargas de trabalho para o Red Hat OpenShift Service Mesh 3, mantendo a conectividade da aplica√ß√£o. Os planos de controle do Service Mesh 2 e 3 s√£o implantados em paralelo no mesmo namespace (por exemplo, Istio-system). Os r√≥tulos (labels) das cargas de trabalho s√£o ent√£o configurados para migrar para o plano de controle do Service Mesh 3 durante o pr√≥ximo rollout. Istio Ambient Mode (Developer Preview) ‚ÄúSidecar-less‚Äù service mesh Uma das maiores desvantagens dos service meshes tradicionais tem sido a exig√™ncia de que cada pod de aplica√ß√£o tenha um proxy sidecar. Benef√≠cios e Desafios dos proxies sidecar Envoy Benef√≠cios Desafios Altamente customiz√°vel atrav√©s das APIs do Istio, permitindo uma service mesh rica em funcionalidades. Com a flexibilidade do Envoy, vem a complexidade! Um modelo de implanta√ß√£o simples - um pod por proxy. Requer a modifica√ß√£o dos pods da aplica√ß√£o para injetar os proxies. Uso de recursos eficiente quando gerenciado cuidadosamente. Um proxy por pod significa muitos proxies! Adi√ß√£o de lat√™ncia toler√°vel para a maioria das aplica√ß√µes voltadas para o usu√°rio. Sem um gerenciamento cuidadoso, o uso de recursos pode sair do controle! ¬† Impactos de performance para aplica√ß√µes de baixa lat√™ncia e alta vaz√£o podem ser inaceit√°veis. ¬† Pode ser ‚Äúpesado demais‚Äù se apenas algumas funcionalidades do mesh forem necess√°rias. Componentes do modo Ambient do Istio Istio-cni: √â um daemonset que configura o redirecionamento do tr√°fego do pod com o ztunnel. Ztunnel: √â um proxy por n√≥ (per node) para lidar eficientemente com funcionalidades da Camada 4 (L4). Um proxy leve, de alta performance, ‚Äúescrito em Rust‚Äù, e espec√≠fico para o Istio. Habilita funcionalidades do mesh como criptografia mTLS, pol√≠ticas de L4 e telemetria. (Opcional) Waypoint: √â um proxy escal√°vel de forma independente para funcionalidades da Camada 7 (L7). Habilita funcionalidades como pol√≠ticas HTTP, telemetria e gerenciamento de tr√°fego. Um proxy Envoy, similar a um gateway. Implantado por namespace por padr√£o (modificado com labels). Escopo dos Proxies ZTunnel vs. Waypoint Os ZTunnels operam em um escopo por n√≥ (per node). Isso significa que uma √∫nica inst√¢ncia do proxy ZTunnel √© executada como um DaemonSet em cada n√≥ de trabalho do cluster. Esse design √© altamente eficiente, pois uma √∫nica inst√¢ncia leve pode gerenciar todo o tr√°fego da Camada 4 (L4) ‚Äî como criptografia mTLS, autentica√ß√£o e pol√≠ticas de autoriza√ß√£o b√°sicas ‚Äî para todos os pods agendados naquele n√≥ espec√≠fico. Ao centralizar a funcionalidade L4 no n√≠vel do n√≥, o modelo Ambient Mode reduz significativamente o consumo de recursos e a complexidade de gerenciamento em compara√ß√£o com o modelo tradicional de um proxy sidecar para cada pod. Em contraste, os proxies Waypoint s√£o, por padr√£o, implantados em um escopo por namespace ou, mais especificamente, por conta de servi√ßo (service account). Quando funcionalidades avan√ßadas da Camada 7 (L7), como balanceamento de carga, gerenciamento de tr√°fego complexo e pol√≠ticas baseadas em HTTP, s√£o necess√°rias para um servi√ßo, um Waypoint proxy dedicado √© implantado para aquele namespace. Esse proxy Envoy, que √© mais robusto, intercepta o tr√°fego relevante e aplica as pol√≠ticas L7 necess√°rias. Este modelo permite que as equipes ativem seletivamente as funcionalidades L7 apenas para as cargas de trabalho que precisam delas, isolando o consumo de recursos e a complexidade de configura√ß√£o ao namespace correspondente, em vez de sobrecarregar todo o mesh. T√∫neis ‚ÄúZero Trust‚Äú (Ztunnels) Os proxies ‚Äúztunnel‚Äù rodam como um DaemonSet no n√≠vel do n√≥. Para pods que est√£o ‚Äúno mesh‚Äù (in mesh), todo o tr√°fego (mesmo o tr√°fego local no n√≥) atravessa o proxy ztunnel local para que ele possa aplicar pol√≠ticas e reportar telemetria. O diagrama comum do modo Ambient √© uma simplifica√ß√£o do funcionamento do Ztunnel: A intercepta√ß√£o de tr√°fego ocorre dentro do namespace de rede do pod (e n√£o no host). Isso garante que o tr√°fego n√£o criptografado nunca saia do isolamento de rede do pod - exatamente como um sidecar! At√© mesmo o tr√°fego local do n√≥ ser√° processado pelo ZTunnel. Conclusao O OpenShift Service Mesh 3 representa um avan√ßo significativo na forma como as organiza√ß√µes gerenciam, protegem e observam suas aplica√ß√µes baseadas em microservi√ßos no OpenShift. A transi√ß√£o para o Istio como n√∫cleo n√£o apenas alinha a solu√ß√£o com o padr√£o de mercado, mas tamb√©m oferece uma base mais s√≥lida, flex√≠vel e preparada para o futuro. As melhorias na observabilidade com o Kiali, as estrat√©gias de upgrade flex√≠veis e o gerenciamento simplificado de operadores e gateways capacitam as equipes de DevOps a operar com mais agilidade e seguran√ßa. A introdu√ß√£o do Istio Ambient Mode, mesmo em Developer Preview, sinaliza um futuro promissor com uma arquitetura ‚Äúsidecar-less‚Äù que promete reduzir a sobrecarga de recursos e simplificar ainda mais a malha de servi√ßos. Em suma, o OSSM3 √© uma atualiza√ß√£o crucial que fortalece o ecossistema do OpenShift, fornecendo as ferramentas necess√°rias para construir e operar aplica√ß√µes resilientes, seguras e escal√°veis, ao mesmo tempo em que estabelece um caminho claro para a inova√ß√£o cont√≠nua no gerenciamento de service mesh. Referencias OpenShift Service Mesh Istio Kiali Argo Rollouts Envoy Proxy Kubernetes OpenTelemetry Grafana Tempo JSON Web Tokens (JWT) Rust " }, { "title": "Dominando Pipelines de Alta Performance: Do ClickOps ao GitOps com Jenkins e CasC", "url": "/posts/dominando-pipelines-de-alta-performance/", "categories": "DevOps, CI/CD, Jenkins, MLOps", "tags": "jenkins, cicd, devops, casc, gitops, automacao, mlops", "date": "2025-06-13 00:00:00 -0300", "content": "Supere as limita√ß√µes do Jenkins tradicional ('ClickOps') e adote Configuration as Code (CasC) para criar pipelines de CI/CD e MLOps que s√£o version√°veis, audit√°veis e escal√°veis." }, { "title": "Controlando e protegendo modelos de IA com seguran√ßa usando Deepseek, Skupper e InstructLab - Terceiro e √öltimo Ato", "url": "/posts/controlando-progetendo-ia-deepseek-skupper-istio-terceiro-ultimo-ato/", "categories": "AI, Kubernetes, instructlab", "tags": "ai, skupper, instructlab, kubernetes, nginx, ingress, loadbalancer", "date": "2025-05-05 00:00:00 -0300", "content": "Neste artigo, vamos implementar e conectar o modelo de IA DeepSeek com o InstructLab usando Skupper para conectar de forma segura um modelo de IA privado com uma interface p√∫blica." }, { "title": "Controlando e protegendo modelos de IA com seguran√ßa usando Deepseek, Skupper e InstructLab - Segundo Ato", "url": "/posts/controlando-progetendo-ia-deepseek-skupper-istio-segundo-ato/", "categories": "AI, Kubernetes, instructlab", "tags": "ai, deepseek, skupper, instructlab, kubernetes, podman, llama-cpp, gguf", "date": "2025-05-04 00:00:00 -0300", "content": "Neste artigo, vamos implementar passo a passo o chatbot com o Instructlab, al√©m de expor o servi√ßo de forma segura usando Skupper" }, { "title": "Controlando e protegendo modelos de IA com seguran√ßa usando Deepseek, Skupper e InstructLab - Primeiro Ato", "url": "/posts/controlando-progetendo-ia-deepseek-skupper-istio-primeiro-ato/", "categories": "AI, Internet", "tags": "ai, deepseek, skupper, instructlab, kubernetes, security, hybrid-cloud, architecture, llm", "date": "2025-05-02 00:00:00 -0300", "content": "Descubra como implantar e operar modelos de IA com seguran√ßa em ambientes h√≠bridos, usando Skupper e InstructLab para proteger dados sens√≠veis." }, { "title": "Real-Time Linux: Uma Jornada de Baixa Lat√™ncia", "url": "/posts/RTL-Linux/", "categories": "linux, rtos, tecnologia", "tags": "linux, real-time, rtos, kernel, preempt-rt, low-latency, sistemas-embarcados, redhat", "date": "2024-12-20 00:00:00 -0300", "content": "Introdu√ß√£o Real-Time Linux (RTL) √© uma extens√£o do kernel do Linux que transforma o sistema operacional em um ambiente de tempo real. Isso significa que, al√©m de suas funcionalidades tradicionais, ele agora √© capaz de lidar com tarefas que exigem alta previsibilidade e baixa lat√™ncia, como sistemas de automa√ß√£o industrial, dispositivos m√©dicos e at√© sistemas de entretenimento. No final de 2024, o Linux Kernel passou a incorporar totalmente o Real-Time Linux (RTL), marcando um momento hist√≥rico na evolu√ß√£o do sistema. Mas como chegamos at√© aqui? A Jornada do RTL A ideia de adicionar capacidades de tempo real ao Linux remonta ao final dos anos 90, quando surgiram os primeiros patches para otimizar o desempenho e reduzir a lat√™ncia do kernel. Esses patches evolu√≠ram para projetos mais robustos, como o PREEMPT-RT. O PREEMPT-RT permitiu: Preemp√ß√£o total: Tornar poss√≠vel a interrup√ß√£o de quase todas as rotinas do kernel. Redu√ß√£o de lat√™ncias: Melhorar a previsibilidade em execu√ß√µes cr√≠ticas. Depois de anos de desenvolvimento comunit√°rio e apoio de empresas como Red Hat, Intel e IBM, o PREEMPT-RT finalmente foi fundido no kernel principal, consolidando o Linux como uma plataforma RTOS (Sistema Operacional de Tempo Real). Compara√ß√£o: Workload RTL vs. Workload Normal Para cargas de trabalho t√≠picas com requisitos de lat√™ncia do kernel na faixa de milissegundos (ms), o kernel padr√£o do Red Hat Enterprise Linux 7 √© suficiente. No entanto, se sua carga de trabalho exige requisitos rigorosos de determinismo de baixa lat√™ncia para recursos centrais do kernel, como manipula√ß√£o de interrup√ß√µes e escalonamento de processos na faixa de microssegundos (Œºs), o kernel de tempo real √© a escolha ideal. Refer√™ncia Modelos de Preemp√ß√£o no Linux Os modelos de preemp√ß√£o do Linux determinam como o kernel gerencia interrup√ß√µes e tarefas. Esses modelos s√£o definidos no momento da compila√ß√£o do kernel, sendo o ‚ÄúKernel Totalmente Preempt√≠vel‚Äù essencial para obter o comportamento em tempo real. Abaixo est√° uma descri√ß√£o dos principais modelos: Sem Preemp√ß√£o For√ßada (Servidor): Modelo tradicional focado em maximizar a taxa de transfer√™ncia. Os pontos de preemp√ß√£o ocorrem apenas em retornos de chamadas de sistema e interrup√ß√µes. Preemp√ß√£o Volunt√°ria (Desktop): Reduz a lat√™ncia do kernel adicionando pontos de preemp√ß√£o expl√≠citos no c√≥digo, em troca de uma leve queda na taxa de transfer√™ncia. Kernel Preempt√≠vel (Desktop de Baixa Lat√™ncia): Faz com que todo o c√≥digo do kernel, exceto se√ß√µes cr√≠ticas, seja preempt√≠vel, com pontos de preemp√ß√£o impl√≠citos ap√≥s cada desativa√ß√£o de preemp√ß√£o. Kernel Preempt√≠vel (RT B√°sico): Similar ao modelo ‚ÄúDesktop de Baixa Lat√™ncia‚Äù, mas com manipuladores de interrup√ß√µes em threads. Esse modelo √© usado para testes e depura√ß√£o. Kernel Totalmente Preempt√≠vel (RT): Todo o c√≥digo do kernel √© preempt√≠vel, exceto em se√ß√µes cr√≠ticas selecionadas. Inclui manipuladores de interrup√ß√µes em threads e mecanismos como spinlocks dorm√™ntes e rt_mutex para minimizar se√ß√µes n√£o preempt√≠veis, garantindo comportamento em tempo real. Onde o Real-Time Linux pode ser Aplicado? As aplica√ß√µes s√£o diversas, mas geralmente se concentram em cen√°rios que exigem desempenho cr√≠tico: Automotivo: Sistemas de freios e controle de motores. Industrial: Rob√≥tica e automa√ß√£o. Telecomunica√ß√µes: Redes 5G que requerem baixa lat√™ncia para processamento de pacotes. Entretenimento: Mixagem de √°udio em tempo real. Sa√∫de: Equipamentos m√©dicos sens√≠veis ao tempo. Exemplo Pr√°tico: Testando o Kernel PREEMPT-RT Entendendo o PREEMPT-RT O PREEMPT-RT √© um conjunto de patches aplicados ao kernel Linux que permite transformar o sistema operacional em um ambiente de tempo real. Este modelo de preemp√ß√£o reduz drasticamente a lat√™ncia ao substituir os mecanismos de sincroniza√ß√£o convencionais por variantes que suportam preemp√ß√£o. Ele tamb√©m implementa mecanismos para dividir se√ß√µes cr√≠ticas longas e for√ßar o encadeamento de manipuladores de interrup√ß√£o. Recursos principais do PREEMPT-RT: Threading de Interrup√ß√µes: Todas as interrup√ß√µes s√£o executadas como threads agend√°veis, permitindo que o sistema priorize e gerencie tarefas em tempo real. Spinlocks Preempt√≠veis: Substitui spinlocks padr√£o por variantes que permitem preemp√ß√£o, minimizando atrasos durante o bloqueio de recursos compartilhados. Heran√ßa de Prioridade: Implementa√ß√£o de mutexes que evitam problemas de invers√£o de prioridade, garantindo que tarefas cr√≠ticas recebam os recursos necess√°rios no momento certo. Fragmenta√ß√£o de Se√ß√µes N√£o Preempt√≠veis: Reduz o tempo de bloqueio em c√≥digo cr√≠tico, quebrando longas se√ß√µes n√£o preempt√≠veis em peda√ßos menores. Esses recursos tornam o kernel Linux altamente responsivo e adequado para sistemas que exigem previsibilidade e baixa lat√™ncia, como aplica√ß√µes em rob√≥tica, telecomunica√ß√µes e equipamentos m√©dicos. A seguir, apresentamos um exemplo de como configurar e testar um kernel com suporte a PREEMPT-RT. Essas instru√ß√µes foram realizadas em uma m√°quina virtual Ubuntu 22.04 LTS. Passos: 1. Obter o c√≥digo do kernel mais recente: git clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git cd linux 2. Configurar o kernel para PREEMPT-RT: make menuconfig Navegue at√© General Setup / Preemption Model e ative a op√ß√£o Fully Preemptible Kernel (Real-Time). Salve e saia. Verifique se a configura√ß√£o foi aplicada: grep PREEMPT_RT .config # Sa√≠da esperada: CONFIG_PREEMPT_RT=y 3. Compilar o kernel: time make -j$(nproc) 4. Instalar e reiniciar: sudo make modules_install &amp;&amp; sudo make install sudo reboot Selecione o novo kernel na inicializa√ß√£o. 5. Confirmar a vers√£o: cat /proc/version # Exemplo de sa√≠da: # Linux version 6.11.0-rtl+ (gcc (Ubuntu 11.4.0) 11.4.0) #1 SMP PREEMPT_RT Fri Sep 20 19:11:35 IST 2024 Agora o kernel est√° configurado para suportar tarefas de tempo real. Para verificar sua efici√™ncia, execute aplicativos em tempo real como mixagem de √°udio com JACK ou PulseAudio. Como Configurar o Red Hat Enterprise Linux for Real Time O Red Hat Enterprise Linux for Real Time (RHEL-RT) oferece um conjunto de ferramentas e configura√ß√µes otimizadas para aplica√ß√µes sens√≠veis √† lat√™ncia. Seguem os passos para configurar e aproveitar ao m√°ximo o RHEL-RT: 1. Pr√©-requisitos Certifique-se de que sua subscri√ß√£o Red Hat inclui o canal do RHEL for Real Time. Atualize seu sistema: sudo dnf update -y 2. Instala√ß√£o do Kernel RT Instale o kernel otimizado para tempo real: sudo dnf install kernel-rt kernel-rt-devel 3. Sele√ß√£o do Kernel RT no Bootloader Depois de instalar o kernel, configure o bootloader para usar o kernel RT como padr√£o: grub2-set-default \"Red Hat Enterprise Linux (kernel-rt)\" sudo grub2-mkconfig -o /boot/grub2/grub.cfg sudo reboot 4. Ajustes de Lat√™ncia Ap√≥s reiniciar no kernel RT, use ferramentas como tuna para ajustar prioridades e afinidades de CPU: sudo tuna -t irq -q sudo tuna -t \"[sua aplica√ß√£o]\" -p 99 Configure o particionamento da CPU para isolar n√∫cleos dedicados a tarefas de tempo real: echo 1 &gt; /sys/devices/system/cpu/cpu[X]/isolated 5. Ferramentas de Diagn√≥stico Utilize ferramentas como cyclictest para medir a lat√™ncia: sudo cyclictest -m -Sp99 -i100 -h300 -q Como o RTL foi Implementado pela Red Hat? A Red Hat contribuiu de forma significativa para a integra√ß√£o do PREEMPT-RT no kernel principal. No Red Hat Enterprise Linux for Real Time, v√°rias otimiza√ß√µes foram feitas para: Otimizar lat√™ncias: Ajustes no agendador e gerenciamento de interrup√ß√µes. Ferramentas especializadas: Perfis de kernel personalizados e ferramentas como tuna para ajustar prioridades em tempo real. Seguran√ßa: Garantir que as modifica√ß√µes n√£o comprometem a estabilidade do sistema. Conclus√£o A inclus√£o do Real-Time Linux no kernel principal marca um ponto de virada para o Linux como um sistema operacional universal. Agora, ele √© capaz de atender tanto aplica√ß√µes convencionais quanto ambientes que exigem alt√≠ssima previsibilidade. Seja voc√™ um desenvolvedor interessado em explorar o potencial do Linux em sistemas embarcados ou um entusiasta de tecnologia, o RTL abre novas portas para inova√ß√µes em diversas √°reas. Refer√™ncias Linux Foundation. ‚ÄúReal-Time Linux Documentation.‚Äù Dispon√≠vel em: https://wiki.linuxfoundation.org/realtime/documentation/start. Acesso em: 20 dez. 2024. Linux Foundation. ‚ÄúKernel PREEMPT-RT.‚Äù Dispon√≠vel em: https://wiki.linuxfoundation.org/realtime/documentation/technical_basics/preemption_models. Acesso em: 20 dez. 2024. Red Hat. ‚ÄúRed Hat Enterprise Linux for Real Time.‚Äù Dispon√≠vel em: https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/7/html/installation_guide/chap-why_use_rt_to_optimize_latency#chap-Why_Use_RT_to_Optimize_Latency. Acesso em: 20 dez. 2024. Kaiwan N Billimoria. ‚ÄúThe Linux Kernel is Now an RTOS.‚Äù Blog Kaiwan Tech. Dispon√≠vel em: https://kaiwantech.wordpress.com/2024/09/21/the-linux-kernel-is-now-an-rtos-with-rtl-being-fully-merged/. Acesso em: 20 dez. 2024. " }, { "title": "TCP/IP O in√≠cio e a evolu√ß√£o", "url": "/posts/protocolos-TCP-IP-o-inicio/", "categories": "networking, tcpip", "tags": "networking, tcp-ip, protocolos, arpanet, internet, historia, tecnologia, redes", "date": "2024-12-14 00:00:00 -0300", "content": "Protocolos TCP/IP: Uma Introdu√ß√£o Completa O ARPANET e as Origens do TCP/IP A hist√≥ria dos protocolos TCP/IP come√ßa no final dos anos 1950, durante o auge da Guerra Fria. O Departamento de Defesa dos EUA (DoD) buscava uma rede de comando e controle que pudesse sobreviver a um ataque nuclear. Na √©poca, as comunica√ß√µes militares utilizavam a rede telef√¥nica p√∫blica, considerada vulner√°vel devido √† sua hierarquia r√≠gida e falta de redund√¢ncia. In√≠cio da Pesquisa e Contribui√ß√µes de Paul Baran Em torno de 1960, o DoD contratou a RAND Corporation para encontrar uma solu√ß√£o. Paul Baran prop√¥s um design distribu√≠do altamente tolerante a falhas, que usava tecnologia de comuta√ß√£o de pacotes digitais em vez de sinais anal√≥gicos. Apesar da resist√™ncia inicial de grandes empresas como a AT&amp;T, a ideia de Baran lan√ßou as bases para as redes resilientes modernas. O Papel da ARPA Em resposta ao lan√ßamento do sat√©lite Sputnik pela Uni√£o Sovi√©tica em 1957, o governo dos EUA criou a ARPA (Advanced Research Projects Agency). A ARPA iniciou esfor√ßos em redes de computadores para promover a pesquisa cient√≠fica e tecnol√≥gica. Larry Roberts, um dos gerentes da ARPA, decidiu construir uma rede baseada em comuta√ß√£o de pacotes, influenciado pelo trabalho de Paul Baran e Donald Davies. Estrutura do ARPANET A ARPANET foi projetada como uma rede de sub-redes de comuta√ß√£o de pacotes composta por minicomputadores chamados IMPs (Interface Message Processors). Esses IMPs, conectados por linhas de transmiss√£o de 56 kbps, formaram a primeira rede eletr√¥nica de comuta√ß√£o de pacotes que utilizava o m√©todo de armazenamento e encaminhamento para transmitir dados de forma confi√°vel. Cada n√≥ da rede era composto por um IMP e um host, conectados localmente por fios curtos. Mensagens de at√© 8063 bits eram divididas em pacotes menores e transmitidas de forma independente, permitindo o roteamento din√¢mico caso partes da rede fossem destru√≠das. A rede foi projetada para ser resiliente, com cada IMP conectado a pelo menos dois outros, garantindo redund√¢ncia. Crescimento e Impacto A ARPANET entrou em opera√ß√£o em dezembro de 1969 com quatro n√≥s iniciais: UCLA, UCSB, SRI e a Universidade de Utah. Em poucos anos, a rede cresceu rapidamente, conectando mais institui√ß√µes e redes. Durante os anos 1980, a integra√ß√£o de novas redes e a cria√ß√£o do DNS (Domain Name System) facilitaram o gerenciamento de endere√ßos e nomes de host. Essa expans√£o culminou na cria√ß√£o dos protocolos TCP/IP, projetados para interconectar redes heterog√™neas. Contratos foram estabelecidos com universidades e empresas para implementar os protocolos em diferentes plataformas, consolidando o TCP/IP como padr√£o global de comunica√ß√£o em redes. Introdu√ß√£o ao Modelo TCP/IP Os protocolos TCP/IP (Transmission Control Protocol/Internet Protocol) formam a espinha dorsal da comunica√ß√£o na internet moderna. Este artigo fornece uma revis√£o abrangente sobre os protocolos, suas camadas e como eles trabalham juntos para permitir a transmiss√£o de dados em redes locais e globais. O Modelo TCP/IP: Introdu√ß√£o e Primeira Camada O modelo TCP/IP √© um framework fundamental para a comunica√ß√£o de dados em redes modernas, estruturado em quatro camadas principais. Cada camada desempenha uma fun√ß√£o espec√≠fica, permitindo que os dados sejam transmitidos de forma eficiente e confi√°vel. Neste artigo, come√ßaremos com uma an√°lise detalhada da primeira camada: Camada de Aplica√ß√£o. Camada de Aplica√ß√£o: A Interface do Usu√°rio A Camada de Aplica√ß√£o no modelo TCP/IP representa o ponto de contato direto entre os usu√°rios e a rede. Ela oferece as ferramentas e protocolos necess√°rios para que aplicativos e servi√ßos possam interagir com o sistema de comunica√ß√£o. Esta camada traduz solicita√ß√µes e respostas de aplica√ß√µes em dados compreens√≠veis pelas camadas inferiores do modelo. Essa camada tamb√©m √© conhecida como a Camada 7 no modelo OSI (Open Systems Interconnection), que √© um modelo de refer√™ncia semelhante ao TCP/IP. No entanto, o modelo TCP/IP √© mais amplamente utilizado e mais diretamente relacionado √† arquitetura da internet. Funcionalidades Principais Intera√ß√£o com Aplica√ß√µes: Oferece servi√ßos que permitem que aplicativos de software utilizem a rede para transmitir dados. Processamento de Dados: Manipula a estrutura dos dados para garantir compatibilidade com protocolos de transporte. Servi√ßos de Rede: Facilita a implementa√ß√£o de servi√ßos espec√≠ficos, como transfer√™ncia de arquivos, envio de e-mails e navega√ß√£o na web. Exemplos de Protocolos na Camada de Aplica√ß√£o HTTP/HTTPS (Hypertext Transfer Protocol): Facilita a comunica√ß√£o entre navegadores e servidores web, essencial para a navega√ß√£o na internet. FTP (File Transfer Protocol): Utilizado para a transfer√™ncia de arquivos entre computadores. SMTP (Simple Mail Transfer Protocol): Gerencia o envio de e-mails. DNS (Domain Name System): Resolve nomes de dom√≠nio em endere√ßos IP. Estrutura T√©cnica Os protocolos na Camada de Aplica√ß√£o n√£o apenas facilitam a comunica√ß√£o, mas tamb√©m incorporam funcionalidades como autentica√ß√£o, compress√£o e criptografia. Por exemplo, o HTTPS adiciona seguran√ßa ao HTTP usando o protocolo SSL/TLS para criptografar dados transmitidos. Modelo de Dados Os dados processados nesta camada s√£o encapsulados e formatados em mensagens, que ser√£o transmitidas para a pr√≥xima camada. A seguir, est√° o fluxo de dados t√≠pico dentro da camada de aplica√ß√£o: Aplica√ß√µes no Dia a Dia A Camada de Aplica√ß√£o √© amplamente utilizada por programas que fazem parte do nosso cotidiano: Navegadores Web: Ao acessar um site, como ‚Äúwww.example.com‚Äù, o navegador utiliza o HTTP ou HTTPS para enviar solicita√ß√µes e receber respostas do servidor web. Clientes de E-mail: Programas como Microsoft Outlook ou Thunderbird utilizam protocolos como SMTP, IMAP ou POP3 para enviar e receber mensagens. Streaming de V√≠deo: Servi√ßos como Netflix e YouTube empregam protocolos como HTTP/HTTPS para entrega de v√≠deos, muitas vezes utilizando redes de distribui√ß√£o de conte√∫do (CDN). Aplicativos de Mensagens: WhatsApp e Telegram utilizam protocolos de comunica√ß√£o baseados em HTTP/HTTPS e outros servi√ßos da camada de aplica√ß√£o para troca de mensagens instant√¢neas e arquivos. Jogos Online: Muitos jogos dependem de APIs baseadas em HTTP/HTTPS para autentica√ß√£o e sincroniza√ß√£o de dados, al√©m de outros protocolos espec√≠ficos. Import√¢ncia na Arquitetura de Redes A Camada de Aplica√ß√£o √© considerada cr√≠tica porque estabelece os fundamentos para a intera√ß√£o humano-computador nas redes. Sem esta camada, o uso pr√°tico da internet seria imposs√≠vel, pois n√£o haveria um meio eficaz de traduzir as inten√ß√µes humanas em solicita√ß√µes process√°veis pela rede. Testando a Camada de Aplica√ß√£o com Python Para demonstrar a funcionalidade da Camada de Aplica√ß√£o, podemos realizar um teste pr√°tico utilizando um script em Python que simula uma solicita√ß√£o HTTP para um servidor web. Aqui est√° o c√≥digo: # Importar a biblioteca de sockets para comunica√ß√£o de rede import socket # Fun√ß√£o para testar a camada de aplica√ß√£o usando o protocolo HTTP def test_application_layer(host: str, port: int): \"\"\"Fun√ß√£o para testar a camada de aplica√ß√£o usando o protocolo HTTP.\"\"\" try: # Criar um socket para comunica√ß√£o com o servidor with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as client_socket: # Conectar ao servidor especificado pelo host e porta client_socket.connect((host, port)) # Preparar uma solicita√ß√£o HTTP GET simples http_request = f\"GET / HTTP/1.1\\r\\nHost: {host}\\r\\nConnection: close\\r\\n\\r\\n\" # Enviar a solicita√ß√£o HTTP para o servidor client_socket.sendall(http_request.encode()) # Receber a resposta do servidor em partes (chunks) response = b\"\" while True: # Receber um chunk de dados do servidor chunk = client_socket.recv(4096) # Se n√£o houver mais dados, interromper o loop if not chunk: # Se n√£o houver mais dados, interromper o loop break # Adicionar o chunk recebido √† resposta completa response += chunk # Exibir a resposta completa do servidor no console print(\"Resposta do Servidor:\") # Decodificar a resposta bin√°ria em texto print(response.decode()) except Exception as e: # Capturar e exibir qualquer erro que ocorra durante o teste print(f\"Erro ao testar a camada de aplica√ß√£o: {e}\") # Testar a fun√ß√£o com um servidor HTTP espec√≠fico test_application_layer(\"www.example.com\", 80) Output Esperado Quando executado, o script realiza uma solicita√ß√£o HTTP para www.example.com e exibe a resposta do servidor. O output ser√° semelhante ao seguinte: $ python aplicacao.py Resposta do Servidor: HTTP/1.1 200 OK Age: 119377 Cache-Control: max-age=604800 Content-Type: text/html; charset=UTF-8 Date: Sat, 14 Dec 2024 03:53:09 GMT Etag: \"3147526947+ident\" Expires: Sat, 21 Dec 2024 03:53:09 GMT Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT Server: ECAcc (mid/8790) Vary: Accept-Encoding X-Cache: HIT Content-Length: 1256 Connection: close &lt;!doctype html&gt; &lt;html&gt; . . . Essa demonstra√ß√£o pr√°tica destaca como os protocolos na Camada de Aplica√ß√£o, como HTTP, facilitam a comunica√ß√£o entre clientes e servidores em redes modernas. Sem esta camada, o uso pr√°tico da internet seria imposs√≠vel, pois n√£o haveria um meio eficaz de traduzir as inten√ß√µes humanas em solicita√ß√µes process√°veis pela rede. Refer√™ncias Tanenbaum, A. S., &amp; Wetherall, D. J. (2011). Computer Networks. Baran, P. (1964). On Distributed Communications: Introduction to Distributed Communications Network. Roberts, L. (1967). Multiple Computer Networks and Intercomputer Communication. Braden, R. (1989). RFC 1122: Requirements for Internet Hosts - Communication Layers. Clark, D. D. (1988). The Design Philosophy of the DARPA Internet Protocols. Cerf, V., &amp; Kahn, R. E. (1974). A Protocol for Packet Network Intercommunication. Pr√≥ximos Passos Nos pr√≥ximos artigos, exploraremos as camadas subsequentes do modelo TCP/IP, detalhando suas fun√ß√µes e protocolos associados. A pr√≥xima ser√° a Camada de Transporte, onde examinaremos o papel do TCP e UDP na comunica√ß√£o confi√°vel e eficiente. " }, { "title": "Running local AI with Instruct Lab and Skupper", "url": "/posts/running-local-ai-with-instruct-lab/", "categories": "skupper, instructlab, chatbot", "tags": "ai, instructlab, skupper, llm, chatbot, machine-learning, openshift, local-ai, security", "date": "2024-08-01 00:00:00 -0300", "content": "Welcome to the Ollama Pilot. Problem to solve The main goal of this project is to create a secure connection between two sites, enabling the communication between the engineer machine and an Instruct Lab Model. The merlinite-7b-lab-Q4_K_M.gguf model will be used for the chatbot, and it is available in the Instruct Lab. The license of the model is available in the Instruct Labs. But, why the banner? Well, the engineer needs to know who is better, Lebron or Jordan. The chatbot will be responsible for answering this question. The chatbot will receive the user input and send it to the llama3 model. The response from the merlinite model will be sent back to the user. Disclaimer All the models used are available in the Hugging Face model hub. The models are not hosted in this project, they are hosted by Hugging Face. The models are used for educational purposes only. Why InstructLab There are many projects rapidly embracing and extending permissively licensed AI models, but they are faced with three main challenges: Contribution to LLMs is not possible directly. They show up as forks, which forces consumers to choose a ‚Äúbest-fit‚Äù model that isn‚Äôt easily extensible. Also, the forks are expensive for model creators to maintain. The ability to contribute ideas is limited by a lack of AI/ML expertise. One has to learn how to fork, train, and refine models to see their idea move forward. This is a high barrier to entry. There is no direct community governance or best practice around review, curation, and distribution of forked models. This snippet was extracted from the Instruct Labs repository. Why Skupper Here the answer is simple, Skupper is a tool that enables secure communication between services in different environments. Skupper will be used to create a secure connection between the two sites, one of the sites has restricted access to the internet. Skupper will enable the communication between the two sites, allowing the Ollama Pilot application to send requests to the llama3 model thru the Instruct Lab chat. Description This project has the objective to create a VAN (Virtual Application Network) that enables the connection between two sites: Site A: A server that hosts the Instruct Lab chat model. This model will be responsible for receiving the user input and sending it to the llama3 model. The response from the llama3 model will be sent back to the user. Site B: An OpenShift site that exposes the Instruct Lab chat model. This site will be responsible for sending the user input to the Instruct Lab chat model and receiving the response from the Merlinite-7b-lab-Q4_K_M.gguf model. In order to connect the two sites, we will use Skupper, a tool that enables secure communication between services in different environments. Skupper will be used to create a secure connection between the two sites, allowing the Ollama Pilot application to send requests to the llama3 model and receive the response from the merlinite model. At the end of the project, you will be able to use your own CHATBOT with protected data. Architecture Summary AI model deployment with InstructLab Private Skupper deployment Public Skupper deployment Secure communication between the two sites with Skupper Chatbot with protected data 1. AI model deployment with InstructLab The first step is to deploy the InstructLab chat model in the InstructLab site. The InstructLab chat model will be responsible for receiving the user input and sending it to the llama3 model. The response from the llama3 model will be sent back to the user. This is based on the article: Getting started with InstructLab for generative AI model tuning mkdir instructlab &amp;&amp; cd instructlab python3.11 -m venv venv source venv/bin/activate pip install 'instructlab[cuda]' -C cmake.args=\"-DLLAMA_CUDA=on\" -C cmake.args=\"-DLLAMA_NATIVE=off\" IMPORTANT: This installation method will enable your Nvidia GPU to be used by instructlab. If you don‚Äôt have an Nvidia GPU, please check other options in: InstructLab üê∂ (ilab) ilab config init To enable external access to your model, please modify the config.yaml file: chat: context: default greedy_mode: false logs_dir: data/chatlogs max_tokens: null model: models/merlinite-7b-lab-Q4_K_M.gguf session: null vi_mode: false visible_overflow: true general: log_level: INFO generate: chunk_word_count: 1000 model: models/merlinite-7b-lab-Q4_K_M.gguf num_cpus: 10 num_instructions: 100 output_dir: generated prompt_file: prompt.txt seed_file: seed_tasks.json taxonomy_base: origin/main taxonomy_path: taxonomy serve: gpu_layers: -1 host_port: 0.0.0.0:8000 # HERE max_ctx_size: 4096 model_path: models/merlinite-7b-lab-Q4_K_M.gguf Now, you can download and start your server: ilab model download ilab model serve # The output should be similar to: INFO 2024-07-30 18:59:01,199 serve.py:51: serve Using model 'models/merlinite-7b-lab-Q4_K_M.gguf' with -1 gpu-layers and 4096 max context size. INFO 2024-07-30 18:59:01,611 server.py:218: server Starting server process, press CTRL+C to shutdown server... INFO 2024-07-30 18:59:01,612 server.py:219: server After application startup complete see http://0.0.0.0:8000/docs for API. 2. Private Skupper deployment The second step is to deploy the private Skupper in Site A. The private Skupper will be responsible for creating a secure connection between the two sites, allowing the Ollama Pilot application to send requests to the llama3 model and receive the response from the merlinite model. Open a new terminal and run the following commands: Install Skupper export SKUPPER_PLATFORM=podman skupper init --ingress none Exposing the InstructLab chat model In order to do this, we will bind the local service that is running the InstructLab chat model to the Skupper service. skupper expose host host.containers.internal --address instructlab --port 8000 Let‚Äôs check the status of the Skupper service: skupper service status Services exposed through Skupper: ‚ï∞‚îÄ instructlab:8000 (tcp) Now, we are almost ready to connect the two sites. The next step is to deploy the public Skupper in Site B and create a connection between the two sites. 3. Public Skupper deployment The third step is to deploy the public Skupper in Site B. The public Skupper will receive the connection from the private Skupper and create a secure connection between the two sites. Open a new terminal and run the following commands: Creating the project and deploying the public Skupper: oc new-project ollama-pilot skupper init --enable-console --enable-flow-collector --console-user admin --console-password admin Creating the token to allow the private Skupper to connect to the public Skupper: skupper token create token.yaml At this point, you should have a token.yaml file with the token to connect the two sites. The next step is to link the two sites. For this, we will need to switch back to the terminal where the private Skupper is running. 4. Secure communication between the two sites with Skupper The fourth step is to connect the two sites. In the terminal where the private Skupper is running, run the following command: skupper link create token.yaml --name instructlab # Or any other name you want Let‚Äôs check the status of the Skupper link: skupper link status Links created from this site: Link instructlab is connected Current links from other sites that are connected: There are no connected links Before continuing, let‚Äôs hop back to the terminal where the public Skupper is running and check the status of the link: skupper link status Links created from this site: There are no links configured or connected Current links from other sites that are connected: Incoming link from site b8ad86d5-9680-4fea-9c07-ea7ee394e0bd 5. Chatbot with protected data Now the last part is to expose the service in the public Skupper and create the Ollama Pilot application. Still on the terminal where the public Skupper is running, run the following command to expose the service. With the following command, we will create a Skupper service that matches the service exposed by the private Skupper. This will end up creating a Kubernetes service that will be used by the Ollama Pilot application. skupper service create instructlab 8000 Exposing the service to the internet: oc expose service instructlab Getting the public URL: oc get route instructlab NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD instructlab instructlab-ollama-pilot.apps.your-cluster-url instructlab port8000 None The last step is to create the Ollama Pilot application. The Ollama Pilot application will be responsible for sending the user input to the Instruct Lab chat model and receiving the response from the Merlinite-7b-lab-Q4_K_M.gguf model. The Ollama Pilot application will be able to send requests to the Instruct Lab chat model through the secure connection created by Skupper. You can repeat all the instructions in step 1. AI model deployment with InstructLab to install the Instruct Lab chat model in Site B. The only difference is that you will not run the ilab model serve command because the Instruct Lab chat model is already running in Site A. The Ollama Pilot application will be responsible for sending the user input to the Instruct Lab chat model and receiving the response from the Merlinite-7b-lab-Q4_K_M.gguf model. The Ollama Pilot application will be able to send requests to the Instruct Lab chat model through the secure connection created by Skupper. ilab model chat --endpoint-url http://instructlab-ollama-pilot.apps.your-cluster-url/v1/ ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ system ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ Welcome to InstructLab Chat w/ MODELS/MERLINITE-7B-LAB-Q4_K_M.GGUF (type /h for help) ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ &gt;&gt;&gt; [S][default] THE question: Yes or No question. Don‚Äôt fool me. Is LeBron better than Jordan? Have fun with your new chatbot with protected data! If you don‚Äôt agree with the answer, you can always ask again and train your model, but King James is the best! " }, { "title": "Vim Motions: Navigating and Editing Code Efficiently", "url": "/posts/vim-motions/", "categories": "vim, productivity", "tags": "vim, neovim, astrovim, editor, produtividade, motions, desenvolvimento, tools", "date": "2024-07-02 14:31:00 -0300", "content": "Vim Motions: Your Keyboard Shortcut Powerhouse Vim motions are a set of commands that empower you to navigate and edit code like a pro. This guide dives into different Vim motions and how to harness them for lightning-fast coding. My Vim Journey: From VSCode and IntelliJ to Neovim and AstroVim After years of using VSCode and IntelliJ, I decided to make the switch to Neovim as my primary development tool. Neovim is a hyperextensible Vim-based text editor that provides a modern and more powerful experience compared to traditional Vim. Recently, I transitioned to AstroVim, a Neovim configuration that comes with a set of built-in plugins and features that enhance productivity. AstroVim offers an intuitive file explorer, search functionality, and other built-in plugins that make the development experience smoother and more efficient. The decision to switch was driven by the need for a more integrated and user-friendly environment, which AstroVim provides out of the box. This series of posts will document my journey and share the tips, tricks, and configurations that have made Neovim and AstroVim indispensable parts of my workflow. After years of using VSCode and IntelliJ, I decided to make the switch to Neovim as my primary development tool. This series of posts will document my journey and share the tips, tricks, and configurations that have made Neovim an indispensable part of my workflow. Today, we‚Äôre starting with the foundation: Vim motions. Mastering these commands is key to unlocking the full potential of Vim‚Äôs editing power. Disclaimer: This is not meant to be a flamewar about editors. It‚Äôs simply a reflection of what has worked best for me and an invitation for you to explore if Vim might be a good fit for your own development style. Vim Plugins: My Productivity Arsenal AstroVim comes with a curated set of plugins that enhance the Neovim experience. Here are some of the default plugins included in AstroVim: ‚Äúnvim-treesitter‚Äù - Syntax highlighting and code navigation ‚Äútelescope.nvim‚Äù - Fuzzy finder and file explorer ‚Äúnvim-lspconfig‚Äù - Language Server Protocol configurations ‚Äúnvim-cmp‚Äù - Autocompletion plugin ‚Äúgitsigns.nvim‚Äù - Git integration ‚Äúlualine.nvim‚Äù - Status line ‚Äúwhich-key.nvim‚Äù - Keybinding helper ‚Äúnvim-tree.lua‚Äù - File explorer ‚Äúbufferline.nvim‚Äù - Buffer line for managing open files ‚Äúplenary.nvim‚Äù - Lua functions used by many plugins ‚Äúcopilot.vim‚Äù - AI-powered code completion ‚Äúcatppuccin/nvim‚Äù - Catppuccin Macchiato theme for Neovim (Complete plugin setup and details will be covered in future posts.) The Vim Editor: More Than Meets the Eye Vim is a highly customizable text editor known for its modal nature. Its modes ‚Äì Normal, Insert, and Visual ‚Äì cater to distinct tasks, allowing you to switch seamlessly between command input and text editing. Vim Plugins: Supercharge Your Vim Experience Vim‚Äôs capabilities extend far beyond its core features. With a vast array of community-maintained plugins, you can transform Vim into a full-fledged Integrated Development Environment (IDE). Vim Motions in Action By mastering Vim motions, you‚Äôll write and navigate code with impressive speed. Even popular IDEs like VS Code offer Vim plugins, enabling you to leverage Vim‚Äôs navigation within your preferred environment. Vim Modes: Normal Mode: Your command center for issuing instructions. Insert Mode: Where the actual code writing happens. Visual Mode: Select and manipulate text visually, with options for both normal and block selection. Vim also has a leader key for creating custom shortcuts, and a command mode for operations like saving files. Navigating Your Codebase AstroVim enhances navigation with additional keybindings that streamline your workflow: Window Navigation (Ctrl + h/j/k/l): Quickly move between split windows using Ctrl combined with h, j, k, or l. Buffer Navigation (]b, [b): Use ]b to move to the next buffer and [b to move to the previous buffer, making it easy to switch between open files. Resize Windows (Ctrl + Arrow Keys): Adjust window sizes with Ctrl and the arrow keys for up, down, left, and right. Toggle Neotree (Leader + e): Open or close the file explorer with Leader + e for quick access to your project files. Toggle Comment (Leader + /): Comment or uncomment lines with Leader + /, streamlining code documentation and debugging. Open Terminal (Leader + tf): Launch a floating terminal with Leader + tf for quick command-line access without leaving Neovim. Let‚Äôs dive into a React app and explore how Vim motions streamline navigation: Basic Movements (h, j, k, l): Forget arrow keys! Use these for left, down, up, and right movement. Prefix with a number (e.g., 5j) to move multiple lines. Word Navigation (w, b, e): Jump forward (w), backward (b), or to the end (e) of words. Use a number prefix for multiple word jumps. Line Navigation (0, ^, g, $, f, F): Go to the start (0), first non-blank character (^), end ($), or search for a character (f forward, F backward). Vertical Navigation ((), {}, Ctrl+D/U, Ctrl+F/B, G): Navigate by sentences (( and )), paragraphs ({ and }), half pages (Ctrl+D, Ctrl+U), full pages (Ctrl+F, Ctrl+B), start of file (gg), and end of file (G). Entering Insert Mode: Multiple Entry Points Vim offers various ways to enter insert mode, each suited for different editing scenarios: Before cursor (i): Use this when you need to insert text right before the current cursor position. For example, adding a missing character in a variable name. After cursor (a): Ideal for appending text immediately after the cursor. This is useful when you want to add a semicolon at the end of a statement. Beginning of line (I): Quickly jump to the start of a line to insert text. This is handy for adding comments or annotations at the start of a line of code. End of line (A): Move to the end of a line to append text. Use this when you need to extend a line with additional code or comments. Below current line (o): Open a new line below the current one and enter insert mode. This is perfect for adding a new line of code in a block. Above current line (O): Similar to o, but opens a new line above. Use this when you need to insert a line before the current one, such as adding a new function definition. Other insert mode triggers include c (change), s (substitute), y (yank/copy), and p (paste). You can even copy entire lines with yy. Learning More Vim‚Äôs learning curve can be steep, but the rewards are immense. To deepen your knowledge: Vim Documentation: https://vimdoc.sourceforge.io/index.html Vim Tutorial: https://www.tutorialspoint.com/vim/vim_tutorial.htm Vim Cheat Sheet: https://www.vim.org/doc/vimtutor/vimtutor.pdf Happy Vimming! " }, { "title": "Workshop: Patient Portal, conectando um banco de dados a um cluster K8S com Skupper", "url": "/posts/workshop-skupper-patient-portal/", "categories": "skupper, multi, cloud, network, redhat", "tags": "skupper, workshop, kubernetes, openshift, networking, database, tutorial, hands-on", "date": "2024-07-02 00:00:00 -0300", "content": "Descri√ß√£o Este workshop tem como objetivo apresentar o Red Hat Service Interconnect, uma solu√ß√£o de integra√ß√£o de aplica√ß√µes que permite a comunica√ß√£o entre diferentes sistemas de forma eficiente e segura. Arquitetura da Solu√ß√£o Topologia de Servi√ßos Resumo do Workshop Logar no Red Hat Developer. Criar um cluster Openshift. Acessar o cluster Openshift. No projeto do Red Hat Openshift Sandbox, acessar o seu projeto. Criar uma m√°quina virtual no Openshift Virtualization. Instalar pacotes na m√°quina virtual: podman kubernetes-client skupper oc wget Fazer o deploy do banco de dados com o podman. Fazer o deploy do frontend e do backend da aplica√ß√£o. Configurar o Service Interconnect (Skupper) para fazer a comunica√ß√£o do banco de dados rodando em um podman com a aplica√ß√£o rodando no Openshift. Acessar a aplica√ß√£o e verificar se a comunica√ß√£o est√° funcionando. Considera√ß√µes. Links Recurso Link [1] Red Hat Developer https://developers.redhat.com/ [2] OC https://docs.openshift.com/container-platform/4.15/cli_reference/openshift_cli/getting-started-cli.html [3] Skupper https://skupper.io/ Pr√©-requisitos Conta no Red Hat Developer Conhecimento b√°sico em Kubernetes Conhecimento b√°sico em Red Hat OpenShift Conhecimento b√°sico em Podman Google Chrome, a prefer√™ncia por ele √© pela funcionalidade de colar comandos no console da m√°quina virtual pelo VNC via browser. Passo a passo 1. Logar no Red Hat Developer Acesse o site do Red Hat Developer e fa√ßa o login com a sua conta. 2. Criar um cluster Openshift Sandbox 2.1. Acesse o Red Hat Openshift Sandbox e clique em ‚ÄúStart Cluster‚Äù. 2.2. Inicie o cluster Openshift Sandbox. 4. Acessar o cluster Openshift Acesse o cluster Openshift Sandbox e clique em ‚ÄúOpen Console‚Äù. 5. No projeto do Red Hat Openshift Sandbox, acessar o seu projeto Clique no seu projeto e mude para a view ‚ÄúAdministrator‚Äù. 6. Criar uma m√°quina virtual no Openshift Virtualization Acesse Virtualization no menu do cluster Openshift e clique em Virtual Machines. Clique em Create Virtual Machine. Escolha From Template e selecione o template Fedora VM. Clique em Create VirtualMachine. 7. Instalar pacotes na m√°quina virtual Acesse a m√°quina virtual e clique em Console. (D√™ preferencia para o Google Chrome, pois ele tem a funcionalidade de colar comandos no console da m√°quina virtual pelo VNC via browser). Logue com as credenciais que est√£o no console. Execute os comandos abaixo para instalar os pacotes necess√°rios: sudo dnf install -y podman kubernetes-client wget # Instalar o oc wget -qO- https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/openshift-client-linux.tar.gz | tar xz -C ~/.local/bin export PATH=\"$HOME/.local/bin:$PATH\" # Instalar o skupper curl https://skupper.io/install.sh | sh 8. Fazer o deploy do banco de dados com o podman Execute o comando abaixo para fazer o deploy do banco de dados: podman network create skupper podman run --name database-target --network skupper --detach --rm -p 5432:5432 quay.io/skupper/patient-portal-database 9. Fazer o deploy do frontend e do backend da aplica√ß√£o No seu console openshift, fa√ßa o deploy do seguinte yaml para o frontend: apiVersion: apps/v1 kind: Deployment metadata: labels: app: frontend name: frontend spec: replicas: 3 selector: matchLabels: app: frontend template: metadata: labels: app: frontend spec: containers: - name: frontend image: quay.io/skupper/patient-portal-frontend env: - name: DATABASE_SERVICE_HOST value: database - name: DATABASE_SERVICE_PORT value: \"5432\" - name: PAYMENT_PROCESSOR_SERVICE_HOST value: payment-processor - name: PAYMENT_PROCESSOR_SERVICE_PORT value: \"8080\" ports: - containerPort: 8080 No seu console openshift, fa√ßa o deploy do seguinte yaml para o backend: apiVersion: apps/v1 kind: Deployment metadata: labels: app: payment-processor name: payment-processor spec: replicas: 3 selector: matchLabels: app: payment-processor template: metadata: labels: app: payment-processor spec: containers: - name: payment-processor image: quay.io/skupper/patient-portal-payment-processor ports: - containerPort: 8080 10. Configurar o Service Interconnect (Skupper) para fazer a comunica√ß√£o do banco de dados rodando em um podman com a aplica√ß√£o rodando no Openshift. Para isso, vamos dividir em 3 etapas: Configura√ß√£o do Cluster Kubernetes Configura√ß√£o do Site Podman Expor o servi√ßo do banco de dados para a VAN do Skupper Configura√ß√£o do Cluster Kubernetes: Iniciar o skupper no cluster oenshift com o console habilitado skupper init --enable-console --enable-flow-collector --console-user admin --console-password admin Acessar o console do skupper, para isso acesse as rotas do seu cluster Openshift, a URL estar√° l√°. Criando um token para conectar o site podman com o cluster Openshift skupper token create ./skupper-token.yaml Configura√ß√£o do Site Podman: Acesse a m√°quina virtual e execute o comando abaixo para conectar o site podman com o cluster Openshift Ininie o skupper no site podman, sem ingress. skupper switch podman # para mudar o contexto para podman o padr√£o √© kubernetes Conecte o site podman com o cluster Openshift skupper link create ./skupper-token.yaml Acesse o console do skupper no cluster Openshift e verifique se o site podman est√° conectado. Expor o servi√ßo do banco de dados para a VAN do Skupper: Expor o servi√ßo do banco de dados para a VAN do Skupper systemctl --user enable --now podman.socket skupper service create database 5432 skupper service bind database host database-target --target-port 5432 No cluster Openshift, vamos criar um servi√ßo Skupper para o banco de dados, esse servi√ßo vai apontar para o servi√ßo do banco de dados que est√° rodando no site podman, atrav√©s da VAN do Skupper. skupper service create database 5432 Agora, a aplica√ß√£o frontend e backend est√£o se comunicando com o banco de dados que est√° rodando em um site podman, atrav√©s da VAN do Skupper. 13. Acessar a aplica√ß√£o e verificar se a comunica√ß√£o est√° funcionando Para isso, vamos precisar executar algumas tarefas para expor o frontend no cluster Openshift. Criar um servi√ßo para o fronend que aponte para o deployment dele use o seguinte YAML: apiVersion: v1 kind: Service metadata: name: frontend namespace: SEU-NAME-SPACE spec: selector: app: frontend ports: - protocol: TCP port: 8080 targetPort: 8080 Criar uma rota que aponte para o servi√ßo do frontend. kind: Route apiVersion: route.openshift.io/v1 metadata: name: frontend namespace: SEU-NAME-SPACE labels: {} spec: to: kind: Service name: frontend tls: {} port: targetPort: 8080 alternateBackends: [] 14. Considera√ß√µes O Red Hat Service Interconnect (Skupper): Oferece uma solu√ß√£o poderosa para integrar aplica√ß√µes em diferentes ambientes, simplificando a comunica√ß√£o entre servi√ßos e proporcionando maior flexibilidade e escalabilidade. Ao abstrair a complexidade da rede subjacente, o Skupper permite que os desenvolvedores se concentrem na l√≥gica de neg√≥cios de suas aplica√ß√µes, sem se preocupar com os detalhes de conectividade. Com recursos como descoberta de servi√ßos autom√°tica: O roteamento inteligente e seguran√ßa integrada, o Skupper garante que as aplica√ß√µes possam se comunicar de forma eficiente e segura, independentemente de sua localiza√ß√£o. Essa abordagem simplifica a gest√£o da infraestrutura e reduz a necessidade de configura√ß√µes manuais, agilizando o desenvolvimento e a implanta√ß√£o de aplica√ß√µes distribu√≠das. Al√©m disso, o Skupper oferece uma interface de usu√°rio intuitiva e ferramentas de linha de comando poderosas, facilitando a configura√ß√£o e o monitoramento da comunica√ß√£o entre servi√ßos. Com sua arquitetura extens√≠vel e suporte a diversos protocolos, o Skupper se adapta a diferentes cen√°rios de integra√ß√£o, atendendo √†s necessidades de projetos de todos os portes. Resumo Neste workshop, voc√™ aprendeu como usar o Red Hat Service Interconnect (Skupper) para conectar um banco de dados a um cluster Kubernetes, permitindo que aplica√ß√µes distribu√≠das se comuniquem de forma eficiente e segura. Com o Skupper, voc√™ pode simplificar a integra√ß√£o de servi√ßos em ambientes heterog√™neos, facilitando o desenvolvimento e a implanta√ß√£o de aplica√ß√µes modernas. Esperamos que este workshop tenha sido √∫til e que voc√™ possa aplicar esses conhecimentos em seus pr√≥prios projetos. Obrigado por participar! " }, { "title": "Using Skupper and OpenShift AI/ML to Prevent Insurance Fraud", "url": "/posts/AI-com-skupper-para-previnir-fraudes/", "categories": "AI, Skupper", "tags": "ai, machine-learning, skupper, openshift, fraud-detection, insurance, networking, security", "date": "2024-06-17 00:00:00 -0300", "content": "Description This workshop demonstrates how to use Skupper to connect local data services to cloud-based AI/ML environments. The workshop includes a Go application in a podman container that exposes internal data for Skupper connection. The AI/ML model training is performed in an OpenShift AI cluster on AWS using Openshift AI/ML services. Disclaimer This lab uses the example from the AI/ML Workshop created by the Red Hat AI Services team. The original workshop is available on GitHub and includes all the necessary information to run the lab. The lab was adapted to use Skupper to connect the local data services to the cloud-based AI/ML environment. In order to faciliate the execution, for those who have access to the demo.redhat.com environment, you can start the lab by clicking here. If you don‚Äôt have access to the demo environment, you can follow the steps at the gitub repository mentioned above. References Red Hat AI/ML Workshop GO Application to expose internal data Modified examples for the workshop The Developers Conference Workshop Repository Skupper Workshop Overview This lab demonstrates how AI/ML technologies can solve a business problem. The information, code, and techniques presented illustrate a prototype solution. Key steps include: Storing raw claim data within the company. Using a Go application in a podman container to expose internal data for Skupper connection. Setting up AI/ML model training in an OpenShift AI cluster on AWS. Connecting local data to cloud-based AI/ML services using Skupper. Skupper Role Skupper provides secure, efficient connections between different environments. In this workshop, it connects local data services containing sensitive insurance claim information to a cloud-based AI/ML environment. This secure connection allows remote data access and processing while maintaining data integrity and security. Process Structure Context Connection and Setup LLM for Text Summarization LLM for Information Extraction LLM for Sentiment Analysis Scenario We are a multinational insurance company undergoing digital transformation. A small team has analyzed the claims process and proposed improvements. The goal is to integrate the claims processing solution with text analysis using our API in a Kubernetes cluster on AWS. Challenges Using Skupper to Ensure Data Security and Integrity Maintaining data integrity and security: Skupper encrypts all data traffic, ensuring sensitive data protection during transmission. Processing emails with OpenShift AI in the on-premises datacenter. Keeping applications with sensitive data within the company. Ensuring secure connections between data services and datacenters. Prototyping Work Examples Using an LLM for Text Summarization An LLM can summarize long emails, allowing insurance adjusters to quickly understand key details. Using an LLM for Information Extraction An LLM extracts key information from emails and automatically populates structured forms. Using an LLM for Sentiment Analysis An LLM identifies customer sentiment, allowing for prompt action based on text tone. How to Use LLMs? Notebook for using LLM Notebook for text summarization with LLM Notebook for information extraction with LLM Notebook for comparing LLM models Part 2: Hands-On Activities Install Skupper binary Install Skupper locally Install Skupper on the OpenShift Cluster Linking the sites Run the application inside the podman site and expose the service Execute the workshop with modified examples Steps Installing the Skupper binary curl https://skupper.io/install.sh | sh Installing Skupper on the podman site export SKUPPER_PLATFORM=podman podman network create skupper skupper init --ingress none Install Skupper on the OpenShift Cluster skupper init --enable-console --enable-flow-collector --console-user admin --console-password admin Linking the sites Creating the token on the most exposed cluster skupper token create /tmp/insurance-claim Linking the podman site to the most exposed cluster skupper link create /tmp/insurance-claim --name ai Running the application inside the podman site and exposing the service podman run -d --network skupper -p 8080:8080 -v /home/rzago/Code/go-flp/data:/app/data --name insurance-claim-data quay.io/rzago/insurance-claim-data:latest skupper service create backend 8080 skupper service bind backend host insurance-claim-data --target-port 8080 skupper service create backend 8080 Successful Connection Final Topology Testing the connection to the podman site service from the OpenShift cluster oc exec deploy/skupper-router -c router -- curl http://backend:8080/claim/claim1.json Next Steps Now you can continue with the workshop until generating the sentiments of the emails. Conclusion This workshop demonstrates how to use Skupper to connect local data services to cloud-based AI/ML environments. The workshop includes a Go application in a podman container that exposes internal data for Skupper connection. The AI/ML model training is performed in an OpenShift AI cluster on AWS using Openshift AI/ML services. " }, { "title": "TemPy: An IoT Architecture with Raspberry Pi and Skupper", "url": "/posts/tempi-com-skupper-e-grafana/", "categories": "skupper, raspberry, grafana, opensource, english", "tags": "skupper, raspberry-pi, iot, grafana, prometheus, opensource, networking, monitoring, temperature-sensor", "date": "2024-02-15 00:00:00 -0300", "content": "Description This project is a proof of concept for an IoT architecture using a Raspberry Pi and a temperature sensor that exposes the temperature data through a REST API. Along with the REST API, there is a cloud integration with any cloud provider using Skupper that enables the data to be visualized in a Grafana dashboard. Clone the repository and follow the instructions to run the project. https://github.com/rafaelvzago/skupper-tempy git clone https://github.com/rafaelvzago/skupper-tempy.git Table of Contents Hardware Raspberry Configuration Temperature Capture Skupper Role Connection to a cluster using skupper and storage data into prometheus Prometheus Grafana Repository Architecture The architecture of the project can be divided into the following parts: Hardware This part involves the physical components used in the project, such as the Raspberry Pi and the temperature sensor. Raspberry Pi 3 Model B+ Raspberry Pi 3 Model B+ DS18B20 Temperature Sensor DS18B20 Temperature Sensor 4.7kŒ© Resistor 4.7kŒ© Resistor Breadboard Breadboard Jumper Wires Jumper Wires Raspberry Configuration This part focuses on the setup and configuration of the Raspberry Pi, including installing the necessary software and libraries. Ubuntu 23.04 server for Raspberry Pi Ubuntu Installation GoLang 1.18+ GoLang Installation Skupper Main Skupper Installation Podman &gt; 4.3 Podman Installation Temperature Capture Credits: Raspberry Pi DS18B20 Temperature Sensor Tutorial In this part, the temperature sensor is connected to the Raspberry Pi, and the code for capturing temperature readings is implemented. Configuration: Raspberry Pi GPIO Pins: Pin 1 (3.3V) is connected to the VDD pin of the DS18B20. Pin 7 (GPIO 4) is connected to the DQ pin of the DS18B20. Pin 9 (GND) is connected to the GND pin of the DS18B20. DS18B20: The VDD pin is powered by 3.3V from the Raspberry Pi. The DQ pin is connected to GPIO 4 with a pull-up resistor. The GND pin is grounded to the Raspberry Pi. Connections: A 4.7kŒ© pull-up resistor (R1) is placed between the VDD and DQ lines. The VDD line from the DS18B20 is connected to a red wire representing 3.3V from the Raspberry Pi. The DQ line is connected to a white wire representing data and is connected to GPIO 4 on the Raspberry Pi. The GND line is connected to a black wire representing ground from the Raspberry Pi. Functionality: The DS18B20 temperature sensor reports temperature data through the 1-Wire interface, which requires only one data line (and ground) for communication with the Raspberry Pi. The pull-up resistor is necessary for the 1-Wire protocol used by the DS18B20 to function correctly. REST API: To expose the temperature data, a REST API is implemented using GoLang. The API is used to capture the temperature data and expose it to the cloud provider. go build tempy/tempy.go Find a way to run the tempy binary on the Raspberry Pi, for this example I will use a simple nohup command to run the tempy binary in the background. nohup ./tempy &amp; The REST API is exposed on port 5000/temperature, and the temperature data can be accessed using the following command: curl localhost:5000/temperature Skupper Role We will use Skupper to establish communication between the Raspberry Pi and the cloud provider, and to expose the temperature data to the cloud. This part covers the setup and configuration of Skupper. Skupper is a layer 7 service interconnect that enables secure communication across Kubernetes clusters, including network and application layer protocols. Skupper is designed to connect services that are running on different infrastructure, and it is based on the idea of a service bus. Skupper In this example we will be using skupper gateway to expose the temperature data to the cloud, for this we will need to have a skupper site running on the cloud and a skupper gateway running on the Raspberry Pi. Skupper gateway is a component that allows non-kubernetes services to be exposed to the skupper network, in this case we will use the skupper gateway to expose the temperature data to the cloud. Skupper site: A namespace running skupper, for this example we will borrow the prometheus service to store the temperature data, so we will init skupper on the cluster with the following command: skupper init --site-name site1 --enable-console --enable-flow-collector Skuper gateway on the Raspberry Pi: To expose the temperature data to the cloud, we will use a skupper gateway to expose the temperature data to the cloud, for this we will use the following command: skupper gateway expose tempy localhost 5000 --type podman Connection to a cluster using skupper and storage data into prometheus The temperature data captured by the Raspberry Pi is stored in the cloud using the chosen cloud provider. This part explains how the data is stored and managed. For this example, we will deploy a prometheus service to store the temperature data, and a prometheus-adapter to scrape the temperature data from the REST API and store it in the prometheus service. In order to facilitate the prometheus role, we will configure the prometheus service discovery to scrape the temperature data from the prometheus-adapter or any other service labeled as app=metric. with this approach, we can easily add more temperature sensors to the architecture and the prometheus service will automatically scrape the temperature data from the new sensors. In order to achive this, the service will be labeled as app=metric, and the prometheus-adapter will add the temperature data to the service, so the prometheus service will scrape the temperature data from the prometheus-adapter. apiVersion: v1 kind: Service metadata: name: tempy-prometheus-adapter-service spec: type: ClusterIP selector: app: metrics Prometheus Adapter: Build the TemPy prometheus-adapter image: podman build -t quay.io/YOUR-USER/tempy-prometheus-adapter:0.1 -f prometheus-adapter/Dockerfile-TempyPrometheusAdapter . Push the image to the quay.io registry: podman push quay.io/YOUR-USER/tempy-prometheus-adapter:0.1 Deploy the prometheus-adapter: kubectl apply -f prometheus-adapter/TempyPrometheusAdapter-deployment.yaml Expose the prometheus-adapter: kubectl apply -f prometheus-adapter/TempyPrometheusAdapter-service.yaml Verify the prometheus-adapter is running: kubectl run -i --tty --rm curl-pod --image=curlimages/curl -- sh curl tempy-prometheus-adapter:9090/metrics ... # TYPE temperature_celsius gauge temperature_celsius 19.81 # HELP temperature_fahrenheit Current temperature in Fahrenheit # TYPE temperature_fahrenheit gauge temperature_fahrenheit 67.66 Check the prometheus-adapter service to check if the labels are being added to the service: kubectl get svc tempy-prometheus-adapter-service -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR tempy-prometheus-adapter-service ClusterIP 10.43.154.250 &lt;none&gt; 9090/TCP 11h app=metrics Prometheus The temperature data is stored in a prometheus service. This part covers the setup and configuration of the prometheus service. We need to persist the data, so we will use a PVC, in my case I will use the longhorn storage class, but you can use any storage class that you have available in your cluster. This is a part of the prometheus configuration file, it is configured to scrape the temperature data from any service labeled as app=metrics, so the prometheus service will scrape the temperature data from the prometheus-adapter. Note that this configuration will only look for services labeled as app=metrics in the skupper-pi namespace, so if you are using a different namespace, you will need to change the configuration file accordingly. ... - job_name: 'metrics-targets' scrape_interval: 5s kubernetes_sd_configs: - role: service namespaces: names: ['skupper-pi'] relabel_configs: - source_labels: [__meta_kubernetes_service_label_app] regex: metrics action: keep ... Create prometheus PVC: kubectl apply -f prometheus/prometheus-pvc.yaml Create prometheus deployment: kubectl apply -f prometheus/prometheus-deployment.yaml Configuring the prometheus service discovery to scrape the temperature data from any service labeled as app=metrics: kubectl apply -f prometheus/prometheus-cm.yaml Deploy the prometheus: kubectl apply -f prometheus/prometheus-deployment.yaml Create prometheus service: kubectl apply -f prometheus/prometheus-service.yaml Verify the prometheus is running, from this point on, the prometheus service should be scraping the temperature data from the prometheus-adapter or any other service labeled as app=metrics, let‚Äôs query all the services discovered by prometheus: kubectl run -i --tty --rm curl-pod --image=curlimages/curl -- sh -c 'curl -G --data-urlencode \"query=up\" http://prometheus:9090/api/v1/query' | jq . If you don't see a command prompt, try pressing enter. warning: couldn't attach to pod/curl-pod, falling back to streaming logs: Internal error occurred: error attaching to container: container is in CONTAINER_EXITED state { \"status\": \"success\", \"data\": { \"resultType\": \"vector\", \"result\": [ { \"metric\": { \"__name__\": \"up\", \"instance\": \"localhost:9090\", \"job\": \"prometheus\" }, \"value\": [ 1708523706.121, \"1\" ] }, { \"metric\": { \"__name__\": \"up\", \"instance\": \"promock.skupper-pi.svc:80\", \"job\": \"metrics-targets\" }, \"value\": [ 1708523706.121, \"1\" ] }, { \"metric\": { \"__name__\": \"up\", \"instance\": \"tempy-prometheus-adapter-service.skupper-pi.svc:9090\", \"job\": \"metrics-targets\" }, \"value\": [ 1708523706.121, \"1\" ] } ] } } ... Grafana The stored temperature data is visualized in a Grafana dashboard. This part covers the setup and configuration of the dashboard. To visualize the temperature data, we will use a Grafana dashboard. The dashboard is configured to scrape the temperature data from the prometheus service and visualize it in a graph. The grafana deployment is done using the following command: For the data persistence, we will use a PVC to store the grafana data, in my case I have longhorn installed on my cluster, so I will use it to store the grafana data, but you can use any other storage class that you have available on your cluster. Create grafana PVC: kubectl apply -f grafana/grafana-pvc.yaml Create grafana deployment: kubectl apply -f grafana/grafana-deployment.yaml Create grafana service: kubectl apply -f grafana/grafana-service.yaml Important: My cluster is configured to use the ingress controller, so I have to create an ingress to expose the grafana service, if your cluster is not configured to use the ingress controller, you will need either to expose the grafana service using a nodeport or a loadbalancer. Create a data source connection in grafana that points to the prometheus service: http://skupper-prometheus:9090 Import the grafana dashboard: grafana/dashboard.json FINALY, you should be able to visualize the temperature data in the grafana dashboard. Repository The complete code for the project can be found in the following GitHub repository: TemPy " }, { "title": "Carreira com Software Livre - O que √© e como come√ßar?", "url": "/posts/carreira-com-software-livre/", "categories": "carreira, opensource", "tags": "carreira, opensource, software-livre, linux, apache, cncf, contribuicao, licencas", "date": "2023-12-07 00:00:00 -0300", "content": "Carreira com Software Livre - O que √© e como come√ßar? Introdu√ß√£o Software Livre √© um movimento que tem como objetivo promover a liberdade de uso, estudo, modifica√ß√£o e distribui√ß√£o de software. O movimento do Software Livre √© baseado em quatro liberdades essenciais: A liberdade de executar o programa, para qualquer prop√≥sito (liberdade n¬∫ 0). A liberdade de estudar como o programa funciona e adapt√°-lo para as suas necessidades (liberdade n¬∫ 1). O acesso ao c√≥digo-fonte √© um pr√©-requisito para esta liberdade. A liberdade de redistribuir c√≥pias de modo que voc√™ possa ajudar ao seu pr√≥ximo (liberdade n¬∫ 2). A liberdade de aperfei√ßoar o programa, e liberar os seus aperfei√ßoamentos, de modo que toda a comunidade se beneficie (liberdade n¬∫ 3). O acesso ao c√≥digo-fonte √© um pr√©-requisito para esta liberdade. Tipos de licen√ßas para software livre Existem diversos tipos de licen√ßas para software livre, sendo as mais populares a GPL, LGPL, MIT, Apache, BSD e a Mozilla. Cada uma dessas licen√ßas possui suas pr√≥prias caracter√≠sticas e restri√ß√µes, por√©m, todas elas garantem as quatro liberdades essenciais do movimento do Software Livre. GPL: A GPL √© uma licen√ßa copyleft, o que significa que qualquer software que utilize uma biblioteca licenciada sob a GPL tamb√©m deve ser licenciado sob a GPL. A GPL √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. LGPL: A LGPL √© uma licen√ßa copyleft, o que significa que qualquer software que utilize uma biblioteca licenciada sob a LGPL tamb√©m deve ser licenciado sob a LGPL. A LGPL √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. MIT: A MIT √© uma licen√ßa permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a MIT pode ser licenciado sob qualquer outra licen√ßa. A MIT √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. Apache: A Apache √© uma licen√ßa permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a Apache pode ser licenciado sob qualquer outra licen√ßa. A Apache √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. BSD: A BSD √© uma licen√ßa permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a BSD pode ser licenciado sob qualquer outra licen√ßa. A BSD √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. Mozilla: A Mozilla √© uma licen√ßa permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a Mozilla pode ser licenciado sob qualquer outra licen√ßa. A Mozilla √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. Como come√ßar a contribuir com software livre? Existem diversas formas de contribuir com software livre, sendo as mais populares a contribui√ß√£o de c√≥digo, a contribui√ß√£o de documenta√ß√£o e a contribui√ß√£o de tradu√ß√£o. Cada uma dessas formas de contribui√ß√£o possui suas pr√≥prias caracter√≠sticas e restri√ß√µes, por√©m, todas elas garantem as quatro liberdades essenciais do movimento do Software Livre. A Import√¢ncia do Software Livre na Ind√∫stria de Tecnologia O Software Livre √© um movimento que tem como objetivo promover a liberdade de uso, estudo, modifica√ß√£o e distribui√ß√£o de software. Hoje existem v√°rios projetos que s√£o pilares da ind√∫stria e s√£o mantidos por comunidades de desenvolvedores que trabalham de forma volunt√°ria. Esses projetos s√£o essenciais para o desenvolvimento de novas tecnologias e para a evolu√ß√£o da ind√∫stria de tecnologia como um todo. Por isso, √© importante que os desenvolvedores se envolvam com o movimento do Software Livre e contribuam com projetos que s√£o essenciais para a ind√∫stria de tecnologia. Exemplos de software livre que s√£o essenciais para a ind√∫stria de tecnologia: Linux: O Linux √© um sistema operacional de c√≥digo aberto que √© utilizado por milh√µes de pessoas em todo o mundo. https://www.kernel.org/. Apache: O Apache √© um servidor web de c√≥digo aberto que √© utilizado por milh√µes de pessoas em todo o mundo. https://httpd.apache.org/. MariaDB: O MariaDB √© um sistema de gerenciamento de banco de dados de c√≥digo aberto derivado do MySQL. https://mariadb.org/. Docker: O Docker √© uma plataforma de c√≥digo aberto que permite que os desenvolvedores empacotem seus aplicativos em cont√™ineres. https://www.docker.com/. Kubernetes: O Kubernetes √© uma plataforma de c√≥digo aberto que permite que os desenvolvedores gerenciem seus aplicativos em cont√™ineres. https://kubernetes.io/. Ansible: O Ansible √© uma ferramenta de c√≥digo aberto que permite que os desenvolvedores automatizem a implanta√ß√£o de seus aplicativos. https://www.ansible.com/. Jenkins: O Jenkins √© uma ferramenta de c√≥digo aberto que permite que os desenvolvedores automatizem a constru√ß√£o e o teste de seus aplicativos. https://www.jenkins.io/. Git: O Git √© uma ferramenta de c√≥digo aberto que permite que os desenvolvedores controlem as vers√µes de seus aplicativos. https://git-scm.com/. Software livre em n√∫meros: Atualmente existem mais de 1.000.000 de projetos de software livre no GitHub. O GitHub √© a maior plataforma de desenvolvimento de software livre do mundo. GitHub O Linux √© o sistema operacional mais utilizado no mundo. Linux Existem mais de projetos 1861 projetos na CNCF. Tanto projetos graduados, incubados, sandbox e arquivados. CNCF Existem mais de 300 projetos na Apache. Apache CNCF - Cloud Native Computing Foundation CNCF (Cloud Native Computing Foundation): Uma organiza√ß√£o sem fins lucrativos. Objetivo: Promover o desenvolvimento de software livre para a nuvem. Caracter√≠sticas: Foco em Cloud Native: Concentra-se em tecnologias que empoderam sistemas escal√°veis, resilientes e √°geis baseados em cont√™ineres. Comunidade Aberta e Colaborativa: Encoraja a colabora√ß√£o e contribui√ß√£o abertas entre membros da ind√∫stria, desenvolvedores e usu√°rios finais. Padr√µes e Pr√°ticas de Governan√ßa: Estabelece padr√µes e melhores pr√°ticas para garantir interoperabilidade e efici√™ncia. Apoio √† Inova√ß√£o e Sustentabilidade: Fomenta a inova√ß√£o e sustentabilidade de projetos e comunidades de software livre. Eventos e Educa√ß√£o: Organiza eventos, webinars e programas educacionais para promover conhecimento e colabora√ß√£o na comunidade cloud native. Projetos Chave: Kubernetes: Um sistema de orquestra√ß√£o de cont√™ineres. Prometheus: Sistema de monitoramento e alerta. Envoy: Um proxy de servi√ßo de c√≥digo aberto. Links: Site Oficial Kubernetes Prometheus Envoy CNCF Projects Apache Software Foundation ASF (Apache Software Foundation): Uma organiza√ß√£o sem fins lucrativos. Objetivo: O objetivo da ASF √© fornecer software livre para o p√∫blico em geral. Principais Projetos da Apache Software Foundation: Apache Hadoop: Framework para processamento distribu√≠do de grandes conjuntos de dados. Apache Kafka: Plataforma de streaming distribu√≠do para constru√ß√£o de pipelines de dados em tempo real. Apache Cassandra: Banco de dados distribu√≠do para lidar com grandes quantidades de dados. Apache Spark: Motor de an√°lise unificado para processamento de dados em larga escala. Apache Lucene: Biblioteca de software para recupera√ß√£o de informa√ß√µes e pesquisa de texto completo. Apache Tomcat: Cont√™iner de servlets para aplica√ß√µes web Java. Apache Maven: Ferramenta de automa√ß√£o de compila√ß√£o para projetos Java. Apache HBase: Banco de dados n√£o relacional distribu√≠do para grandes conjuntos de dados. Apache Flink: Framework e mecanismo de processamento de fluxo distribu√≠do. Apache Airflow: Plataforma para programar, coordenar e monitorar fluxos de trabalho. Links: Site Oficial Apache Hadoop Apache Kafka Apache Cassandra Apache Spark Apache Lucene Apache Tomcat Apache Maven Apache HBase Apache Flink Apache Airflow Linux Foundation A Linux Foundation √© conhecida por seu apoio a v√°rios projetos importantes de c√≥digo aberto, incluindo o Linux Kernel, Kubernetes, Hyperledger e Node.js. Eles se concentram em fornecer um lar neutro e apoio para a colabora√ß√£o em tecnologias de c√≥digo aberto, priorizando inova√ß√£o, inclus√£o e desenvolvimento sustent√°vel. Para obter informa√ß√µes detalhadas e uma lista completa dos projetos, recomendo visitar diretamente o site da Linux Foundation: Linux Foundation Projects. Principais Projetos da Linux Foundation: CNCF: Cloud Native Computing Foundation. LF AI: Linux Foundation Artificial Intelligence. LF Edge: Linux Foundation Edge. LF Energy: Linux Foundation Energy. LF Public Health: Linux Foundation Public Health. OpenJS Foundation: OpenJS Foundation. RISC-V: RISC-V. Links: Site Oficial Linux Foundation Projects Resumo Esse artigo discute a carreira em Software Livre, enfatizando a import√¢ncia das quatro liberdades essenciais do movimento: executar, estudar, redistribuir e aperfei√ßoar programas. Ele explora diferentes tipos de licen√ßas, como GPL, LGPL, MIT, Apache, BSD e Mozilla, destacando suas caracter√≠sticas √∫nicas. O texto sugere formas de contribuir com software livre, incluindo c√≥digo, documenta√ß√£o e tradu√ß√£o. Destaca a relev√¢ncia do Software Livre na ind√∫stria de tecnologia, citando exemplos como Linux, Apache e Docker. Al√©m disso, menciona projetos e iniciativas de organiza√ß√µes como CNCF, Apache Software Foundation e Linux Foundation, fornecendo links √∫teis e informa√ß√µes sobre seus projetos e objetivos. " }, { "title": "Quem sou eu?", "url": "/posts/quem-sou-eu/", "categories": "sobre, off-topic", "tags": "sobre, pessoal, rafael-zago, devops, redhat, palestrante, instrutor", "date": "2023-12-04 00:00:00 -0300", "content": "Apresenta√ß√£o Qu√© pasa? Ol√°! N√£o me leve muito a s√©rio, ok? Eu criei esse espa√ßo para compartilhar um pouco do conhecimento que eu tenho e que 90% dele, eu ganhei na internet. Ent√£o j√° passou da hora de devolver um pouco para o mundo. Hoje sou senior software automation engineer na Red Hat, mas j√° passei por algumas empresas (pequenas e grandes) fazendo de tudo um pouco: DevOps de cora√ß√£o e SysAdmin de voca√ß√£o. Criando m√©todos de aprendizagem e estruturando treinamentos. Trabalhei, por muitos anos, com suporte de aplica√ß√µes de v√°rios tamanhos e complexidade. Sou instrutor da Caelum/Alura. Sou padrinho do carinha mais dahora da terra! Sem clubismo‚Ä¶ Comunidades Sou devops de cora√ß√£o e tamb√©m membro da organiza√ß√£o do DevOpsDays SP Organiza√ß√£o do DevOpsDays 2020 Abaixo est√£o as poucas contribui√ß√µes que j√° fiz: Podcasts Hipsters Ponto Tech #239 DNE 224 - Trabalhar para Gringa Talks/Palestras Uma estrat√©gia upstream e downstream para entrega cont√≠nua - Mini DebConf Bras√≠lia!, 2023. Skupper, a cloud h√≠brida com 3 comandos - DevOpsDays Fortaleza, 2022. Take out the rust, transformando time com responsabilidade - DevOpsDays S√£o Paulo, 2019. Desenvolvendo Aplica√ß√µes na Nuvem: Uma Abordagem Pr√°tica - LinuxDay Limeira, 2014 Palestra Linux 101 - Unisal Campinas, 2018 IHC and Security Talk - Unisal Campinas 2018 V√≠deos O que √© Openshift? - Alura " }, { "title": "CI/CD Upstream vs Downstream", "url": "/posts/ci-cd-downstream-upstream/", "categories": "pipeline", "tags": "ci-cd, pipeline, devops, automation, upstream-downstream, redhat, skupper", "date": "2023-06-02 00:00:00 -0300", "content": "Integrando Skupper com Skupper: Uma abordagem upstream e downstream Quando se trata de desenvolvimento de software, integrar projetos upstream e downstream pode ser um desafio. Neste artigo, vamos explorar uma abordagem eficaz para integrar o Skupper e o Skupper, utilizando ferramentas populares para cada lado do desenvolvimento. Introdu√ß√£o O Skupper √© um projeto de software livre que fornece uma solu√ß√£o de rede de servi√ßo para Kubernetes. O Skupper √© desenvolvido pela Red Hat e est√° dispon√≠vel sob a licen√ßa Apache 2.0. Essa √© a vers√£o upstream do Skupper, o que significa que √© a vers√£o que est√° sendo desenvolvida ativamente pela Red Hat. Para os usu√°rios que desejam implantar o Skupper em um ambiente de produ√ß√£o, a Red Hat oferece o Skupper, uma vers√£o comercial do Skupper que √© fornecida pela Red Hat sob o nome de Red Hat AMQ Interconnect. Essa √© a vers√£o downstream do Skupper, o que significa que √© a vers√£o portada para o Red Hat Enterprise Linux e como Opera com o Red Hat OpenShift. Apesar de serem projetos diferentes, o Skupper e o Skupper compartilham uma base de c√≥digo comum e, portanto, √© importante que as altera√ß√µes feitas no Skupper sejam integradas ao RHSI (Red HaT Application Interconnect). Para isso, √© necess√°rio estabelecer um fluxo de trabalho eficiente que permita a integra√ß√£o cont√≠nua entre o Skupper e o RHSI. Definindo o ambiente e as ferramentas Antes de come√ßarmos, vamos configurar nosso ambiente de desenvolvimento. Para o lado downstream, faremos uso das seguintes ferramentas: Jira: uma ferramenta de gerenciamento de projetos que nos ajudar√° a rastrear e organizar as tarefas relacionadas ao desenvolvimento downstream. Confluence: uma plataforma de colabora√ß√£o que usaremos para documentar informa√ß√µes importantes sobre o projeto. Git: um sistema de controle de vers√£o que nos permitir√° gerenciar nosso c√≥digo fonte e colaborar com outros desenvolvedores. Quay.io: um registro de cont√™ineres que nos ajudar√° a armazenar e distribuir nossas imagens de cont√™ineres. Jenkins: uma ferramenta de automa√ß√£o de integra√ß√£o cont√≠nua que nos permitir√° construir, testar e implantar nosso software de forma automatizada. Por outro lado, para o desenvolvimento upstream, faremos uso das seguintes ferramentas: GitHub Issues: um recurso do GitHub que nos ajudar√° a rastrear e gerenciar problemas e solicita√ß√µes de recursos relacionados ao desenvolvimento upstream. CircleCI: uma plataforma de integra√ß√£o cont√≠nua que nos permitir√° construir, testar e validar nosso c√≥digo de forma automatizada. Fluxo de trabalho Agora que nosso ambiente est√° configurado, vamos explorar um fluxo de trabalho b√°sico para a integra√ß√£o cont√≠nua entre o Skupper e o Skupper. Desenvolvimento Upstream Utilize o GitHub Issues para rastrear e gerenciar problemas e solicita√ß√µes de recursos. Fa√ßa uso do CircleCI para construir e testar o c√≥digo do Skupper de forma automatizada. Integra√ß√£o Upstream-Downstream Ap√≥s o desenvolvimento upstream estar pronto, abra uma solicita√ß√£o de pull no reposit√≥rio do Skupper. Uma vez que a solicita√ß√£o de pull seja aprovada, uma nova vers√£o do Skupper √© criada e publicada no Quay.io. Desenvolvimento Downstream Utilize o Jira para criar tarefas relacionadas √†s funcionalidades downstream. Utilize o Git para clonar o c√≥digo fonte do Skupper e iniciar o desenvolvimento downstream. Use o Jenkins para automatizar a constru√ß√£o, teste e implanta√ß√£o do Skupper. Integra√ß√£o Downstream-Upstream Quando necess√°rio, fa√ßa altera√ß√µes no c√≥digo do Skupper e abra uma solicita√ß√£o de pull no reposit√≥rio. Ap√≥s a aprova√ß√£o da solicita√ß√£o de pull, uma nova vers√£o do Skupper √© publicada. Exemplo pr√°tico Para ilustrar o fluxo de trabalho descrito acima, vamos considerar um cen√°rio em que estamos adicionando suporte para um novo protocolo de comunica√ß√£o no Skupper e integrando essa funcionalidade ao Skupper. Desenvolvimento Upstream Abra um problema no GitHub Issues para rastrear a solicita√ß√£o de suporte ao novo protocolo. Escreva o c√≥digo necess√°rio para adicionar o suporte no Skupper. Utilize o CircleCI para construir e testar o c√≥digo automaticamente. Integra√ß√£o Upstream-Downstream Abra uma solicita√ß√£o de pull no reposit√≥rio do Skupper para incorporar as altera√ß√µes. Ap√≥s a aprova√ß√£o da solicita√ß√£o de pull, uma nova vers√£o do Skupper √© publicada no Quay.io. Desenvolvimento Downstream No Jira, crie uma tarefa para adicionar suporte ao novo protocolo no Skupper. Clone o reposit√≥rio do Skupper usando o Git. Adicione o suporte ao novo protocolo no c√≥digo do Skupper. Use o Jenkins para automatizar a constru√ß√£o, teste e implanta√ß√£o do Skupper com as novas altera√ß√µes. Integra√ß√£o Downstream-Upstream Se necess√°rio, fa√ßa altera√ß√µes adicionais no c√≥digo do Skupper e abra uma solicita√ß√£o de pull. Ap√≥s a aprova√ß√£o da solicita√ß√£o de pull, uma nova vers√£o do Skupper √© publicada. Conclus√£o A integra√ß√£o cont√≠nua entre o Skupper e o Skupper √© essencial para garantir que as atualiza√ß√µes do software cheguem aos usu√°rios de forma eficiente, mantendo a viabilidade comercial. Utilizando ferramentas como Jira, Confluence, Git, Quay.io, Jenkins, GitHub Issues e CircleCI, √© poss√≠vel estabelecer um fluxo de trabalho robusto e automatizado que agiliza o desenvolvimento upstream e downstream, permitindo a entrega cont√≠nua de software de alta qualidade. Esperamos que este artigo tenha fornecido insights valiosos sobre a integra√ß√£o upstream e downstream e tenha demonstrado como essas ferramentas podem ser usadas em conjunto para um processo de desenvolvimento mais eficiente. Obrigado por ler e continue explorando as possibilidades de integra√ß√£o cont√≠nua entre projetos de software livre e produtos comerciais! " }, { "title": "Criando uma rede de aplicativos multicloud com Skupper", "url": "/posts/multicloud-com-skupper/", "categories": "cloud, k8s, skupper", "tags": "kubernetes, skupper, cloud, redhat, multicloud, networking, devops", "date": "2022-10-01 00:00:00 -0300", "content": "Refer√™ncias e tecnologias utilizadas: https://skupper.io https://minikube.sigs.k8s.io Reposit√≥rio com os C√≥digos Qpid-dispatch ActiveMQ Kubectl Kubernetes MTLS Open-source Skupper-router Skupper Ferramentas Um computador com o minikube [2] instalado; Um terminal para executar os comandos; kubectl &gt; 1.15 [6] ou mais nova. Descri√ß√£o da solu√ß√£o O Skupper [1] √© uma ferramenta que permite conectar dois ou mais ambientes de cloud de uma maneira n√£o intrusiva e segura. Tais ambientes podem ser de diferentes provedores de servi√ßo em nuvem como: AWS, GCP, AZURE entre outras, e, inclusive, clusters kubernetes nativos. tl;dr Para quem est√° come√ßando com cloud: O Skupper √© uma ferramenta que permite conectar diferentes ambientes de computa√ß√£o em nuvem de maneira segura e sem complica√ß√µes. Imagine que voc√™ tem duas salas diferentes, cada uma com seu pr√≥prio conjunto de ferramentas. Skupper √© como uma porta segura que permite que essas salas ‚Äúconversem‚Äù entre si, compartilhando ferramentas conforme necess√°rio. Isso √© √∫til quando voc√™ tem diferentes partes de um aplicativo rodando em diferentes lugares, mas elas precisam trabalhar juntas como se estivessem no mesmo lugar. Para quem tem algum conhecimento de cloud: O Skupper √© uma solu√ß√£o de rede de servi√ßo para Kubernetes que permite a comunica√ß√£o segura e f√°cil entre clusters. Ele cria uma camada de rede virtual que conecta pods em diferentes clusters como se estivessem na mesma rede local. Isso √© feito sem a necessidade de privil√©gios de administrador do cluster e sem a necessidade de expor servi√ßos √† Internet p√∫blica. Al√©m disso, o Skupper n√£o √© intrusivo com sua aplica√ß√£o, pois n√£o cria side-cars ou outros containers dentro dos Pods. Ele √© open-source e oferece criptografia de ponta a ponta usando certificados digitais. Para quem gosta de escovar bits: O Skupper pode ser dividido em duas partes: o skupper-router e o control-plane chamado skupper-service-controller. O skupper-router √© um roteador de rede de servi√ßo baseado no Qpid-dispatch [4] e no ActiveMQ [5]. O skupper-service-controller √© um controlador Kubernetes que gerencia o skupper-router e fornece uma API para configurar e gerenciar a rede de servi√ßo. Existem outros containers que s√£o usados para configurar e gerenciar o skupper-router, mas eles s√£o apenas auxiliares e n√£o s√£o necess√°rios para o funcionamento do Skupper. Mas isso vai ficar para outro post. Solu√ß√£o Esse exemplo consiste em dois servi√ßos: 1. Frontend Um servi√ßo de backend que exp√µe um endpoint /api/hello. Que tem como resposta Oi, &lt;seu-nome&gt;. Eu sou &lt;meu-nome&gt; (&lt;nome-pod&gt;). O deploy ser√° feito no namespace config_oeste; 2. Backend Um servi√ßo de frontend que exp√µe um endpoint /api/hello que faz uma chamada para o servi√ßo de backend e retorna a resposta, mas nesse caso o servi√ßo esta rodando em outro namespace chama config_leste, este por sua vez pode estar em outro cluster ou namespace. Por que usar o Skupper? Com o Skupper, voc√™ pode colocar o back-end em um cluster e o front-end em outro e manter a conectividade entre os dois servi√ßos sem expor o back-end √† Internet p√∫blica. Detalhes: N√£o √© necess√°rio ter privil√©gios de administrador do cluster, j√° que a solu√ß√£o √© no n√≠vel do namespace; N√£o √© intrusivo com a sua aplica√ß√£o, pois n√£o cria side-cars ou outros containers dentro dos Pods; √â open-source; Voc√™ pode conectar, em seu cluster, servi√ßos externos como: Bancos de dados, aplica√ß√µes legadas e ainda de alta criticidade; Criptografado de ponta a ponta usando certificados digitais; Baixa curva de aprendizagem. MTLS [9] por padr√£o. MTLS √© um protocolo de seguran√ßa que garante que a comunica√ß√£o entre dois pontos seja feita de maneira segura e criptografada. Utiliza√ß√£o de certificados pr√≥prios caso necess√°rio, ou seja, voc√™ pode usar os certificados da sua empresa ou gerar novos certificados para o Skupper ( que √© o padr√£o e s√£o criados automaticamente). Agora vamos preparar nosso ambiente de teste, que consiste no seguinte: Um servi√ßo de backend que est√° rodando em um namespace que vai prover a l√≥gica para outro servi√ßo de frontend que obviamente est√° e outro namespace*. Nesse caso, cada servi√ßo est√° rodando em namespaces diferentes, mas o mesmo exemplo pode (e deve) ser testado com provedores diferentes. 1. Nesse exemplo vamos utilizar dois namespaces chamados: 1.1. config_oeste onde ficar√° o frontend. Lembre-se de abrir uma aba do seu terminal para cada namespace export KUBECONFIG=~/.kube/config-oeste 1.2. config_leste onde ficar√° o backend agora, no outro terminal: export KUBECONFIG=~/.kube/config-leste Obs: Voc√™ pode usar o nome que quiser para os namespaces, mas lembre-se de usar o mesmo nome no arquivo de configura√ß√£o do skupper. 2. Configurando cada namespace: 2.1.config_oeste: kubectl create namespace oeste kubectl config set-context --current --namespace oeste 2.2.config_leste: kubectl create namespace leste kubectl config set-context --current --namespace leste 3. Instalando o Skupper: Voc√™ possui algumas maneiras de instalar o skupper, como por exemplo: Compilar a partir do reposit√≥rio Fazer o download do execut√°vel direto do reposit√≥rio [1] do projeto Usar o script de instala√ß√£o disponibilizado pelo site skupper.io e vamos utilizar esse m√©todo, por ser mais f√°cil de fazer e voc√™ n√£o precisar√° se preocupar com depend√™ncias. 4. Insta√ßa√ß√£o do CLI do Skupper: curl https://skupper.io/install.sh | sh 5. Iniciando o skupper nos dois namespaces: 5.1.config_oeste: skupper init 5.2.config_leste: skupper init 6. Conectando os namespaces: A cria√ß√£o de um link requer o uso de dois comandos skupper em conjunto: skupper token create e skupper link create. O comando skupper token create gera um token secreto que significa permiss√£o para criar um link. O token tamb√©m carrega os detalhes do link. Em seguida, em um namespace remoto, o comando skupper link create usa o token para criar um link para o namespace que o gerou. Nota: O token de link √© realmente um segredo. Qualquer pessoa que tenha o token pode vincular ao seu namespace. Certifique-se de que apenas aqueles em quem voc√™ confia tenham acesso a ele. Por√©m sua utiliza√ß√£o pode ser controlada por n√∫mero de usos e tempo de vida. Veja a documenta√ß√£o do skupper [1] para mais detalhes. 6.1. Criando o token no namespace config_oeste: skupper token create ~/secret.token Token written to ~/secret.token 6.2. Fazendo o link no namespace config_leste ao namespace config_oeste com o token gerado: skupper link create ~/secret.token 7. Fazendo o deploy do frontend e do backend: 7.1. Applicando o YAML para fazer o deploy do frontend no namespace config_oeste: kubectl create deployment frontend --image quay.io/skupper/hello-world-frontend deployment.apps/frontend created 7.2. Applicando o YAML para fazer o deploy do backend no namespace config_leste: kubectl create deployment backend --image quay.io/skupper/hello-world-backend --replicas 3 deployment.apps/backend created 8. Expondo os servi√ßos de backend: Agora que os servi√ßos est√£o rodando, vamos expor os servi√ßos para que possamos acess√°-los. Nesse caso, vamos expor o servi√ßo de backend para que o frontend possa acess√°-lo, independente de onde ele esteja rodando. 8.1. Expondo o servi√ßo de backend no namespace config_leste: skupper expose deployment/backend --port 8080 deployment backend exposed as backend 9. Expondo os servi√ßos de frontend: Agora que os servi√ßos est√£o rodando, vamos expor os servi√ßos para que possamos acess√°-los. Nesse caso, vamos expor o servi√ßo de frontend para que possamos acess√°-lo, independente de onde ele esteja rodando. 9.1. Expondo o servi√ßo de frontend no namespace config_oeste: kubectl expose deployment frontend --port 8080 --type LoadBalancer service/frontend exposed 10. Testando a aplica√ß√£o: Agora que os servi√ßos est√£o rodando, vamos testar a aplica√ß√£o. Nesse caso, vamos acessar o servi√ßo de frontend e verificar se ele consegue acessar o servi√ßo de backend. Para isso, vamos fazer uma chamada para o endpoint /api/health do servi√ßo de frontend e verificar se ele consegue acessar o servi√ßo de backend. 10.1.config_oeste: kubectl get service/frontend NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE frontend LoadBalancer 10.103.232.28 &lt;external-ip&gt; 8080:30407/TCP 15s curl http://&lt;external-ip&gt;:8080/api/health OK 11. Apagando tudo: Pronto! Agora que voc√™ j√° testou o Skupper, vamos apagar tudo para que voc√™ possa testar novamente ou fazer outras experi√™ncias. 11.1. Apagando tudo no namespace config_oeste: skupper delete kubectl delete service/frontend kubectl delete deployment/frontend 11.2. Apagando tudo no namespace config_leste: skupper delete kubectl delete deployment/backend Resumo Este exemplo localiza os servi√ßos de front-end e back-end em namespaces diferentes, em clusters diferentes. Normalmente isso significa que eles n√£o tem como se comunicar, a menos que sejam expostos √† Internet p√∫blica. A introdu√ß√£o do Skupper em cada namespace nos permite criar uma rede de aplicativos virtuais que pode conectar servi√ßos em diferentes clusters. Qualquer servi√ßo exposto na rede de aplicativos √© representado como um servi√ßo local em todos os namespaces vinculados. O servi√ßo de back-end est√° localizado no leste, mas o servi√ßo de front-end no oeste pode ‚Äúv√™-lo‚Äù como se fosse local. Quando o front-end envia uma solicita√ß√£o ao back-end, o Skupper encaminha a solicita√ß√£o para o namespace em que o back-end est√° sendo executado e roteia a resposta de volta ao front-end. N√£o foi necess√°rio expor o servi√ßo de back-end √† Internet p√∫blica. O Skupper criou uma rede de aplicativos que conecta os servi√ßos em diferentes clusters. O servi√ßo de back-end est√° localizado no leste, mas o servi√ßo de front-end no oeste pode ‚Äúv√™-lo‚Äù como se fosse local. Quando o front-end envia uma solicita√ß√£o ao back-end, o Skupper encaminha a solicita√ß√£o para o namespace em que o back-end est√° sendo executado e roteia a resposta de volta ao front-end. Nenhuma VPN ou conex√£o Layer 3 foi necess√°ria. O Skupper cria uma rede de aplicativos que conecta os servi√ßos em diferentes clusters. O servi√ßo de back-end est√° localizado no leste, mas o servi√ßo de front-end no oeste pode ‚Äúv√™-lo‚Äù como se fosse local. Quando o front-end envia uma solicita√ß√£o ao back-end, o Skupper encaminha a solicita√ß√£o para o namespace em que o back-end est√° sendo executado e roteia a resposta de volta ao front-end. " } ]
