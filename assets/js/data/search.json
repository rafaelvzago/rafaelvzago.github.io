[ { "title": "Real-Time Linux: Uma Jornada de Baixa Lat√™ncia", "url": "/posts/RTL-Linux/", "categories": "linux, rtos, tecnologia", "tags": "linux, rtos, redhat, tecnologia", "date": "2024-12-20 00:00:00 -0300", "snippet": "Introdu√ß√£oReal-Time Linux (RTL) √© uma extens√£o do kernel do Linux que transforma o sistema operacional em um ambiente de tempo real. Isso significa que, al√©m de suas funcionalidades tradicionais, e...", "content": "Introdu√ß√£oReal-Time Linux (RTL) √© uma extens√£o do kernel do Linux que transforma o sistema operacional em um ambiente de tempo real. Isso significa que, al√©m de suas funcionalidades tradicionais, ele agora √© capaz de lidar com tarefas que exigem alta previsibilidade e baixa lat√™ncia, como sistemas de automa√ß√£o industrial, dispositivos m√©dicos e at√© sistemas de entretenimento.No final de 2024, o Linux Kernel passou a incorporar totalmente o Real-Time Linux (RTL), marcando um momento hist√≥rico na evolu√ß√£o do sistema. Mas como chegamos at√© aqui?A Jornada do RTLA ideia de adicionar capacidades de tempo real ao Linux remonta ao final dos anos 90, quando surgiram os primeiros patches para otimizar o desempenho e reduzir a lat√™ncia do kernel. Esses patches evolu√≠ram para projetos mais robustos, como o PREEMPT-RT.O PREEMPT-RT permitiu: Preemp√ß√£o total: Tornar poss√≠vel a interrup√ß√£o de quase todas as rotinas do kernel. Redu√ß√£o de lat√™ncias: Melhorar a previsibilidade em execu√ß√µes cr√≠ticas.Depois de anos de desenvolvimento comunit√°rio e apoio de empresas como Red Hat, Intel e IBM, o PREEMPT-RT finalmente foi fundido no kernel principal, consolidando o Linux como uma plataforma RTOS (Sistema Operacional de Tempo Real).Compara√ß√£o: Workload RTL vs. Workload NormalPara cargas de trabalho t√≠picas com requisitos de lat√™ncia do kernel na faixa de milissegundos (ms), o kernel padr√£o do Red Hat Enterprise Linux 7 √© suficiente. No entanto, se sua carga de trabalho exige requisitos rigorosos de determinismo de baixa lat√™ncia para recursos centrais do kernel, como manipula√ß√£o de interrup√ß√µes e escalonamento de processos na faixa de microssegundos (Œºs), o kernel de tempo real √© a escolha ideal.Refer√™nciaModelos de Preemp√ß√£o no LinuxOs modelos de preemp√ß√£o do Linux determinam como o kernel gerencia interrup√ß√µes e tarefas. Esses modelos s√£o definidos no momento da compila√ß√£o do kernel, sendo o ‚ÄúKernel Totalmente Preempt√≠vel‚Äù essencial para obter o comportamento em tempo real. Abaixo est√° uma descri√ß√£o dos principais modelos: Sem Preemp√ß√£o For√ßada (Servidor): Modelo tradicional focado em maximizar a taxa de transfer√™ncia. Os pontos de preemp√ß√£o ocorrem apenas em retornos de chamadas de sistema e interrup√ß√µes. Preemp√ß√£o Volunt√°ria (Desktop): Reduz a lat√™ncia do kernel adicionando pontos de preemp√ß√£o expl√≠citos no c√≥digo, em troca de uma leve queda na taxa de transfer√™ncia. Kernel Preempt√≠vel (Desktop de Baixa Lat√™ncia): Faz com que todo o c√≥digo do kernel, exceto se√ß√µes cr√≠ticas, seja preempt√≠vel, com pontos de preemp√ß√£o impl√≠citos ap√≥s cada desativa√ß√£o de preemp√ß√£o. Kernel Preempt√≠vel (RT B√°sico): Similar ao modelo ‚ÄúDesktop de Baixa Lat√™ncia‚Äù, mas com manipuladores de interrup√ß√µes em threads. Esse modelo √© usado para testes e depura√ß√£o. Kernel Totalmente Preempt√≠vel (RT): Todo o c√≥digo do kernel √© preempt√≠vel, exceto em se√ß√µes cr√≠ticas selecionadas. Inclui manipuladores de interrup√ß√µes em threads e mecanismos como spinlocks dorm√™ntes e rt_mutex para minimizar se√ß√µes n√£o preempt√≠veis, garantindo comportamento em tempo real.Onde o Real-Time Linux pode ser Aplicado?As aplica√ß√µes s√£o diversas, mas geralmente se concentram em cen√°rios que exigem desempenho cr√≠tico: Automotivo: Sistemas de freios e controle de motores. Industrial: Rob√≥tica e automa√ß√£o. Telecomunica√ß√µes: Redes 5G que requerem baixa lat√™ncia para processamento de pacotes. Entretenimento: Mixagem de √°udio em tempo real. Sa√∫de: Equipamentos m√©dicos sens√≠veis ao tempo.Exemplo Pr√°tico: Testando o Kernel PREEMPT-RTEntendendo o PREEMPT-RTO PREEMPT-RT √© um conjunto de patches aplicados ao kernel Linux que permite transformar o sistema operacional em um ambiente de tempo real. Este modelo de preemp√ß√£o reduz drasticamente a lat√™ncia ao substituir os mecanismos de sincroniza√ß√£o convencionais por variantes que suportam preemp√ß√£o. Ele tamb√©m implementa mecanismos para dividir se√ß√µes cr√≠ticas longas e for√ßar o encadeamento de manipuladores de interrup√ß√£o.Recursos principais do PREEMPT-RT: Threading de Interrup√ß√µes: Todas as interrup√ß√µes s√£o executadas como threads agend√°veis, permitindo que o sistema priorize e gerencie tarefas em tempo real. Spinlocks Preempt√≠veis: Substitui spinlocks padr√£o por variantes que permitem preemp√ß√£o, minimizando atrasos durante o bloqueio de recursos compartilhados. Heran√ßa de Prioridade: Implementa√ß√£o de mutexes que evitam problemas de invers√£o de prioridade, garantindo que tarefas cr√≠ticas recebam os recursos necess√°rios no momento certo. Fragmenta√ß√£o de Se√ß√µes N√£o Preempt√≠veis: Reduz o tempo de bloqueio em c√≥digo cr√≠tico, quebrando longas se√ß√µes n√£o preempt√≠veis em peda√ßos menores.Esses recursos tornam o kernel Linux altamente responsivo e adequado para sistemas que exigem previsibilidade e baixa lat√™ncia, como aplica√ß√µes em rob√≥tica, telecomunica√ß√µes e equipamentos m√©dicos.A seguir, apresentamos um exemplo de como configurar e testar um kernel com suporte a PREEMPT-RT. Essas instru√ß√µes foram realizadas em uma m√°quina virtual Ubuntu 22.04 LTS.Passos:1. Obter o c√≥digo do kernel mais recente:git clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.gitcd linux2. Configurar o kernel para PREEMPT-RT:make menuconfigNavegue at√© General Setup / Preemption Model e ative a op√ß√£o Fully Preemptible Kernel (Real-Time). Salve e saia.Verifique se a configura√ß√£o foi aplicada:grep PREEMPT_RT .config# Sa√≠da esperada: CONFIG_PREEMPT_RT=y3. Compilar o kernel:time make -j$(nproc)4. Instalar e reiniciar:sudo make modules_install &amp;&amp; sudo make installsudo rebootSelecione o novo kernel na inicializa√ß√£o.5. Confirmar a vers√£o:cat /proc/version# Exemplo de sa√≠da:# Linux version 6.11.0-rtl+ (gcc (Ubuntu 11.4.0) 11.4.0) #1 SMP PREEMPT_RT Fri Sep 20 19:11:35 IST 2024Agora o kernel est√° configurado para suportar tarefas de tempo real. Para verificar sua efici√™ncia, execute aplicativos em tempo real como mixagem de √°udio com JACK ou PulseAudio.Como Configurar o Red Hat Enterprise Linux for Real TimeO Red Hat Enterprise Linux for Real Time (RHEL-RT) oferece um conjunto de ferramentas e configura√ß√µes otimizadas para aplica√ß√µes sens√≠veis √† lat√™ncia. Seguem os passos para configurar e aproveitar ao m√°ximo o RHEL-RT:1. Pr√©-requisitos Certifique-se de que sua subscri√ß√£o Red Hat inclui o canal do RHEL for Real Time. Atualize seu sistema:sudo dnf update -y2. Instala√ß√£o do Kernel RTInstale o kernel otimizado para tempo real:sudo dnf install kernel-rt kernel-rt-devel3. Sele√ß√£o do Kernel RT no BootloaderDepois de instalar o kernel, configure o bootloader para usar o kernel RT como padr√£o:grub2-set-default \"Red Hat Enterprise Linux (kernel-rt)\"sudo grub2-mkconfig -o /boot/grub2/grub.cfgsudo reboot4. Ajustes de Lat√™nciaAp√≥s reiniciar no kernel RT, use ferramentas como tuna para ajustar prioridades e afinidades de CPU:sudo tuna -t irq -qsudo tuna -t \"[sua aplica√ß√£o]\" -p 99Configure o particionamento da CPU para isolar n√∫cleos dedicados a tarefas de tempo real:echo 1 &gt; /sys/devices/system/cpu/cpu[X]/isolated5. Ferramentas de Diagn√≥sticoUtilize ferramentas como cyclictest para medir a lat√™ncia:sudo cyclictest -m -Sp99 -i100 -h300 -qComo o RTL foi Implementado pela Red Hat?A Red Hat contribuiu de forma significativa para a integra√ß√£o do PREEMPT-RT no kernel principal. No Red Hat Enterprise Linux for Real Time, v√°rias otimiza√ß√µes foram feitas para: Otimizar lat√™ncias: Ajustes no agendador e gerenciamento de interrup√ß√µes. Ferramentas especializadas: Perfis de kernel personalizados e ferramentas como tuna para ajustar prioridades em tempo real. Seguran√ßa: Garantir que as modifica√ß√µes n√£o comprometem a estabilidade do sistema.Conclus√£oA inclus√£o do Real-Time Linux no kernel principal marca um ponto de virada para o Linux como um sistema operacional universal. Agora, ele √© capaz de atender tanto aplica√ß√µes convencionais quanto ambientes que exigem alt√≠ssima previsibilidade.Seja voc√™ um desenvolvedor interessado em explorar o potencial do Linux em sistemas embarcados ou um entusiasta de tecnologia, o RTL abre novas portas para inova√ß√µes em diversas √°reas.Refer√™ncias Linux Foundation. ‚ÄúReal-Time Linux Documentation.‚Äù Dispon√≠vel em: https://wiki.linuxfoundation.org/realtime/documentation/start. Acesso em: 20 dez. 2024. Linux Foundation. ‚ÄúKernel PREEMPT-RT.‚Äù Dispon√≠vel em: https://wiki.linuxfoundation.org/realtime/documentation/technical_basics/preemption_models. Acesso em: 20 dez. 2024. Red Hat. ‚ÄúRed Hat Enterprise Linux for Real Time.‚Äù Dispon√≠vel em: https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/7/html/installation_guide/chap-why_use_rt_to_optimize_latency#chap-Why_Use_RT_to_Optimize_Latency. Acesso em: 20 dez. 2024. Kaiwan N Billimoria. ‚ÄúThe Linux Kernel is Now an RTOS.‚Äù Blog Kaiwan Tech. Dispon√≠vel em: https://kaiwantech.wordpress.com/2024/09/21/the-linux-kernel-is-now-an-rtos-with-rtl-being-fully-merged/. Acesso em: 20 dez. 2024." }, { "title": "TCP/IP O in√≠cio e a evolu√ß√£o", "url": "/posts/protocolos-TCP-IP-o-inicio/", "categories": "networking, tcpip", "tags": "networking, tcpip, tecnologia", "date": "2024-12-14 00:00:00 -0300", "snippet": "Protocolos TCP/IP: Uma Introdu√ß√£o CompletaO ARPANET e as Origens do TCP/IPA hist√≥ria dos protocolos TCP/IP come√ßa no final dos anos 1950, durante o auge da Guerra Fria. O Departamento de Defesa dos...", "content": "Protocolos TCP/IP: Uma Introdu√ß√£o CompletaO ARPANET e as Origens do TCP/IPA hist√≥ria dos protocolos TCP/IP come√ßa no final dos anos 1950, durante o auge da Guerra Fria. O Departamento de Defesa dos EUA (DoD) buscava uma rede de comando e controle que pudesse sobreviver a um ataque nuclear. Na √©poca, as comunica√ß√µes militares utilizavam a rede telef√¥nica p√∫blica, considerada vulner√°vel devido √† sua hierarquia r√≠gida e falta de redund√¢ncia.In√≠cio da Pesquisa e Contribui√ß√µes de Paul BaranEm torno de 1960, o DoD contratou a RAND Corporation para encontrar uma solu√ß√£o. Paul Baran prop√¥s um design distribu√≠do altamente tolerante a falhas, que usava tecnologia de comuta√ß√£o de pacotes digitais em vez de sinais anal√≥gicos. Apesar da resist√™ncia inicial de grandes empresas como a AT&amp;T, a ideia de Baran lan√ßou as bases para as redes resilientes modernas.O Papel da ARPAEm resposta ao lan√ßamento do sat√©lite Sputnik pela Uni√£o Sovi√©tica em 1957, o governo dos EUA criou a ARPA (Advanced Research Projects Agency). A ARPA iniciou esfor√ßos em redes de computadores para promover a pesquisa cient√≠fica e tecnol√≥gica. Larry Roberts, um dos gerentes da ARPA, decidiu construir uma rede baseada em comuta√ß√£o de pacotes, influenciado pelo trabalho de Paul Baran e Donald Davies.Estrutura do ARPANETA ARPANET foi projetada como uma rede de sub-redes de comuta√ß√£o de pacotes composta por minicomputadores chamados IMPs (Interface Message Processors). Esses IMPs, conectados por linhas de transmiss√£o de 56 kbps, formaram a primeira rede eletr√¥nica de comuta√ß√£o de pacotes que utilizava o m√©todo de armazenamento e encaminhamento para transmitir dados de forma confi√°vel.Cada n√≥ da rede era composto por um IMP e um host, conectados localmente por fios curtos. Mensagens de at√© 8063 bits eram divididas em pacotes menores e transmitidas de forma independente, permitindo o roteamento din√¢mico caso partes da rede fossem destru√≠das. A rede foi projetada para ser resiliente, com cada IMP conectado a pelo menos dois outros, garantindo redund√¢ncia.Crescimento e ImpactoA ARPANET entrou em opera√ß√£o em dezembro de 1969 com quatro n√≥s iniciais: UCLA, UCSB, SRI e a Universidade de Utah. Em poucos anos, a rede cresceu rapidamente, conectando mais institui√ß√µes e redes. Durante os anos 1980, a integra√ß√£o de novas redes e a cria√ß√£o do DNS (Domain Name System) facilitaram o gerenciamento de endere√ßos e nomes de host.Essa expans√£o culminou na cria√ß√£o dos protocolos TCP/IP, projetados para interconectar redes heterog√™neas. Contratos foram estabelecidos com universidades e empresas para implementar os protocolos em diferentes plataformas, consolidando o TCP/IP como padr√£o global de comunica√ß√£o em redes.Introdu√ß√£o ao Modelo TCP/IPOs protocolos TCP/IP (Transmission Control Protocol/Internet Protocol) formam a espinha dorsal da comunica√ß√£o na internet moderna. Este artigo fornece uma revis√£o abrangente sobre os protocolos, suas camadas e como eles trabalham juntos para permitir a transmiss√£o de dados em redes locais e globais.O Modelo TCP/IP: Introdu√ß√£o e Primeira CamadaO modelo TCP/IP √© um framework fundamental para a comunica√ß√£o de dados em redes modernas, estruturado em quatro camadas principais. Cada camada desempenha uma fun√ß√£o espec√≠fica, permitindo que os dados sejam transmitidos de forma eficiente e confi√°vel. Neste artigo, come√ßaremos com uma an√°lise detalhada da primeira camada: Camada de Aplica√ß√£o.Camada de Aplica√ß√£o: A Interface do Usu√°rioA Camada de Aplica√ß√£o no modelo TCP/IP representa o ponto de contato direto entre os usu√°rios e a rede. Ela oferece as ferramentas e protocolos necess√°rios para que aplicativos e servi√ßos possam interagir com o sistema de comunica√ß√£o. Esta camada traduz solicita√ß√µes e respostas de aplica√ß√µes em dados compreens√≠veis pelas camadas inferiores do modelo.Essa camada tamb√©m √© conhecida como a Camada 7 no modelo OSI (Open Systems Interconnection), que √© um modelo de refer√™ncia semelhante ao TCP/IP. No entanto, o modelo TCP/IP √© mais amplamente utilizado e mais diretamente relacionado √† arquitetura da internet.Funcionalidades Principais Intera√ß√£o com Aplica√ß√µes: Oferece servi√ßos que permitem que aplicativos de software utilizem a rede para transmitir dados. Processamento de Dados: Manipula a estrutura dos dados para garantir compatibilidade com protocolos de transporte. Servi√ßos de Rede: Facilita a implementa√ß√£o de servi√ßos espec√≠ficos, como transfer√™ncia de arquivos, envio de e-mails e navega√ß√£o na web.Exemplos de Protocolos na Camada de Aplica√ß√£o HTTP/HTTPS (Hypertext Transfer Protocol): Facilita a comunica√ß√£o entre navegadores e servidores web, essencial para a navega√ß√£o na internet. FTP (File Transfer Protocol): Utilizado para a transfer√™ncia de arquivos entre computadores. SMTP (Simple Mail Transfer Protocol): Gerencia o envio de e-mails. DNS (Domain Name System): Resolve nomes de dom√≠nio em endere√ßos IP.Estrutura T√©cnicaOs protocolos na Camada de Aplica√ß√£o n√£o apenas facilitam a comunica√ß√£o, mas tamb√©m incorporam funcionalidades como autentica√ß√£o, compress√£o e criptografia. Por exemplo, o HTTPS adiciona seguran√ßa ao HTTP usando o protocolo SSL/TLS para criptografar dados transmitidos.Modelo de DadosOs dados processados nesta camada s√£o encapsulados e formatados em mensagens, que ser√£o transmitidas para a pr√≥xima camada. A seguir, est√° o fluxo de dados t√≠pico dentro da camada de aplica√ß√£o:Aplica√ß√µes no Dia a DiaA Camada de Aplica√ß√£o √© amplamente utilizada por programas que fazem parte do nosso cotidiano: Navegadores Web: Ao acessar um site, como ‚Äúwww.example.com‚Äù, o navegador utiliza o HTTP ou HTTPS para enviar solicita√ß√µes e receber respostas do servidor web. Clientes de E-mail: Programas como Microsoft Outlook ou Thunderbird utilizam protocolos como SMTP, IMAP ou POP3 para enviar e receber mensagens. Streaming de V√≠deo: Servi√ßos como Netflix e YouTube empregam protocolos como HTTP/HTTPS para entrega de v√≠deos, muitas vezes utilizando redes de distribui√ß√£o de conte√∫do (CDN). Aplicativos de Mensagens: WhatsApp e Telegram utilizam protocolos de comunica√ß√£o baseados em HTTP/HTTPS e outros servi√ßos da camada de aplica√ß√£o para troca de mensagens instant√¢neas e arquivos. Jogos Online: Muitos jogos dependem de APIs baseadas em HTTP/HTTPS para autentica√ß√£o e sincroniza√ß√£o de dados, al√©m de outros protocolos espec√≠ficos.Import√¢ncia na Arquitetura de RedesA Camada de Aplica√ß√£o √© considerada cr√≠tica porque estabelece os fundamentos para a intera√ß√£o humano-computador nas redes. Sem esta camada, o uso pr√°tico da internet seria imposs√≠vel, pois n√£o haveria um meio eficaz de traduzir as inten√ß√µes humanas em solicita√ß√µes process√°veis pela rede.Testando a Camada de Aplica√ß√£o com PythonPara demonstrar a funcionalidade da Camada de Aplica√ß√£o, podemos realizar um teste pr√°tico utilizando um script em Python que simula uma solicita√ß√£o HTTP para um servidor web. Aqui est√° o c√≥digo:# Importar a biblioteca de sockets para comunica√ß√£o de redeimport socket# Fun√ß√£o para testar a camada de aplica√ß√£o usando o protocolo HTTPdef test_application_layer(host: str, port: int): \"\"\"Fun√ß√£o para testar a camada de aplica√ß√£o usando o protocolo HTTP.\"\"\" try: # Criar um socket para comunica√ß√£o com o servidor with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as client_socket: # Conectar ao servidor especificado pelo host e porta client_socket.connect((host, port)) # Preparar uma solicita√ß√£o HTTP GET simples http_request = f\"GET / HTTP/1.1\\r\\nHost: {host}\\r\\nConnection: close\\r\\n\\r\\n\" # Enviar a solicita√ß√£o HTTP para o servidor client_socket.sendall(http_request.encode()) # Receber a resposta do servidor em partes (chunks) response = b\"\" while True: # Receber um chunk de dados do servidor chunk = client_socket.recv(4096) # Se n√£o houver mais dados, interromper o loop if not chunk: # Se n√£o houver mais dados, interromper o loop break # Adicionar o chunk recebido √† resposta completa response += chunk # Exibir a resposta completa do servidor no console print(\"Resposta do Servidor:\") # Decodificar a resposta bin√°ria em texto print(response.decode()) except Exception as e: # Capturar e exibir qualquer erro que ocorra durante o teste print(f\"Erro ao testar a camada de aplica√ß√£o: {e}\")# Testar a fun√ß√£o com um servidor HTTP espec√≠ficotest_application_layer(\"www.example.com\", 80)Output EsperadoQuando executado, o script realiza uma solicita√ß√£o HTTP para www.example.com e exibe a resposta do servidor. O output ser√° semelhante ao seguinte:$ python aplicacao.pyResposta do Servidor:HTTP/1.1 200 OKAge: 119377Cache-Control: max-age=604800Content-Type: text/html; charset=UTF-8Date: Sat, 14 Dec 2024 03:53:09 GMTEtag: \"3147526947+ident\"Expires: Sat, 21 Dec 2024 03:53:09 GMTLast-Modified: Thu, 17 Oct 2019 07:18:26 GMTServer: ECAcc (mid/8790)Vary: Accept-EncodingX-Cache: HITContent-Length: 1256Connection: close&lt;!doctype html&gt;&lt;html&gt;...Essa demonstra√ß√£o pr√°tica destaca como os protocolos na Camada de Aplica√ß√£o, como HTTP, facilitam a comunica√ß√£o entre clientes e servidores em redes modernas. Sem esta camada, o uso pr√°tico da internet seria imposs√≠vel, pois n√£o haveria um meio eficaz de traduzir as inten√ß√µes humanas em solicita√ß√µes process√°veis pela rede.Refer√™ncias Tanenbaum, A. S., &amp; Wetherall, D. J. (2011). Computer Networks. Baran, P. (1964). On Distributed Communications: Introduction to Distributed Communications Network. Roberts, L. (1967). Multiple Computer Networks and Intercomputer Communication. Braden, R. (1989). RFC 1122: Requirements for Internet Hosts - Communication Layers. Clark, D. D. (1988). The Design Philosophy of the DARPA Internet Protocols. Cerf, V., &amp; Kahn, R. E. (1974). A Protocol for Packet Network Intercommunication.Pr√≥ximos PassosNos pr√≥ximos artigos, exploraremos as camadas subsequentes do modelo TCP/IP, detalhando suas fun√ß√µes e protocolos associados. A pr√≥xima ser√° a Camada de Transporte, onde examinaremos o papel do TCP e UDP na comunica√ß√£o confi√°vel e eficiente." }, { "title": "Running local AI with Instruct Lab and Skupper", "url": "/posts/running-local-ai-with-instruct-lab/", "categories": "skupper, instructlab, chatbot", "tags": "cloud, network, redhat", "date": "2024-08-01 00:00:00 -0300", "snippet": "Welcome to the Ollama Pilot.Problem to solveThe main goal of this project is to create a secure connection between two sites, enabling the communication between the engineer machine and an Instruct...", "content": "Welcome to the Ollama Pilot.Problem to solveThe main goal of this project is to create a secure connection between two sites, enabling the communication between the engineer machine and an Instruct Lab Model. The merlinite-7b-lab-Q4_K_M.gguf model will be used for the chatbot, and it is available in the Instruct Lab. The license of the model is available in the Instruct Labs.But, why the banner? Well, the engineer needs to know who is better, Lebron or Jordan. The chatbot will be responsible for answering this question. The chatbot will receive the user input and send it to the llama3 model. The response from the merlinite model will be sent back to the user.Disclaimer All the models used are available in the Hugging Face model hub. The models are not hosted in this project, they are hosted by Hugging Face. The models are used for educational purposes only.Why InstructLabThere are many projects rapidly embracing and extending permissively licensed AI models, but they are faced with three main challenges: Contribution to LLMs is not possible directly. They show up as forks, which forces consumers to choose a ‚Äúbest-fit‚Äù model that isn‚Äôt easily extensible. Also, the forks are expensive for model creators to maintain. The ability to contribute ideas is limited by a lack of AI/ML expertise. One has to learn how to fork, train, and refine models to see their idea move forward. This is a high barrier to entry. There is no direct community governance or best practice around review, curation, and distribution of forked models.This snippet was extracted from the Instruct Labs repository.Why SkupperHere the answer is simple, Skupper is a tool that enables secure communication between services in different environments. Skupper will be used to create a secure connection between the two sites, one of the sites has restricted access to the internet. Skupper will enable the communication between the two sites, allowing the Ollama Pilot application to send requests to the llama3 model thru the Instruct Lab chat.DescriptionThis project has the objective to create a VAN (Virtual Application Network) that enables the connection between two sites: Site A: A server that hosts the Instruct Lab chat model. This model will be responsible for receiving the user input and sending it to the llama3 model. The response from the llama3 model will be sent back to the user. Site B: An OpenShift site that exposes the Instruct Lab chat model. This site will be responsible for sending the user input to the Instruct Lab chat model and receiving the response from the Merlinite-7b-lab-Q4_K_M.gguf model. In order to connect the two sites, we will use Skupper, a tool that enables secure communication between services in different environments. Skupper will be used to create a secure connection between the two sites, allowing the Ollama Pilot application to send requests to the llama3 model and receive the response from the merlinite model.At the end of the project, you will be able to use your own CHATBOT with protected data.ArchitectureSummary AI model deployment with InstructLab Private Skupper deployment Public Skupper deployment Secure communication between the two sites with Skupper Chatbot with protected data1. AI model deployment with InstructLabThe first step is to deploy the InstructLab chat model in the InstructLab site. The InstructLab chat model will be responsible for receiving the user input and sending it to the llama3 model. The response from the llama3 model will be sent back to the user. This is based on the article: Getting started with InstructLab for generative AI model tuningmkdir instructlab &amp;&amp; cd instructlab python3.11 -m venv venv source venv/bin/activatepip install 'instructlab[cuda]' -C cmake.args=\"-DLLAMA_CUDA=on\" -C cmake.args=\"-DLLAMA_NATIVE=off\" IMPORTANT: This installation method will enable your Nvidia GPU to be used by instructlab. If you don‚Äôt have an Nvidia GPU, please check other options in: InstructLab üê∂ (ilab)ilab config initTo enable external access to your model, please modify the config.yaml file:chat: context: default greedy_mode: false logs_dir: data/chatlogs max_tokens: null model: models/merlinite-7b-lab-Q4_K_M.gguf session: null vi_mode: false visible_overflow: truegeneral: log_level: INFOgenerate: chunk_word_count: 1000 model: models/merlinite-7b-lab-Q4_K_M.gguf num_cpus: 10 num_instructions: 100 output_dir: generated prompt_file: prompt.txt seed_file: seed_tasks.json taxonomy_base: origin/main taxonomy_path: taxonomyserve: gpu_layers: -1 host_port: 0.0.0.0:8000 # HERE max_ctx_size: 4096 model_path: models/merlinite-7b-lab-Q4_K_M.ggufNow, you can download and start your server:ilab model downloadilab model serve# The output should be similar to:INFO 2024-07-30 18:59:01,199 serve.py:51: serve Using model 'models/merlinite-7b-lab-Q4_K_M.gguf' with -1 gpu-layers and 4096 max context size.INFO 2024-07-30 18:59:01,611 server.py:218: server Starting server process, press CTRL+C to shutdown server...INFO 2024-07-30 18:59:01,612 server.py:219: server After application startup complete see http://0.0.0.0:8000/docs for API.2. Private Skupper deploymentThe second step is to deploy the private Skupper in Site A. The private Skupper will be responsible for creating a secure connection between the two sites, allowing the Ollama Pilot application to send requests to the llama3 model and receive the response from the merlinite model. Open a new terminal and run the following commands:Install Skupperexport SKUPPER_PLATFORM=podmanskupper init --ingress noneExposing the InstructLab chat modelIn order to do this, we will bind the local service that is running the InstructLab chat model to the Skupper service.skupper expose host host.containers.internal --address instructlab --port 8000Let‚Äôs check the status of the Skupper service:skupper service statusServices exposed through Skupper:‚ï∞‚îÄ instructlab:8000 (tcp)Now, we are almost ready to connect the two sites. The next step is to deploy the public Skupper in Site B and create a connection between the two sites.3. Public Skupper deploymentThe third step is to deploy the public Skupper in Site B. The public Skupper will receive the connection from the private Skupper and create a secure connection between the two sites. Open a new terminal and run the following commands: Creating the project and deploying the public Skupper:oc new-project ollama-pilotskupper init --enable-console --enable-flow-collector --console-user admin --console-password admin Creating the token to allow the private Skupper to connect to the public Skupper:skupper token create token.yamlAt this point, you should have a token.yaml file with the token to connect the two sites. The next step is to link the two sites. For this, we will need to switch back to the terminal where the private Skupper is running.4. Secure communication between the two sites with SkupperThe fourth step is to connect the two sites. In the terminal where the private Skupper is running, run the following command:skupper link create token.yaml --name instructlab # Or any other name you wantLet‚Äôs check the status of the Skupper link:skupper link statusLinks created from this site: Link instructlab is connectedCurrent links from other sites that are connected: There are no connected links Before continuing, let‚Äôs hop back to the terminal where the public Skupper is running and check the status of the link:skupper link statusLinks created from this site: There are no links configured or connectedCurrent links from other sites that are connected: Incoming link from site b8ad86d5-9680-4fea-9c07-ea7ee394e0bd5. Chatbot with protected dataNow the last part is to expose the service in the public Skupper and create the Ollama Pilot application. Still on the terminal where the public Skupper is running, run the following command to expose the service. With the following command, we will create a Skupper service that matches the service exposed by the private Skupper. This will end up creating a Kubernetes service that will be used by the Ollama Pilot application.skupper service create instructlab 8000 Exposing the service to the internet:oc expose service instructlab Getting the public URL:oc get route instructlabNAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARDinstructlab instructlab-ollama-pilot.apps.your-cluster-url instructlab port8000 None The last step is to create the Ollama Pilot application. The Ollama Pilot application will be responsible for sending the user input to the Instruct Lab chat model and receiving the response from the Merlinite-7b-lab-Q4_K_M.gguf model. The Ollama Pilot application will be able to send requests to the Instruct Lab chat model through the secure connection created by Skupper.You can repeat all the instructions in step 1. AI model deployment with InstructLab to install the Instruct Lab chat model in Site B. The only difference is that you will not run the ilab model serve command because the Instruct Lab chat model is already running in Site A.The Ollama Pilot application will be responsible for sending the user input to the Instruct Lab chat model and receiving the response from the Merlinite-7b-lab-Q4_K_M.gguf model. The Ollama Pilot application will be able to send requests to the Instruct Lab chat model through the secure connection created by Skupper.ilab model chat --endpoint-url http://instructlab-ollama-pilot.apps.your-cluster-url/v1/‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ system ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Welcome to InstructLab Chat w/ MODELS/MERLINITE-7B-LAB-Q4_K_M.GGUF (type /h for help)‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ&gt;&gt;&gt; [S][default]THE question: Yes or No question. Don‚Äôt fool me. Is LeBron better than Jordan?Have fun with your new chatbot with protected data! If you don‚Äôt agree with the answer, you can always ask again and train your model, but King James is the best!" }, { "title": "Vim Motions: Navigating and Editing Code Efficiently", "url": "/posts/vim-motions/", "categories": "vim, productivity", "tags": "vim, developer", "date": "2024-07-02 14:31:00 -0300", "snippet": "Vim Motions: Your Keyboard Shortcut PowerhouseVim motions are a set of commands that empower you to navigate and edit code like a pro. This guide dives into different Vim motions and how to harness...", "content": "Vim Motions: Your Keyboard Shortcut PowerhouseVim motions are a set of commands that empower you to navigate and edit code like a pro. This guide dives into different Vim motions and how to harness them for lightning-fast coding.My Vim Journey: From VSCode and IntelliJ to NeovimAfter years of using VSCode and IntelliJ, I decided to make the switch to Neovim as my primary development tool. This series of posts will document my journey and share the tips, tricks, and configurations that have made Neovim an indispensable part of my workflow.Today, we‚Äôre starting with the foundation: Vim motions. Mastering these commands is key to unlocking the full potential of Vim‚Äôs editing power.Disclaimer: This is not meant to be a flamewar about editors. It‚Äôs simply a reflection of what has worked best for me and an invitation for you to explore if Vim might be a good fit for your own development style.Vim Plugins: My Productivity ArsenalOne of the things that makes Vim (and Neovim) so powerful is the ability to customize it with plugins. Here are some of the plugins I rely on for maximum productivity: ‚ÄúVundle.vim‚Äù ‚Äúundotree‚Äù ‚Äúvim-fugitive‚Äù ‚Äúgruvbox‚Äù ‚Äúcopilot.vim‚Äù ‚Äúvim-log-highlighting‚Äù ‚Äúnerdtree‚Äù ‚Äúlightline.vim‚Äù ‚Äúvim-gitbranch‚Äù ‚Äúvim-terraform‚Äù ‚Äúvim-go‚Äù ‚Äúfzf‚Äù ‚Äúale‚Äù ‚Äúfzf.vim‚Äù ‚Äúvim-tmux-navigator‚Äù(Complete plugin setup and details will be covered in future posts.)The Vim Editor: More Than Meets the EyeVim is a highly customizable text editor known for its modal nature. Its modes ‚Äì Normal, Insert, and Visual ‚Äì cater to distinct tasks, allowing you to switch seamlessly between command input and text editing.Vim Plugins: Supercharge Your Vim ExperienceVim‚Äôs capabilities extend far beyond its core features. With a vast array of community-maintained plugins, you can transform Vim into a full-fledged Integrated Development Environment (IDE).Vim Motions in ActionBy mastering Vim motions, you‚Äôll write and navigate code with impressive speed. Even popular IDEs like VS Code offer Vim plugins, enabling you to leverage Vim‚Äôs navigation within your preferred environment.Vim Modes: Normal Mode: Your command center for issuing instructions. Insert Mode: Where the actual code writing happens. Visual Mode: Select and manipulate text visually, with options for both normal and block selection.Vim also has a leader key for creating custom shortcuts, and a command mode for operations like saving files.Navigating Your CodebaseLet‚Äôs dive into a React app and explore how Vim motions streamline navigation: Basic Movements (h, j, k, l): Forget arrow keys! Use these for left, down, up, and right movement. Prefix with a number (e.g., 5j) to move multiple lines. Word Navigation (w, b, e): Jump forward (w), backward (b), or to the end (e) of words. Use a number prefix for multiple word jumps. Line Navigation (0, ^, g, $, f, F): Go to the start (0), first non-blank character (^), end ($), or search for a character (f forward, F backward). Vertical Navigation ((), {}, Ctrl+D/U, Ctrl+F/B, G): Navigate by sentences (( and )), paragraphs ({ and }), half pages (Ctrl+D, Ctrl+U), full pages (Ctrl+F, Ctrl+B), start of file (gg), and end of file (G). Entering Insert Mode: Multiple Entry PointsVim offers various ways to enter insert mode: Before cursor: i After cursor: a Beginning of line: I End of line: A Below current line: o Above current line: OOther insert mode triggers include c (change), s (substitute), y (yank/copy), and p (paste). You can even copy entire lines with yy.Learning MoreVim‚Äôs learning curve can be steep, but the rewards are immense. To deepen your knowledge: Vim Documentation: https://vimdoc.sourceforge.io/index.html Vim Tutorial: https://www.tutorialspoint.com/vim/vim_tutorial.htm Vim Cheat Sheet: https://www.vim.org/doc/vimtutor/vimtutor.pdfHappy Vimming!" }, { "title": "Workshop: Patient Portal, conectando um banco de dados a um cluster K8S com Skupper", "url": "/posts/workshop-skupper-patient-portal/", "categories": "skupper, multi, cloud, network, redhat", "tags": "cloud, network, redhat", "date": "2024-07-02 00:00:00 -0300", "snippet": "Descri√ß√£oEste workshop tem como objetivo apresentar o Red Hat Service Interconnect, uma solu√ß√£o de integra√ß√£o de aplica√ß√µes que permite a comunica√ß√£o entre diferentes sistemas de forma eficiente e ...", "content": "Descri√ß√£oEste workshop tem como objetivo apresentar o Red Hat Service Interconnect, uma solu√ß√£o de integra√ß√£o de aplica√ß√µes que permite a comunica√ß√£o entre diferentes sistemas de forma eficiente e segura.Arquitetura da Solu√ß√£oTopologia de Servi√ßosResumo do Workshop Logar no Red Hat Developer. Criar um cluster Openshift. Acessar o cluster Openshift. No projeto do Red Hat Openshift Sandbox, acessar o seu projeto. Criar uma m√°quina virtual no Openshift Virtualization. Instalar pacotes na m√°quina virtual: podman kubernetes-client skupper oc wget Fazer o deploy do banco de dados com o podman. Fazer o deploy do frontend e do backend da aplica√ß√£o. Configurar o Service Interconnect (Skupper) para fazer a comunica√ß√£o do banco de dados rodando em um podman com a aplica√ß√£o rodando no Openshift. Acessar a aplica√ß√£o e verificar se a comunica√ß√£o est√° funcionando. Considera√ß√µes.Links Recurso Link [1] Red Hat Developer https://developers.redhat.com/ [2] OC https://docs.openshift.com/container-platform/4.15/cli_reference/openshift_cli/getting-started-cli.html [3] Skupper https://skupper.io/ Pr√©-requisitos Conta no Red Hat Developer Conhecimento b√°sico em Kubernetes Conhecimento b√°sico em Red Hat OpenShift Conhecimento b√°sico em Podman Google Chrome, a prefer√™ncia por ele √© pela funcionalidade de colar comandos no console da m√°quina virtual pelo VNC via browser.Passo a passo1. Logar no Red Hat DeveloperAcesse o site do Red Hat Developer e fa√ßa o login com a sua conta.2. Criar um cluster Openshift Sandbox2.1. Acesse o Red Hat Openshift Sandbox e clique em ‚ÄúStart Cluster‚Äù.2.2. Inicie o cluster Openshift Sandbox.4. Acessar o cluster OpenshiftAcesse o cluster Openshift Sandbox e clique em ‚ÄúOpen Console‚Äù.5. No projeto do Red Hat Openshift Sandbox, acessar o seu projetoClique no seu projeto e mude para a view ‚ÄúAdministrator‚Äù.6. Criar uma m√°quina virtual no Openshift Virtualization Acesse Virtualization no menu do cluster Openshift e clique em Virtual Machines. Clique em Create Virtual Machine. Escolha From Template e selecione o template Fedora VM. Clique em Create VirtualMachine.7. Instalar pacotes na m√°quina virtual Acesse a m√°quina virtual e clique em Console. (D√™ preferencia para o Google Chrome, pois ele tem a funcionalidade de colar comandos no console da m√°quina virtual pelo VNC via browser). Logue com as credenciais que est√£o no console. Execute os comandos abaixo para instalar os pacotes necess√°rios: sudo dnf install -y podman kubernetes-client wget# Instalar o ocwget -qO- https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/openshift-client-linux.tar.gz | tar xz -C ~/.local/binexport PATH=\"$HOME/.local/bin:$PATH\"# Instalar o skuppercurl https://skupper.io/install.sh | sh 8. Fazer o deploy do banco de dados com o podman Execute o comando abaixo para fazer o deploy do banco de dados:podman network create skupperpodman run --name database-target --network skupper --detach --rm -p 5432:5432 quay.io/skupper/patient-portal-database9. Fazer o deploy do frontend e do backend da aplica√ß√£o No seu console openshift, fa√ßa o deploy do seguinte yaml para o frontend:apiVersion: apps/v1kind: Deploymentmetadata: labels: app: frontend name: frontendspec: replicas: 3 selector: matchLabels: app: frontend template: metadata: labels: app: frontend spec: containers: - name: frontend image: quay.io/skupper/patient-portal-frontend env: - name: DATABASE_SERVICE_HOST value: database - name: DATABASE_SERVICE_PORT value: \"5432\" - name: PAYMENT_PROCESSOR_SERVICE_HOST value: payment-processor - name: PAYMENT_PROCESSOR_SERVICE_PORT value: \"8080\" ports: - containerPort: 8080 No seu console openshift, fa√ßa o deploy do seguinte yaml para o backend:apiVersion: apps/v1kind: Deploymentmetadata: labels: app: payment-processor name: payment-processorspec: replicas: 3 selector: matchLabels: app: payment-processor template: metadata: labels: app: payment-processor spec: containers: - name: payment-processor image: quay.io/skupper/patient-portal-payment-processor ports: - containerPort: 808010. Configurar o Service Interconnect (Skupper) para fazer a comunica√ß√£o do banco de dados rodando em um podman com a aplica√ß√£o rodando no Openshift.Para isso, vamos dividir em 3 etapas: Configura√ß√£o do Cluster Kubernetes Configura√ß√£o do Site Podman Expor o servi√ßo do banco de dados para a VAN do Skupper Configura√ß√£o do Cluster Kubernetes: Iniciar o skupper no cluster oenshift com o console habilitado skupper init --enable-console --enable-flow-collector --console-user admin --console-password admin Acessar o console do skupper, para isso acesse as rotas do seu cluster Openshift, a URL estar√° l√°. Criando um token para conectar o site podman com o cluster Openshift skupper token create ./skupper-token.yaml Configura√ß√£o do Site Podman: Acesse a m√°quina virtual e execute o comando abaixo para conectar o site podman com o cluster Openshift Ininie o skupper no site podman, sem ingress. skupper switch podman # para mudar o contexto para podman o padr√£o √© kubernetes Conecte o site podman com o cluster Openshift skupper link create ./skupper-token.yaml Acesse o console do skupper no cluster Openshift e verifique se o site podman est√° conectado. Expor o servi√ßo do banco de dados para a VAN do Skupper: Expor o servi√ßo do banco de dados para a VAN do Skupper systemctl --user enable --now podman.socketskupper service create database 5432skupper service bind database host database-target --target-port 5432 No cluster Openshift, vamos criar um servi√ßo Skupper para o banco de dados, esse servi√ßo vai apontar para o servi√ßo do banco de dados que est√° rodando no site podman, atrav√©s da VAN do Skupper. skupper service create database 5432 Agora, a aplica√ß√£o frontend e backend est√£o se comunicando com o banco de dados que est√° rodando em um site podman, atrav√©s da VAN do Skupper.13. Acessar a aplica√ß√£o e verificar se a comunica√ß√£o est√° funcionandoPara isso, vamos precisar executar algumas tarefas para expor o frontend no cluster Openshift. Criar um servi√ßo para o fronend que aponte para o deployment dele use o seguinte YAML:apiVersion: v1kind: Servicemetadata: name: frontend namespace: SEU-NAME-SPACEspec: selector: app: frontend ports: - protocol: TCP port: 8080 targetPort: 8080 Criar uma rota que aponte para o servi√ßo do frontend.kind: RouteapiVersion: route.openshift.io/v1metadata: name: fronted namespace: SEU-NAME-SPACE labels: {}spec: to: kind: Service name: frontend tls: {} port: targetPort: 8080 alternateBackends: []14. Considera√ß√µes O Red Hat Service Interconnect (Skupper):Oferece uma solu√ß√£o poderosa para integrar aplica√ß√µes em diferentes ambientes, simplificando a comunica√ß√£o entre servi√ßos e proporcionando maior flexibilidade e escalabilidade. Ao abstrair a complexidade da rede subjacente, o Skupper permite que os desenvolvedores se concentrem na l√≥gica de neg√≥cios de suas aplica√ß√µes, sem se preocupar com os detalhes de conectividade. Com recursos como descoberta de servi√ßos autom√°tica:O roteamento inteligente e seguran√ßa integrada, o Skupper garante que as aplica√ß√µes possam se comunicar de forma eficiente e segura, independentemente de sua localiza√ß√£o. Essa abordagem simplifica a gest√£o da infraestrutura e reduz a necessidade de configura√ß√µes manuais, agilizando o desenvolvimento e a implanta√ß√£o de aplica√ß√µes distribu√≠das. Al√©m disso, o Skupper oferece uma interface de usu√°rio intuitiva e ferramentas de linha de comando poderosas, facilitando a configura√ß√£o e o monitoramento da comunica√ß√£o entre servi√ßos. Com sua arquitetura extens√≠vel e suporte a diversos protocolos, o Skupper se adapta a diferentes cen√°rios de integra√ß√£o, atendendo √†s necessidades de projetos de todos os portes.ResumoNeste workshop, voc√™ aprendeu como usar o Red Hat Service Interconnect (Skupper) para conectar um banco de dados a um cluster Kubernetes, permitindo que aplica√ß√µes distribu√≠das se comuniquem de forma eficiente e segura. Com o Skupper, voc√™ pode simplificar a integra√ß√£o de servi√ßos em ambientes heterog√™neos, facilitando o desenvolvimento e a implanta√ß√£o de aplica√ß√µes modernas. Esperamos que este workshop tenha sido √∫til e que voc√™ possa aplicar esses conhecimentos em seus pr√≥prios projetos. Obrigado por participar!" }, { "title": "Using Skupper and OpenShift AI/ML to Prevent Insurance Fraud", "url": "/posts/AI-com-skupper-para-previnir-fraudes/", "categories": "AI, Skupper", "tags": "zago, rafael", "date": "2024-06-17 00:00:00 -0300", "snippet": "DescriptionThis workshop demonstrates how to use Skupper to connect local data services to cloud-based AI/ML environments. The workshop includes a Go application in a podman container that exposes ...", "content": "DescriptionThis workshop demonstrates how to use Skupper to connect local data services to cloud-based AI/ML environments. The workshop includes a Go application in a podman container that exposes internal data for Skupper connection. The AI/ML model training is performed in an OpenShift AI cluster on AWS using Openshift AI/ML services.DisclaimerThis lab uses the example from the AI/ML Workshop created by the Red Hat AI Services team. The original workshop is available on GitHub and includes all the necessary information to run the lab. The lab was adapted to use Skupper to connect the local data services to the cloud-based AI/ML environment.In order to faciliate the execution, for those who have access to the demo.redhat.com environment, you can start the lab by clicking here. If you don‚Äôt have access to the demo environment, you can follow the steps at the gitub repository mentioned above.References Red Hat AI/ML Workshop GO Application to expose internal data Modified examples for the workshop The Developers Conference Workshop Repository SkupperWorkshop OverviewThis lab demonstrates how AI/ML technologies can solve a business problem. The information, code, and techniques presented illustrate a prototype solution. Key steps include: Storing raw claim data within the company. Using a Go application in a podman container to expose internal data for Skupper connection. Setting up AI/ML model training in an OpenShift AI cluster on AWS. Connecting local data to cloud-based AI/ML services using Skupper.Skupper RoleSkupper provides secure, efficient connections between different environments. In this workshop, it connects local data services containing sensitive insurance claim information to a cloud-based AI/ML environment. This secure connection allows remote data access and processing while maintaining data integrity and security.Process Structure Context Connection and Setup LLM for Text Summarization LLM for Information Extraction LLM for Sentiment AnalysisScenarioWe are a multinational insurance company undergoing digital transformation. A small team has analyzed the claims process and proposed improvements. The goal is to integrate the claims processing solution with text analysis using our API in a Kubernetes cluster on AWS.ChallengesUsing Skupper to Ensure Data Security and Integrity Maintaining data integrity and security: Skupper encrypts all data traffic, ensuring sensitive data protection during transmission. Processing emails with OpenShift AI in the on-premises datacenter. Keeping applications with sensitive data within the company. Ensuring secure connections between data services and datacenters.Prototyping Work ExamplesUsing an LLM for Text SummarizationAn LLM can summarize long emails, allowing insurance adjusters to quickly understand key details.Using an LLM for Information ExtractionAn LLM extracts key information from emails and automatically populates structured forms.Using an LLM for Sentiment AnalysisAn LLM identifies customer sentiment, allowing for prompt action based on text tone.How to Use LLMs? Notebook for using LLM Notebook for text summarization with LLM Notebook for information extraction with LLM Notebook for comparing LLM modelsPart 2: Hands-OnActivities Install Skupper binary Install Skupper locally Install Skupper on the OpenShift Cluster Linking the sites Run the application inside the podman site and expose the service Execute the workshop with modified examplesSteps Installing the Skupper binary curl https://skupper.io/install.sh | sh Installing Skupper on the podman site export SKUPPER_PLATFORM=podman podman network create skupper skupper init --ingress none Install Skupper on the OpenShift Cluster skupper init --enable-console --enable-flow-collector --console-user admin --console-password admin Linking the sites Creating the token on the most exposed cluster skupper token create /tmp/insurance-claim Linking the podman site to the most exposed cluster skupper link create /tmp/insurance-claim --name ai Running the application inside the podman site and exposing the service podman run -d --network skupper -p 8080:8080 -v /home/rzago/Code/go-flp/data:/app/data --name insurance-claim-data quay.io/rzago/insurance-claim-data:latest skupper service create backend 8080 skupper service bind backend host insurance-claim-data --target-port 8080 skupper service create backend 8080 Successful ConnectionFinal TopologyTesting the connection to the podman site service from the OpenShift clusteroc exec deploy/skupper-router -c router -- curl http://backend:8080/claim/claim1.jsonNext StepsNow you can continue with the workshop until generating the sentiments of the emails.ConclusionThis workshop demonstrates how to use Skupper to connect local data services to cloud-based AI/ML environments. The workshop includes a Go application in a podman container that exposes internal data for Skupper connection. The AI/ML model training is performed in an OpenShift AI cluster on AWS using Openshift AI/ML services." }, { "title": "TemPy: An IoT Architecture with Raspberry Pi and Skupper", "url": "/posts/tempi-com-skupper-e-grafana/", "categories": "skupper, raspberry, grafana, opensource, english", "tags": "skupper, raspberry, grafana, opensource, english", "date": "2024-02-15 00:00:00 -0300", "snippet": "DescriptionThis project is a proof of concept for an IoT architecture using a Raspberry Pi and a temperature sensor that exposes the temperature data through a REST API. Along with the REST API, th...", "content": "DescriptionThis project is a proof of concept for an IoT architecture using a Raspberry Pi and a temperature sensor that exposes the temperature data through a REST API. Along with the REST API, there is a cloud integration with any cloud provider using Skupper that enables the data to be visualized in a Grafana dashboard. Clone the repository and follow the instructions to run the project. https://github.com/rafaelvzago/skupper-tempygit clone https://github.com/rafaelvzago/skupper-tempy.gitTable of Contents Hardware Raspberry Configuration Temperature Capture Skupper Role Connection to a cluster using skupper and storage data into prometheus Prometheus Grafana RepositoryArchitectureThe architecture of the project can be divided into the following parts:HardwareThis part involves the physical components used in the project, such as the Raspberry Pi and the temperature sensor. Raspberry Pi 3 Model B+ Raspberry Pi 3 Model B+ DS18B20 Temperature Sensor DS18B20 Temperature Sensor 4.7kŒ© Resistor 4.7kŒ© Resistor Breadboard Breadboard Jumper Wires Jumper WiresRaspberry ConfigurationThis part focuses on the setup and configuration of the Raspberry Pi, including installing the necessary software and libraries. Ubuntu 23.04 server for Raspberry Pi Ubuntu Installation GoLang 1.18+ GoLang Installation Skupper Main Skupper Installation Podman &gt; 4.3 Podman InstallationTemperature Capture Credits: Raspberry Pi DS18B20 Temperature Sensor TutorialIn this part, the temperature sensor is connected to the Raspberry Pi, and the code for capturing temperature readings is implemented.Configuration: Raspberry Pi GPIO Pins: Pin 1 (3.3V) is connected to the VDD pin of the DS18B20. Pin 7 (GPIO 4) is connected to the DQ pin of the DS18B20. Pin 9 (GND) is connected to the GND pin of the DS18B20. DS18B20: The VDD pin is powered by 3.3V from the Raspberry Pi. The DQ pin is connected to GPIO 4 with a pull-up resistor. The GND pin is grounded to the Raspberry Pi. Connections: A 4.7kŒ© pull-up resistor (R1) is placed between the VDD and DQ lines. The VDD line from the DS18B20 is connected to a red wire representing 3.3V from the Raspberry Pi. The DQ line is connected to a white wire representing data and is connected to GPIO 4 on the Raspberry Pi. The GND line is connected to a black wire representing ground from the Raspberry Pi.Functionality: The DS18B20 temperature sensor reports temperature data through the 1-Wire interface, which requires only one data line (and ground) for communication with the Raspberry Pi. The pull-up resistor is necessary for the 1-Wire protocol used by the DS18B20 to function correctly.REST API: To expose the temperature data, a REST API is implemented using GoLang. The API is used to capture the temperature data and expose it to the cloud provider.go build tempy/tempy.go Find a way to run the tempy binary on the Raspberry Pi, for this example I will use a simple nohup command to run the tempy binary in the background.nohup ./tempy &amp; The REST API is exposed on port 5000/temperature, and the temperature data can be accessed using the following command:curl localhost:5000/temperatureSkupper RoleWe will use Skupper to establish communication between the Raspberry Pi and the cloud provider, and to expose the temperature data to the cloud. This part covers the setup and configuration of Skupper.Skupper is a layer 7 service interconnect that enables secure communication across Kubernetes clusters, including network and application layer protocols. Skupper is designed to connect services that are running on different infrastructure, and it is based on the idea of a service bus. Skupper In this example we will be using skupper gateway to expose the temperature data to the cloud, for this we will need to have a skupper site running on the cloud and a skupper gateway running on the Raspberry Pi. Skupper gateway is a component that allows non-kubernetes services to be exposed to the skupper network, in this case we will use the skupper gateway to expose the temperature data to the cloud.Skupper site: A namespace running skupper, for this example we will borrow the prometheus service to store the temperature data, so we will init skupper on the cluster with the following command: skupper init --site-name site1 --enable-console --enable-flow-collector Skuper gateway on the Raspberry Pi: To expose the temperature data to the cloud, we will use a skupper gateway to expose the temperature data to the cloud, for this we will use the following command: skupper gateway expose tempy localhost 5000 --type podmanConnection to a cluster using skupper and storage data into prometheusThe temperature data captured by the Raspberry Pi is stored in the cloud using the chosen cloud provider. This part explains how the data is stored and managed.For this example, we will deploy a prometheus service to store the temperature data, and a prometheus-adapter to scrape the temperature data from the REST API and store it in the prometheus service. In order to facilitate the prometheus role, we will configure the prometheus service discovery to scrape the temperature data from the prometheus-adapter or any other service labeled as app=metric. with this approach, we can easily add more temperature sensors to the architecture and the prometheus service will automatically scrape the temperature data from the new sensors.In order to achive this, the service will be labeled as app=metric, and the prometheus-adapter will add the temperature data to the service, so the prometheus service will scrape the temperature data from the prometheus-adapter.apiVersion: v1kind: Servicemetadata: name: tempy-prometheus-adapter-servicespec: type: ClusterIP selector: app: metricsPrometheus Adapter: Build the TemPy prometheus-adapter image: podman build -t quay.io/YOUR-USER/tempy-prometheus-adapter:0.1 -f prometheus-adapter/Dockerfile-TempyPrometheusAdapter . Push the image to the quay.io registry: podman push quay.io/YOUR-USER/tempy-prometheus-adapter:0.1 Deploy the prometheus-adapter: kubectl apply -f prometheus-adapter/TempyPrometheusAdapter-deployment.yaml Expose the prometheus-adapter: kubectl apply -f prometheus-adapter/TempyPrometheusAdapter-service.yaml Verify the prometheus-adapter is running: kubectl run -i --tty --rm curl-pod --image=curlimages/curl -- shcurl tempy-prometheus-adapter:9090/metrics...# TYPE temperature_celsius gaugetemperature_celsius 19.81# HELP temperature_fahrenheit Current temperature in Fahrenheit# TYPE temperature_fahrenheit gaugetemperature_fahrenheit 67.66 CHeck the prometheus-adapter sservice to check if the labels are being added to the service: kubectl get svc tempy-prometheus-adapter-service -o wideNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTORtempy-prometheus-adapter-service ClusterIP 10.43.154.250 &lt;none&gt; 9090/TCP 11h app=metrics PrometheusThe temperature data is stored in a prometheus service. This part covers the setup and configuration of the prometheus service. We need to persist the data, so we will use a PVC, in my case I will use the longhorn storage class, but you can use any storage class that you have available in your cluster.This is a part of the prometheus configuration file, it is configured to scrape the temperature data from any service labeled as app=metrics, so the prometheus service will scrape the temperature data from the prometheus-adapter. Note that this configuration will only look for services labeled as app=metrics in the skupper-pi namespace, so if you are using a different namespace, you will need to change the configuration file accordingly.... - job_name: 'metrics-targets' scrape_interval: 5s kubernetes_sd_configs: - role: service namespaces: names: ['skupper-pi'] relabel_configs: - source_labels: [__meta_kubernetes_service_label_app] regex: metrics action: keep... Create prometheus PVC: kubectl apply -f prometheus/prometheus-pvc.yaml Create prometheus deployment: kubectl apply -f prometheus/prometheus-deployment.yaml Configuring the prometheus service discovery to scrape the temperature data from any service labeled as app=metrics: kubectl apply -f prometheus/prometheus-cm.yaml Deploy the prometheus: kubectl apply -f prometheus/prometheus-deployment.yaml Create prometheus service: kubectl apply -f prometheus/prometheus-service.yaml Verify the prometheus is running, from this point on, the prometheus service should be scraping the temperature data from the prometheus-adapter or any other service labeled as app=metrics, let‚Äôs query all the services discovered by prometheus: kubectl run -i --tty --rm curl-pod --image=curlimages/curl -- sh -c 'curl -G --data-urlencode \"query=up\" http://prometheus:9090/api/v1/query' | jq .If you don't see a command prompt, try pressing enter.warning: couldn't attach to pod/curl-pod, falling back to streaming logs: Internal error occurred: error attaching to container: container is in CONTAINER_EXITED state{ \"status\": \"success\", \"data\": { \"resultType\": \"vector\", \"result\": [ { \"metric\": { \"__name__\": \"up\", \"instance\": \"localhost:9090\", \"job\": \"prometheus\" }, \"value\": [ 1708523706.121, \"1\" ] }, { \"metric\": { \"__name__\": \"up\", \"instance\": \"promock.skupper-pi.svc:80\", \"job\": \"metrics-targets\" }, \"value\": [ 1708523706.121, \"1\" ] }, { \"metric\": { \"__name__\": \"up\", \"instance\": \"tempy-prometheus-adapter-service.skupper-pi.svc:9090\", \"job\": \"metrics-targets\" }, \"value\": [ 1708523706.121, \"1\" ] } ] }}... GrafanaThe stored temperature data is visualized in a Grafana dashboard. This part covers the setup and configuration of the dashboard. To visualize the temperature data, we will use a Grafana dashboard. The dashboard is configured to scrape the temperature data from the prometheus service and visualize it in a graph. The grafana deployment is done using the following command: For the data persistence, we will use a PVC to store the grafana data, in my case I have longhorn installed on my cluster, so I will use it to store the grafana data, but you can use any other storage class that you have available on your cluster. Create grafana PVC: kubectl apply -f grafana/grafana-pvc.yaml Create grafana deployment: kubectl apply -f grafana/grafana-deployment.yaml Create grafana service: kubectl apply -f grafana/grafana-service.yaml Important: My cluster is configrued to use the ingress controller, so I have to create an ingress to expose the grafana service, if your cluster is not configured to use the ingress controller, you will neeed either to expose the grafana service using a nodeport or a loadbalancer. Create a data source connection in grafana that points to the prometheus service: http://skupper-prometheus:9090 Import the grafana dashboard: grafana/dashboard.json FINALY, you should be able to visualize the temperature data in the grafana dashboard.RepositoryThe complete code for the project can be found in the following GitHub repository: TemPy" }, { "title": "Carreira com Software Livre - O que √© e como come√ßar?", "url": "/posts/carreira-com-softeware-livre/", "categories": "carreira, opensource", "tags": "carreira, opensource", "date": "2023-12-07 00:00:00 -0300", "snippet": "Carreira com Software Livre - O que √© e como come√ßar?Introdu√ß√£oSoftware Livre √© um movimento que tem como objetivo promover a liberdade de uso, estudo, modifica√ß√£o e distribui√ß√£o de software. O mov...", "content": "Carreira com Software Livre - O que √© e como come√ßar?Introdu√ß√£oSoftware Livre √© um movimento que tem como objetivo promover a liberdade de uso, estudo, modifica√ß√£o e distribui√ß√£o de software. O movimento do Software Livre √© baseado em quatro liberdades essenciais: A liberdade de executar o programa, para qualquer prop√≥sito (liberdade n¬∫ 0). A liberdade de estudar como o programa funciona e adapt√°-lo para as suas necessidades (liberdade n¬∫ 1). O acesso ao c√≥digo-fonte √© um pr√©-requisito para esta liberdade. A liberdade de redistribuir c√≥pias de modo que voc√™ possa ajudar ao seu pr√≥ximo (liberdade n¬∫ 2). A liberdade de aperfei√ßoar o programa, e liberar os seus aperfei√ßoamentos, de modo que toda a comunidade se beneficie (liberdade n¬∫ 3). O acesso ao c√≥digo-fonte √© um pr√©-requisito para esta liberdade.Tipos de licen√ßas para software livreExistem diversos tipos de licen√ßas para software livre, sendo as mais populares a GPL, LGPL, MIT, Apache, BSD e a Mozilla. Cada uma dessas licen√ßas possui suas pr√≥prias caracter√≠sticas e restri√ß√µes, por√©m, todas elas garantem as quatro liberdades essenciais do movimento do Software Livre. GPL: A GPL √© uma licen√ßa copyleft, o que significa que qualquer software que utilize uma biblioteca licenciada sob a GPL tamb√©m deve ser licenciado sob a GPL. A GPL √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. LGPL: A LGPL √© uma licen√ßa copyleft, o que significa que qualquer software que utilize uma biblioteca licenciada sob a LGPL tamb√©m deve ser licenciado sob a LGPL. A LGPL √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. MIT: A MIT √© uma licen√ßa permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a MIT pode ser licenciado sob qualquer outra licen√ßa. A MIT √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. Apache: A Apache √© uma licen√ßa permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a Apache pode ser licenciado sob qualquer outra licen√ßa. A Apache √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. BSD: A BSD √© uma licen√ßa permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a BSD pode ser licenciado sob qualquer outra licen√ßa. A BSD √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos. Mozilla: A Mozilla √© uma licen√ßa permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a Mozilla pode ser licenciado sob qualquer outra licen√ßa. A Mozilla √© uma licen√ßa muito popular entre os desenvolvedores de software livre, pois garante que o software permane√ßa livre e aberto para todos.Como come√ßar a contribuir com software livre?Existem diversas formas de contribuir com software livre, sendo as mais populares a contribui√ß√£o de c√≥digo, a contribui√ß√£o de documenta√ß√£o e a contribui√ß√£o de tradu√ß√£o. Cada uma dessas formas de contribui√ß√£o possui suas pr√≥prias caracter√≠sticas e restri√ß√µes, por√©m, todas elas garantem as quatro liberdades essenciais do movimento do Software Livre.A Import√¢ncia do Software Livre na Ind√∫stria de TecnologiaO Software Livre √© um movimento que tem como objetivo promover a liberdade de uso, estudo, modifica√ß√£o e distribui√ß√£o de software. Hoje existem v√°rios projetos que s√£o pilares da ind√∫stria e s√£o mantidos por comunidades de desenvolvedores que trabalham de forma volunt√°ria. Esses projetos s√£o essenciais para o desenvolvimento de novas tecnologias e para a evolu√ß√£o da ind√∫stria de tecnologia como um todo. Por isso, √© importante que os desenvolvedores se envolvam com o movimento do Software Livre e contribuam com projetos que s√£o essenciais para a ind√∫stria de tecnologia.Exemplos de software livre que s√£o essenciais para a ind√∫stria de tecnologia: Linux: O Linux √© um sistema operacional de c√≥digo aberto que √© utilizado por milh√µes de pessoas em todo o mundo. https://www.kernel.org/. Apache: O Apache √© um servidor web de c√≥digo aberto que √© utilizado por milh√µes de pessoas em todo o mundo. https://httpd.apache.org/. MariaDB: O MariaDB √© um sistema de gerenciamento de banco de dados de c√≥digo aberto derivado do MySQL. https://mariadb.org/. Docker: O Docker √© uma plataforma de c√≥digo aberto que permite que os desenvolvedores empacotem seus aplicativos em cont√™ineres. https://www.docker.com/. Kubernetes: O Kubernetes √© uma plataforma de c√≥digo aberto que permite que os desenvolvedores gerenciem seus aplicativos em cont√™ineres. https://kubernetes.io/. Ansible: O Ansible √© uma ferramenta de c√≥digo aberto que permite que os desenvolvedores automatizem a implanta√ß√£o de seus aplicativos. https://www.ansible.com/. Jenkins: O Jenkins √© uma ferramenta de c√≥digo aberto que permite que os desenvolvedores automatizem a constru√ß√£o e o teste de seus aplicativos. https://www.jenkins.io/. Git: O Git √© uma ferramenta de c√≥digo aberto que permite que os desenvolvedores controlem as vers√µes de seus aplicativos. https://git-scm.com/.Software livre em n√∫meros: Atualmente existem mais de 1.000.000 de projetos de software livre no GitHub. O GitHub √© a maior plataforma de desenvolvimento de software livre do mundo. GitHub O Linux √© o sistema operacional mais utilizado no mundo. Linux Existem mais de projetos 1861 projetos na CNCf. Tanto projetos graduaos, incubados, sabdbvox e arquivados. CNCf Existem mais de 300 projetos na Apache. ApacheCNCF - Cloud Native Computing Foundation CNCF (Cloud Native Computing Foundation): Uma organiza√ß√£o sem fins lucrativos. Objetivo: Promover o desenvolvimento de software livre para a nuvem. Caracter√≠sticas: Foco em Cloud Native: Concentra-se em tecnologias que empoderam sistemas escal√°veis, resilientes e ag√©is baseados em cont√™ineres. Comunidade Aberta e Colaborativa: Encoraja a colabora√ß√£o e contribui√ß√£o abertas entre membros da ind√∫stria, desenvolvedores e usu√°rios finais. Padr√µes e Pr√°ticas de Governan√ßa: Estabelece padr√µes e melhores pr√°ticas para garantir interoperabilidade e efici√™ncia. Apoio √† Inova√ß√£o e Sustentabilidade: Fomenta a inova√ß√£o e sustentabilidade de projetos e comunidades de software livre. Eventos e Educa√ß√£o: Organiza eventos, webinars e programas educacionais para promover conhecimento e colabora√ß√£o na comunidade cloud native. Projetos Chave: Kubernetes: Um sistema de orquestra√ß√£o de cont√™ineres. Prometheus: Sistema de monitoramento e alerta. Envoy: Um proxy de servi√ßo de c√≥digo aberto. Links: Site Oficial Kubernetes Prometheus Envoy CNCF Projects Apache Software Foundation ASF (Apache Software Foundation): Uma organiza√ß√£o sem fins lucrativos. Objetivo: O objetivo da ASF √© fornecer software livre para o p√∫blico em geral. Principais Projetos da Apache Software Foundation: Apache Hadoop: Framework para processamento distribu√≠do de grandes conjuntos de dados. Apache Kafka: Plataforma de streaming distribu√≠do para constru√ß√£o de pipelines de dados em tempo real. Apache Cassandra: Banco de dados distribu√≠do para lidar com grandes quantidades de dados. Apache Spark: Motor de an√°lise unificado para processamento de dados em larga escala. Apache Lucene: Biblioteca de software para recupera√ß√£o de informa√ß√µes e pesquisa de texto completo. Apache Tomcat: Cont√™iner de servlets para aplica√ß√µes web Java. Apache Maven: Ferramenta de automa√ß√£o de compila√ß√£o para projetos Java. Apache HBase: Banco de dados n√£o relacional distribu√≠do para grandes conjuntos de dados. Apache Flink: Framework e mecanismo de processamento de fluxo distribu√≠do. Apache Airflow: Plataforma para programar, coordenar e monitorar fluxos de trabalho. Links: Site Oficial Apache Hadoop Apache Kafka Apache Cassandra Apache Spark Apache Lucene Apache Tomcat Apache Maven Apache HBase Apache Flink Apache Airflow Linux FoundationA Linux Foundation √© conhecida por seu apoio a v√°rios projetos importantes de c√≥digo aberto, incluindo o Linux Kernel, Kubernetes, Hyperledger e Node.js. Eles se concentram em fornecer um lar neutro e apoio para a colabora√ß√£o em tecnologias de c√≥digo aberto, priorizando inova√ß√£o, inclus√£o e desenvolvimento sustent√°vel.Para obter informa√ß√µes detalhadas e uma lista completa dos projetos, recomendo visitar diretamente o site da Linux Foundation: Linux Foundation Projects.Principais Projetos da Linux Foundation: CNCF: Cloud Native Computing Foundation. LF AI: Linux Foundation Artificial Intelligence. LF Edge: Linux Foundation Edge. LF Energy: Linux Foundation Energy. LF Public Health: Linux Foundation Public Health. OpenJS Foundation: OpenJS Foundation. RISC-V: RISC-V. Links: Site Oficial Linux Foundation Projects ResumoEsse artigo discute a carreira em Software Livre, enfatizando a import√¢ncia das quatro liberdades essenciais do movimento: executar, estudar, redistribuir e aperfei√ßoar programas. Ele explora diferentes tipos de licen√ßas, como GPL, LGPL, MIT, Apache, BSD e Mozilla, destacando suas caracter√≠sticas √∫nicas. O texto sugere formas de contribuir com software livre, incluindo c√≥digo, documenta√ß√£o e tradu√ß√£o. Destaca a relev√¢ncia do Software Livre na ind√∫stria de tecnologia, citando exemplos como Linux, Apache e Docker. Al√©m disso, menciona projetos e iniciativas de organiza√ß√µes como CNCF, Apache Software Foundation e Linux Foundation, fornecendo links √∫teis e informa√ß√µes sobre seus projetos e objetivos." }, { "title": "Quem sou eu?", "url": "/posts/quem-sou-eu/", "categories": "sobre, off-topic", "tags": "zago, rafael", "date": "2023-12-04 00:00:00 -0300", "snippet": "Apresenta√ß√£oQu√© pasa?Ol√°! N√£o me leve muito a s√©rio, ok? Eu criei esse espa√ßo para compartilhar um pouco do conhecimento que eu tenho e que 90% dele, eu ganhei na internet. Ent√£o j√° passou da hora ...", "content": "Apresenta√ß√£oQu√© pasa?Ol√°! N√£o me leve muito a s√©rio, ok? Eu criei esse espa√ßo para compartilhar um pouco do conhecimento que eu tenho e que 90% dele, eu ganhei na internet. Ent√£o j√° passou da hora de devolver um pouco para o mundo.Hoje sou senior software automation engineer na Red Hat, mas j√° passei por algumas empresas (pequenas e grandes) fazendo de tudo um pouco: DevOps de cora√ß√£o e SysAdmin de voca√ß√£o. Criando m√©todos de aprendizagem e estruturando treinamentos. Trabalhei, por muitos anos, com suporte de aplica√ß√µes de v√°rios tamanhos e complexidade. Sou instrutor da Caelum/Alura. Sou padrinho do carinha mais dahora da terra! Sem clubismo‚Ä¶ComunidadesSou devops de cora√ß√£o e tamb√©m membro da organiza√ß√£o do DevOpsDays SP Organiza√ß√£o do DevOpsDays 2020Abaixo est√£o as poucas contribui√ß√µes que j√° fiz:Podcasts Hipsters Ponto Tech #239 DNE 224 - Trabalhar para GringaTalks/Palestras Uma estrat√©gia upstream e downstream para entrega cont√≠nua - Mini DebConf Bras√≠lia!, 2023. Skupper, a cloud h√≠brida com 3 comandos - DevOpsDays Fortaleza, 2022. Take out the rust, transformando time com responsabilidade - DevOpsDays S√£o Paulo, 2019. Desenvolvendo Aplica√ß√µes na Nuvem: Uma Abordagem Pr√°tica - LinuxDay Limeira, 2014 Palestra Linux 101 - Unisal Campinas, 2018 IHC and Security Talk - Unisal Campinas 2018V√≠deos O que √© Openshift? - Alura" }, { "title": "CI/CD Upstream vs Downstream", "url": "/posts/ci-cd-downstream-upstream/", "categories": "pipeline", "tags": "pipeline, ci, cd", "date": "2023-06-02 00:00:00 -0300", "snippet": "Integrando Skupper com Skupper: Uma abordagem upstream e downstreamQuando se trata de desenvolvimento de software, integrar projetos upstream e downstream pode ser um desafio. Neste artigo, vamos e...", "content": "Integrando Skupper com Skupper: Uma abordagem upstream e downstreamQuando se trata de desenvolvimento de software, integrar projetos upstream e downstream pode ser um desafio. Neste artigo, vamos explorar uma abordagem eficaz para integrar o Skupper e o Skupper, utilizando ferramentas populares para cada lado do desenvolvimento.Introdu√ß√£oO Skupper √© um projeto de software livre que fornece uma solu√ß√£o de rede de servi√ßo para Kubernetes. O Skupper √© desenvolvido pela Red Hat e est√° dispon√≠vel sob a licen√ßa Apache 2.0. Essa √© a vers√£o upstream do Skupper, o que significa que √© a vers√£o que est√° sendo desenvolvida ativamente pela Red Hat.Para os usu√°rios que desejam implantar o Skupper em um ambiente de produ√ß√£o, a Red Hat oferece o Skupper, uma vers√£o comercial do Skupper que √© fornecida pela Red Hat sob o nome de Red Hat AMQ Interconnect. Essa √© a vers√£o downstream do Skupper, o que significa que √© a vers√£o portada para o Red Hat Enterprise Linux e como Opera com o Red Hat OpenShift. Apesar de serem projetos diferentes, o Skupper e o Skupper compartilham uma base de c√≥digo comum e, portanto, √© importante que as altera√ß√µes feitas no Skupper sejam integradas ao RHSI (Red HaT Application Interconnect). Para isso, √© necess√°rio estabelecer um fluxo de trabalho eficiente que permita a integra√ß√£o cont√≠nua entre o Skupper e o RHSI.Definindo o ambiente e as ferramentasAntes de come√ßarmos, vamos configurar nosso ambiente de desenvolvimento. Para o lado downstream, faremos uso das seguintes ferramentas: Jira: uma ferramenta de gerenciamento de projetos que nos ajudar√° a rastrear e organizar as tarefas relacionadas ao desenvolvimento downstream. Confluence: uma plataforma de colabora√ß√£o que usaremos para documentar informa√ß√µes importantes sobre o projeto. Git: um sistema de controle de vers√£o que nos permitir√° gerenciar nosso c√≥digo fonte e colaborar com outros desenvolvedores. Quay.io: um registro de cont√™ineres que nos ajudar√° a armazenar e distribuir nossas imagens de cont√™ineres. Jenkins: uma ferramenta de automa√ß√£o de integra√ß√£o cont√≠nua que nos permitir√° construir, testar e implantar nosso software de forma automatizada.Por outro lado, para o desenvolvimento upstream, faremos uso das seguintes ferramentas: GitHub Issues: um recurso do GitHub que nos ajudar√° a rastrear e gerenciar problemas e solicita√ß√µes de recursos relacionados ao desenvolvimento upstream. CircleCI: uma plataforma de integra√ß√£o cont√≠nua que nos permitir√° construir, testar e validar nosso c√≥digo de forma automatizada.Fluxo de trabalhoAgora que nosso ambiente est√° configurado, vamos explorar um fluxo de trabalho b√°sico para a integra√ß√£o cont√≠nua entre o Skupper e o Skupper. Desenvolvimento Upstream Utilize o GitHub Issues para rastrear e gerenciar problemas e solicita√ß√µes de recursos. Fa√ßa uso do CircleCI para construir e testar o c√≥digo do Skupper de forma automatizada. Integra√ß√£o Upstream-Downstream Ap√≥s o desenvolvimento upstream estar pronto, abra uma solicita√ß√£o de pull no reposit√≥rio do Skupper. Uma vez que a solicita√ß√£o de pull seja aprovada, uma nova vers√£o do Skupper √© criada e publicada no Quay.io. Desenvolvimento Downstream Utilize o Jira para criar tarefas relacionadas √†s funcionalidades downstream. Utilize o Git para clonar o c√≥digo fonte do Skupper e iniciar o desenvolvimento downstream. Use o Jenkins para automatizar a constru√ß√£o, teste e implanta√ß√£o do Skupper. Integra√ß√£o Downstream-Upstream Quando necess√°rio, fa√ßa altera√ß√µes no c√≥digo do Skupper e abra uma solicita√ß√£o de pull no reposit√≥rio. Ap√≥s a aprova√ß√£o da solicita√ß√£o de pull, uma nova vers√£o do Skupper √© publicada. Exemplo pr√°ticoPara ilustrar o fluxo de trabalho descrito acima, vamos considerar um cen√°rio em que estamos adicionando suporte para um novo protocolo de comunica√ß√£o no Skupper e integrando essa funcionalidade ao Skupper. Desenvolvimento Upstream Abra um problema no GitHub Issues para rastrear a solicita√ß√£o de suporte ao novo protocolo. Escreva o c√≥digo necess√°rio para adicionar o suporte no Skupper. Utilize o CircleCI para construir e testar o c√≥digo automaticamente. Integra√ß√£o Upstream-Downstream Abra uma solicita√ß√£o de pull no reposit√≥rio do Skupper para incorporar as altera√ß√µes. Ap√≥s a aprova√ß√£o da solicita√ß√£o de pull, uma nova vers√£o do Skupper √© publicada no Quay.io. Desenvolvimento Downstream No Jira, crie uma tarefa para adicionar suporte ao novo protocolo no Skupper. Clone o reposit√≥rio do Skupper usando o Git. Adicione o suporte ao novo protocolo no c√≥digo do Skupper. Use o Jenkins para automatizar a constru√ß√£o, teste e implanta√ß√£o do Skupper com as novas altera√ß√µes. Integra√ß√£o Downstream-Upstream Se necess√°rio, fa√ßa altera√ß√µes adicionais no c√≥digo do Skupper e abra uma solicita√ß√£o de pull. Ap√≥s a aprova√ß√£o da solicita√ß√£o de pull, uma nova vers√£o do Skupper √© publicada. Conclus√£oA integra√ß√£o cont√≠nua entre o Skupper e o Skupper √© essencial para garantir que as atualiza√ß√µes do software cheguem aos usu√°rios de forma eficiente, mantendo a viabilidade comercial. Utilizando ferramentas como Jira, Confluence, Git, Quay.io, Jenkins, GitHub Issues e CircleCI, √© poss√≠vel estabelecer um fluxo de trabalho robusto e automatizado que agiliza o desenvolvimento upstream e downstream, permitindo a entrega cont√≠nua de software de alta qualidade.Esperamos que este artigo tenha fornecido insights valiosos sobre a integra√ß√£o upstream e downstream e tenha demonstrado como essas ferramentas podem ser usadas em conjunto para um processo de desenvolvimento mais eficiente.Obrigado por ler e continue explorando as possibilidades de integra√ß√£o cont√≠nua entre projetos de software livre e produtos comerciais!" }, { "title": "Criando uma rede de aplicativos multicloud com Skupper", "url": "/posts/multicloud-com-skupper/", "categories": "cloud, k8s, skupper", "tags": "k8s, skupper, could, RedHat", "date": "2022-10-01 00:00:00 -0300", "snippet": "Refer√™ncias e tecnologias utilizadas: https://skupper.io https://minikube.sigs.k8s.io Reposit√≥rio com os C√≥digos Qpid-dispatch ActiveMQ Kubectl Kubernetes MTLS Open-source Skupper-router ...", "content": "Refer√™ncias e tecnologias utilizadas: https://skupper.io https://minikube.sigs.k8s.io Reposit√≥rio com os C√≥digos Qpid-dispatch ActiveMQ Kubectl Kubernetes MTLS Open-source Skupper-router SkupperFerramentas Um computador com o minikube [2] instalado; Um terminal para executar os comandos; kubectl &gt; 1.15 [6] ou mais nova.Descri√ß√£o da solu√ß√£oO Skupper [1] √© uma ferramenta que permite conectar dois ou mais ambientes de cloud de uma maneira n√£o intrusiva e segura. Tais ambientes podem ser de diferentes provedores de servi√ßo em nuvem como: AWS, GCP, AZURE entre outras, e, inclusive, clusters kubernetes nativos.tl;drPara quem est√° come√ßando com cloud: O Skupper √© uma ferramenta que permite conectar diferentes ambientes de computa√ß√£o em nuvem de maneira segura e sem complica√ß√µes. Imagine que voc√™ tem duas salas diferentes, cada uma com seu pr√≥prio conjunto de ferramentas. Skupper √© como uma porta segura que permite que essas salas ‚Äúconversem‚Äù entre si, compartilhando ferramentas conforme necess√°rio. Isso √© √∫til quando voc√™ tem diferentes partes de um aplicativo rodando em diferentes lugares, mas elas precisam trabalhar juntas como se estivessem no mesmo lugar.Para quem tem algum conheciemento de cloud: O Skupper √© uma solu√ß√£o de rede de servi√ßo para Kubernetes que permite a comunica√ß√£o segura e f√°cil entre clusters. Ele cria uma camada de rede virtual que conecta pods em diferentes clusters como se estivessem na mesma rede local. Isso √© feito sem a necessidade de privil√©gios de administrador do cluster e sem a necessidade de expor servi√ßos √† Internet p√∫blica. Al√©m disso, o Skupper n√£o √© intrusivo com sua aplica√ß√£o, pois n√£o cria side-cars ou outros containers dentro dos Pods. Ele √© open-source e oferece criptografia de ponta a ponta usando certificados digitais.Para quem gosta de escovar bits: O Skupper pode ser dividido em duas partes: o skupper-router e o control-plane chamado skupper-service-controller. O skupper-router √© um roteador de rede de servi√ßo baseado no Qpid-dispatch [4] e no ActiveMQ [5]. O skupper-service-controller √© um controlador Kubernetes que gerencia o skupper-router e fornece uma API para configurar e gerenciar a rede de servi√ßo. Existem outros containers que s√£o usados para configurar e gerenciar o skupper-router, mas eles s√£o apenas auxiliares e n√£o s√£o necess√°rios para o funcionamento do Skupper. Mas isso vai ficar para outro post.Solu√ß√£oEsse exemplo consiste em dois servi√ßos:1. Frontend Um servi√ßo de backend que exp√µe um endpoint /api/hello. Que tem como resposta Oi, &lt;seu-nome&gt;. Eu sou &lt;meu-nome&gt; (&lt;nome-pod&gt;). O deploy ser√° feito no namespace confi_oeste;2. Backend Um servi√ßo de frontend que exp√µe um endpoint /api/hello que faz uma chamada para o servi√ßo de backend e retorna a resposta, mas nesse caso o servi√ßo esta rodando em outro namespace chama config_leste, este por sua vez pode estar em outro cluster ou namespace.Por que usar o Skupper? Com o Skupper, voc√™ pode colocar o back-end em um cluster e o front-end em outro e manter a conectividade entre os dois servi√ßos sem expor o back-end √† Internet p√∫blica.Detalhes: N√£o √© necess√°rio ter privil√©gios de administrador do cluster, j√° que a solu√ß√£o √© no n√≠vel do namespace; N√£o √© intrusivo com a sua aplica√ß√£o, pois n√£o cria side-cars ou outros containers dentro dos Pods; √â open-source; Voc√™ pode conectar, em seu cluster, servi√ßos externos como: Bancos de dados, aplica√ß√µes legadas e ainda de alta criticidade; Criptografado de ponta a ponta usando certificados digitais; Baixa curva de aprenddizagem. MTLS [9] por padr√£o. MTLS √© um protocolo de seguran√ßa que garante que a comunica√ß√£o entre dois pontos seja feita de maneira segura e criptografada. Utiliza√ß√£o de certificados pr√≥prios caso necess√°rio, ou seja, voc√™ pode usar os certificados da sua empresa ou gerar novos certificados para o Skupper ( que √© o padr√£o e s√£o criados automaticamente).Agora vamos preparar nosso ambiente de teste, que consiste no seguinte: Um servi√ßo de backend que est√° rodando em um namespace que vai prover a l√≥gica para outro servi√ßo de frontend que obviamente est√° e outro namespace*. Nesse caso, cada servi√ßo est√° rodando em namespaces diferentes, mas o mesmo exemplo pode (e deve) ser testado com provedores diferentes.1. Nesse exemplo vamos utilizar dois namespaces chamados:1.1. config_oeste onde ficar√° o frontend. Lembre-se de abrir uma aba do seu terminal para cada namespaceexport KUBECONFIG=~/.kube/config-oeste1.2. config_leste onde ficar√° o backend agora, no outro terminal:export KUBECONFIG=~/.kube/config-lesteObs: Voc√™ pode usar o nome que quiser para os namespaces, mas lembre-se de usar o mesmo nome no arquivo de configura√ß√£o do skupper.2. Configurando cada namespace:2.1.config_oeste:kubectl create namespace oestekubectl config set-context --current --namespace oeste2.2.config_leste:kubectl create namespace lestekubectl config set-context --current --namespace leste3. Instalando o Skupper:Voc√™ possui algumas maneiras de instalar o skupper, como por exemplo: Compilar a partir do reposit√≥rio Fazer o download do execut√°vel direto do reposit√≥rio [1] do projeto Usar o script de instala√ß√£o disponibilizado pelo site skupper.io e vamos utilizar esse m√©todo, por ser mais f√°cil de fazer e voc√™ n√£o precisar√° se preocupar com depend√™ncias.4. Insta√ßa√ß√£o do CLI do Skupper: curl https://skupper.io/install.sh | sh5. Iniciando o skupper nos dois namespaces:5.1.config_oeste:skupper init5.2.config_leste:skupper init6. Conectando os namespaces:A cria√ß√£o de um link requer o uso de dois comandos skupper em conjunto: skupper token create e skupper link create.O comando skupper token create gera um token secreto que significa permiss√£o para criar um link. O token tamb√©m carrega os detalhes do link. Em seguida, em um namespace remoto, o comando skupper link create usa o token para criar um link para o namespace que o gerou. Nota: O token de link √© realmente um segredo. Qualquer pessoa que tenha o token pode vincular ao seu namespace. Certifique-se de que apenas aqueles em quem voc√™ confia tenham acesso a ele. Por√©m sua utiliza√ß√£o pode ser controlada por n√∫mero de usos e tempo de vida. Veja a documenta√ß√£o do skupper [1] para mais detalhes.6.1. Criando o token no namespace config_oeste:skupper token create ~/secret.tokenToken written to ~/secret.token6.2. Fazendo o link no namespace config_leste ao namespace config_oeste com o token gerado:skupper link create ~/secret.token7. Fazendo o deploy do frontend e do backend:7.1. Applicando o YAML para fazer o deploy do frontend no namespace config_oeste:kubectl create deployment frontend --image quay.io/skupper/hello-world-frontenddeployment.apps/frontend created7.2. Applicando o YAML para fazer o deploy do backend no namespace config_leste:kubectl create deployment backend --image quay.io/skupper/hello-world-backend --replicas 3deployment.apps/backend created8. Expondo os servi√ßos de backend:Agora que os servi√ßos est√£o rodando, vamos expor os servi√ßos para que possamos acess√°-los. Nesse caso, vamos expor o servi√ßo de backend para que o frontend possa acess√°-lo, independente de onde ele esteja rodando.8.1. Expondo o servi√ßo de backend no namespace config_leste:skupper expose deployment/backend --port 8080deployment backend exposed as backend9. Expondo os servi√ßos de frontend:Agora que os servi√ßos est√£o rodando, vamos expor os servi√ßos para que possamos acess√°-los. Nesse caso, vamos expor o servi√ßo de frontend para que possamos acess√°-lo, independente de onde ele esteja rodando.9.1. Expondo o servi√ßo de frontend no namespace config_oeste:kubectl expose deployment frontend --port 8080 --type LoadBalancerservice/frontend exposed10. Testando a aplica√ß√£o:Agora que os servi√ßos est√£o rodando, vamos testar a aplica√ß√£o. Nesse caso, vamos acessar o servi√ßo de frontend e verificar se ele consegue acessar o servi√ßo de backend. Para isso, vamos fazer uma chamada para o endpoint /api/health do servi√ßo de frontend e verificar se ele consegue acessar o servi√ßo de backend.10.1.config_oeste:kubectl get service/frontendNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEfrontend LoadBalancer 10.103.232.28 &lt;external-ip&gt; 8080:30407/TCP 15scurl http://&lt;external-ip&gt;:8080/api/healthOK11. Apagando tudo:Pronto! Agora que voc√™ j√° testou o Skupper, vamos apagar tudo para que voc√™ possa testar novamente ou fazer outras experi√™ncias.11.1. Apagando tudo no namespace config_oeste:skupper deletekubectl delete service/frontendkubectl delete deployment/frontend11.2. Apagando tudo no namespace config_leste:skupper deletekubectl delete deployment/backendResumoEste exemplo localiza os servi√ßos de front-end e back-end em namespaces diferentes, em clusters diferentes. Normalmente isso significa que eles n√£o tem como se comunicar, a menos que sejam expostos √† Internet p√∫blica.A introdu√ß√£o do Skupper em cada namespace nos permite criar uma rede de aplicativos virtuais que pode conectar servi√ßos em diferentes clusters. Qualquer servi√ßo exposto na rede de aplicativos √© representado como um servi√ßo local em todos os namespaces vinculados.O servi√ßo de back-end est√° localizado no leste, mas o servi√ßo de front-end no oeste pode ‚Äúv√™-lo‚Äù como se fosse local. Quando o front-end envia uma solicita√ß√£o ao back-end, o Skupper encaminha a solicita√ß√£o para o namespace em que o back-end est√° sendo executado e roteia a resposta de volta ao front-end.N√¢o foi necess√°rio expor o servi√ßo de back-end √† Internet p√∫blica. O Skupper criou uma rede de aplicativos que conecta os servi√ßos em diferentes clusters. O servi√ßo de back-end est√° localizado no leste, mas o servi√ßo de front-end no oeste pode ‚Äúv√™-lo‚Äù como se fosse local. Quando o front-end envia uma solicita√ß√£o ao back-end, o Skupper encaminha a solicita√ß√£o para o namespace em que o back-end est√° sendo executado e roteia a resposta de volta ao front-end.Nenhuma VPN ou conex√£o Layer 3 foi necess√°ria. O Skupper cria uma rede de aplicativos que conecta os servi√ßos em diferentes clusters. O servi√ßo de back-end est√° localizado no leste, mas o servi√ßo de front-end no oeste pode ‚Äúv√™-lo‚Äù como se fosse local. Quando o front-end envia uma solicita√ß√£o ao back-end, o Skupper encaminha a solicita√ß√£o para o namespace em que o back-end est√° sendo executado e roteia a resposta de volta ao front-end." } ]
