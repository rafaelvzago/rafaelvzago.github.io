[ { "title": "Real-Time Linux: Uma Jornada de Baixa Latência", "url": "/posts/RTL-Linux/", "categories": "linux, rtos, tecnologia", "tags": "linux, rtos, redhat, tecnologia", "date": "2024-12-20 00:00:00 -0300", "snippet": "IntroduçãoReal-Time Linux (RTL) é uma extensão do kernel do Linux que transforma o sistema operacional em um ambiente de tempo real. Isso significa que, além de suas funcionalidades tradicionais, e...", "content": "IntroduçãoReal-Time Linux (RTL) é uma extensão do kernel do Linux que transforma o sistema operacional em um ambiente de tempo real. Isso significa que, além de suas funcionalidades tradicionais, ele agora é capaz de lidar com tarefas que exigem alta previsibilidade e baixa latência, como sistemas de automação industrial, dispositivos médicos e até sistemas de entretenimento.No final de 2024, o Linux Kernel passou a incorporar totalmente o Real-Time Linux (RTL), marcando um momento histórico na evolução do sistema. Mas como chegamos até aqui?A Jornada do RTLA ideia de adicionar capacidades de tempo real ao Linux remonta ao final dos anos 90, quando surgiram os primeiros patches para otimizar o desempenho e reduzir a latência do kernel. Esses patches evoluíram para projetos mais robustos, como o PREEMPT-RT.O PREEMPT-RT permitiu: Preempção total: Tornar possível a interrupção de quase todas as rotinas do kernel. Redução de latências: Melhorar a previsibilidade em execuções críticas.Depois de anos de desenvolvimento comunitário e apoio de empresas como Red Hat, Intel e IBM, o PREEMPT-RT finalmente foi fundido no kernel principal, consolidando o Linux como uma plataforma RTOS (Sistema Operacional de Tempo Real).Comparação: Workload RTL vs. Workload NormalPara cargas de trabalho típicas com requisitos de latência do kernel na faixa de milissegundos (ms), o kernel padrão do Red Hat Enterprise Linux 7 é suficiente. No entanto, se sua carga de trabalho exige requisitos rigorosos de determinismo de baixa latência para recursos centrais do kernel, como manipulação de interrupções e escalonamento de processos na faixa de microssegundos (μs), o kernel de tempo real é a escolha ideal.ReferênciaModelos de Preempção no LinuxOs modelos de preempção do Linux determinam como o kernel gerencia interrupções e tarefas. Esses modelos são definidos no momento da compilação do kernel, sendo o “Kernel Totalmente Preemptível” essencial para obter o comportamento em tempo real. Abaixo está uma descrição dos principais modelos: Sem Preempção Forçada (Servidor): Modelo tradicional focado em maximizar a taxa de transferência. Os pontos de preempção ocorrem apenas em retornos de chamadas de sistema e interrupções. Preempção Voluntária (Desktop): Reduz a latência do kernel adicionando pontos de preempção explícitos no código, em troca de uma leve queda na taxa de transferência. Kernel Preemptível (Desktop de Baixa Latência): Faz com que todo o código do kernel, exceto seções críticas, seja preemptível, com pontos de preempção implícitos após cada desativação de preempção. Kernel Preemptível (RT Básico): Similar ao modelo “Desktop de Baixa Latência”, mas com manipuladores de interrupções em threads. Esse modelo é usado para testes e depuração. Kernel Totalmente Preemptível (RT): Todo o código do kernel é preemptível, exceto em seções críticas selecionadas. Inclui manipuladores de interrupções em threads e mecanismos como spinlocks dormêntes e rt_mutex para minimizar seções não preemptíveis, garantindo comportamento em tempo real.Onde o Real-Time Linux pode ser Aplicado?As aplicações são diversas, mas geralmente se concentram em cenários que exigem desempenho crítico: Automotivo: Sistemas de freios e controle de motores. Industrial: Robótica e automação. Telecomunicações: Redes 5G que requerem baixa latência para processamento de pacotes. Entretenimento: Mixagem de áudio em tempo real. Saúde: Equipamentos médicos sensíveis ao tempo.Exemplo Prático: Testando o Kernel PREEMPT-RTEntendendo o PREEMPT-RTO PREEMPT-RT é um conjunto de patches aplicados ao kernel Linux que permite transformar o sistema operacional em um ambiente de tempo real. Este modelo de preempção reduz drasticamente a latência ao substituir os mecanismos de sincronização convencionais por variantes que suportam preempção. Ele também implementa mecanismos para dividir seções críticas longas e forçar o encadeamento de manipuladores de interrupção.Recursos principais do PREEMPT-RT: Threading de Interrupções: Todas as interrupções são executadas como threads agendáveis, permitindo que o sistema priorize e gerencie tarefas em tempo real. Spinlocks Preemptíveis: Substitui spinlocks padrão por variantes que permitem preempção, minimizando atrasos durante o bloqueio de recursos compartilhados. Herança de Prioridade: Implementação de mutexes que evitam problemas de inversão de prioridade, garantindo que tarefas críticas recebam os recursos necessários no momento certo. Fragmentação de Seções Não Preemptíveis: Reduz o tempo de bloqueio em código crítico, quebrando longas seções não preemptíveis em pedaços menores.Esses recursos tornam o kernel Linux altamente responsivo e adequado para sistemas que exigem previsibilidade e baixa latência, como aplicações em robótica, telecomunicações e equipamentos médicos.A seguir, apresentamos um exemplo de como configurar e testar um kernel com suporte a PREEMPT-RT. Essas instruções foram realizadas em uma máquina virtual Ubuntu 22.04 LTS.Passos:1. Obter o código do kernel mais recente:git clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.gitcd linux2. Configurar o kernel para PREEMPT-RT:make menuconfigNavegue até General Setup / Preemption Model e ative a opção Fully Preemptible Kernel (Real-Time). Salve e saia.Verifique se a configuração foi aplicada:grep PREEMPT_RT .config# Saída esperada: CONFIG_PREEMPT_RT=y3. Compilar o kernel:time make -j$(nproc)4. Instalar e reiniciar:sudo make modules_install &amp;&amp; sudo make installsudo rebootSelecione o novo kernel na inicialização.5. Confirmar a versão:cat /proc/version# Exemplo de saída:# Linux version 6.11.0-rtl+ (gcc (Ubuntu 11.4.0) 11.4.0) #1 SMP PREEMPT_RT Fri Sep 20 19:11:35 IST 2024Agora o kernel está configurado para suportar tarefas de tempo real. Para verificar sua eficiência, execute aplicativos em tempo real como mixagem de áudio com JACK ou PulseAudio.Como Configurar o Red Hat Enterprise Linux for Real TimeO Red Hat Enterprise Linux for Real Time (RHEL-RT) oferece um conjunto de ferramentas e configurações otimizadas para aplicações sensíveis à latência. Seguem os passos para configurar e aproveitar ao máximo o RHEL-RT:1. Pré-requisitos Certifique-se de que sua subscrição Red Hat inclui o canal do RHEL for Real Time. Atualize seu sistema:sudo dnf update -y2. Instalação do Kernel RTInstale o kernel otimizado para tempo real:sudo dnf install kernel-rt kernel-rt-devel3. Seleção do Kernel RT no BootloaderDepois de instalar o kernel, configure o bootloader para usar o kernel RT como padrão:grub2-set-default \"Red Hat Enterprise Linux (kernel-rt)\"sudo grub2-mkconfig -o /boot/grub2/grub.cfgsudo reboot4. Ajustes de LatênciaApós reiniciar no kernel RT, use ferramentas como tuna para ajustar prioridades e afinidades de CPU:sudo tuna -t irq -qsudo tuna -t \"[sua aplicação]\" -p 99Configure o particionamento da CPU para isolar núcleos dedicados a tarefas de tempo real:echo 1 &gt; /sys/devices/system/cpu/cpu[X]/isolated5. Ferramentas de DiagnósticoUtilize ferramentas como cyclictest para medir a latência:sudo cyclictest -m -Sp99 -i100 -h300 -qComo o RTL foi Implementado pela Red Hat?A Red Hat contribuiu de forma significativa para a integração do PREEMPT-RT no kernel principal. No Red Hat Enterprise Linux for Real Time, várias otimizações foram feitas para: Otimizar latências: Ajustes no agendador e gerenciamento de interrupções. Ferramentas especializadas: Perfis de kernel personalizados e ferramentas como tuna para ajustar prioridades em tempo real. Segurança: Garantir que as modificações não comprometem a estabilidade do sistema.ConclusãoA inclusão do Real-Time Linux no kernel principal marca um ponto de virada para o Linux como um sistema operacional universal. Agora, ele é capaz de atender tanto aplicações convencionais quanto ambientes que exigem altíssima previsibilidade.Seja você um desenvolvedor interessado em explorar o potencial do Linux em sistemas embarcados ou um entusiasta de tecnologia, o RTL abre novas portas para inovações em diversas áreas.Referências Linux Foundation. “Real-Time Linux Documentation.” Disponível em: https://wiki.linuxfoundation.org/realtime/documentation/start. Acesso em: 20 dez. 2024. Linux Foundation. “Kernel PREEMPT-RT.” Disponível em: https://wiki.linuxfoundation.org/realtime/documentation/technical_basics/preemption_models. Acesso em: 20 dez. 2024. Red Hat. “Red Hat Enterprise Linux for Real Time.” Disponível em: https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/7/html/installation_guide/chap-why_use_rt_to_optimize_latency#chap-Why_Use_RT_to_Optimize_Latency. Acesso em: 20 dez. 2024. Kaiwan N Billimoria. “The Linux Kernel is Now an RTOS.” Blog Kaiwan Tech. Disponível em: https://kaiwantech.wordpress.com/2024/09/21/the-linux-kernel-is-now-an-rtos-with-rtl-being-fully-merged/. Acesso em: 20 dez. 2024." }, { "title": "TCP/IP O início e a evolução", "url": "/posts/protocolos-TCP-IP-o-inicio/", "categories": "networking, tcpip", "tags": "networking, tcpip, tecnologia", "date": "2024-12-14 00:00:00 -0300", "snippet": "Protocolos TCP/IP: Uma Introdução CompletaO ARPANET e as Origens do TCP/IPA história dos protocolos TCP/IP começa no final dos anos 1950, durante o auge da Guerra Fria. O Departamento de Defesa dos...", "content": "Protocolos TCP/IP: Uma Introdução CompletaO ARPANET e as Origens do TCP/IPA história dos protocolos TCP/IP começa no final dos anos 1950, durante o auge da Guerra Fria. O Departamento de Defesa dos EUA (DoD) buscava uma rede de comando e controle que pudesse sobreviver a um ataque nuclear. Na época, as comunicações militares utilizavam a rede telefônica pública, considerada vulnerável devido à sua hierarquia rígida e falta de redundância.Início da Pesquisa e Contribuições de Paul BaranEm torno de 1960, o DoD contratou a RAND Corporation para encontrar uma solução. Paul Baran propôs um design distribuído altamente tolerante a falhas, que usava tecnologia de comutação de pacotes digitais em vez de sinais analógicos. Apesar da resistência inicial de grandes empresas como a AT&amp;T, a ideia de Baran lançou as bases para as redes resilientes modernas.O Papel da ARPAEm resposta ao lançamento do satélite Sputnik pela União Soviética em 1957, o governo dos EUA criou a ARPA (Advanced Research Projects Agency). A ARPA iniciou esforços em redes de computadores para promover a pesquisa científica e tecnológica. Larry Roberts, um dos gerentes da ARPA, decidiu construir uma rede baseada em comutação de pacotes, influenciado pelo trabalho de Paul Baran e Donald Davies.Estrutura do ARPANETA ARPANET foi projetada como uma rede de sub-redes de comutação de pacotes composta por minicomputadores chamados IMPs (Interface Message Processors). Esses IMPs, conectados por linhas de transmissão de 56 kbps, formaram a primeira rede eletrônica de comutação de pacotes que utilizava o método de armazenamento e encaminhamento para transmitir dados de forma confiável.Cada nó da rede era composto por um IMP e um host, conectados localmente por fios curtos. Mensagens de até 8063 bits eram divididas em pacotes menores e transmitidas de forma independente, permitindo o roteamento dinâmico caso partes da rede fossem destruídas. A rede foi projetada para ser resiliente, com cada IMP conectado a pelo menos dois outros, garantindo redundância.Crescimento e ImpactoA ARPANET entrou em operação em dezembro de 1969 com quatro nós iniciais: UCLA, UCSB, SRI e a Universidade de Utah. Em poucos anos, a rede cresceu rapidamente, conectando mais instituições e redes. Durante os anos 1980, a integração de novas redes e a criação do DNS (Domain Name System) facilitaram o gerenciamento de endereços e nomes de host.Essa expansão culminou na criação dos protocolos TCP/IP, projetados para interconectar redes heterogêneas. Contratos foram estabelecidos com universidades e empresas para implementar os protocolos em diferentes plataformas, consolidando o TCP/IP como padrão global de comunicação em redes.Introdução ao Modelo TCP/IPOs protocolos TCP/IP (Transmission Control Protocol/Internet Protocol) formam a espinha dorsal da comunicação na internet moderna. Este artigo fornece uma revisão abrangente sobre os protocolos, suas camadas e como eles trabalham juntos para permitir a transmissão de dados em redes locais e globais.O Modelo TCP/IP: Introdução e Primeira CamadaO modelo TCP/IP é um framework fundamental para a comunicação de dados em redes modernas, estruturado em quatro camadas principais. Cada camada desempenha uma função específica, permitindo que os dados sejam transmitidos de forma eficiente e confiável. Neste artigo, começaremos com uma análise detalhada da primeira camada: Camada de Aplicação.Camada de Aplicação: A Interface do UsuárioA Camada de Aplicação no modelo TCP/IP representa o ponto de contato direto entre os usuários e a rede. Ela oferece as ferramentas e protocolos necessários para que aplicativos e serviços possam interagir com o sistema de comunicação. Esta camada traduz solicitações e respostas de aplicações em dados compreensíveis pelas camadas inferiores do modelo.Essa camada também é conhecida como a Camada 7 no modelo OSI (Open Systems Interconnection), que é um modelo de referência semelhante ao TCP/IP. No entanto, o modelo TCP/IP é mais amplamente utilizado e mais diretamente relacionado à arquitetura da internet.Funcionalidades Principais Interação com Aplicações: Oferece serviços que permitem que aplicativos de software utilizem a rede para transmitir dados. Processamento de Dados: Manipula a estrutura dos dados para garantir compatibilidade com protocolos de transporte. Serviços de Rede: Facilita a implementação de serviços específicos, como transferência de arquivos, envio de e-mails e navegação na web.Exemplos de Protocolos na Camada de Aplicação HTTP/HTTPS (Hypertext Transfer Protocol): Facilita a comunicação entre navegadores e servidores web, essencial para a navegação na internet. FTP (File Transfer Protocol): Utilizado para a transferência de arquivos entre computadores. SMTP (Simple Mail Transfer Protocol): Gerencia o envio de e-mails. DNS (Domain Name System): Resolve nomes de domínio em endereços IP.Estrutura TécnicaOs protocolos na Camada de Aplicação não apenas facilitam a comunicação, mas também incorporam funcionalidades como autenticação, compressão e criptografia. Por exemplo, o HTTPS adiciona segurança ao HTTP usando o protocolo SSL/TLS para criptografar dados transmitidos.Modelo de DadosOs dados processados nesta camada são encapsulados e formatados em mensagens, que serão transmitidas para a próxima camada. A seguir, está o fluxo de dados típico dentro da camada de aplicação:Aplicações no Dia a DiaA Camada de Aplicação é amplamente utilizada por programas que fazem parte do nosso cotidiano: Navegadores Web: Ao acessar um site, como “www.example.com”, o navegador utiliza o HTTP ou HTTPS para enviar solicitações e receber respostas do servidor web. Clientes de E-mail: Programas como Microsoft Outlook ou Thunderbird utilizam protocolos como SMTP, IMAP ou POP3 para enviar e receber mensagens. Streaming de Vídeo: Serviços como Netflix e YouTube empregam protocolos como HTTP/HTTPS para entrega de vídeos, muitas vezes utilizando redes de distribuição de conteúdo (CDN). Aplicativos de Mensagens: WhatsApp e Telegram utilizam protocolos de comunicação baseados em HTTP/HTTPS e outros serviços da camada de aplicação para troca de mensagens instantâneas e arquivos. Jogos Online: Muitos jogos dependem de APIs baseadas em HTTP/HTTPS para autenticação e sincronização de dados, além de outros protocolos específicos.Importância na Arquitetura de RedesA Camada de Aplicação é considerada crítica porque estabelece os fundamentos para a interação humano-computador nas redes. Sem esta camada, o uso prático da internet seria impossível, pois não haveria um meio eficaz de traduzir as intenções humanas em solicitações processáveis pela rede.Testando a Camada de Aplicação com PythonPara demonstrar a funcionalidade da Camada de Aplicação, podemos realizar um teste prático utilizando um script em Python que simula uma solicitação HTTP para um servidor web. Aqui está o código:# Importar a biblioteca de sockets para comunicação de redeimport socket# Função para testar a camada de aplicação usando o protocolo HTTPdef test_application_layer(host: str, port: int): \"\"\"Função para testar a camada de aplicação usando o protocolo HTTP.\"\"\" try: # Criar um socket para comunicação com o servidor with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as client_socket: # Conectar ao servidor especificado pelo host e porta client_socket.connect((host, port)) # Preparar uma solicitação HTTP GET simples http_request = f\"GET / HTTP/1.1\\r\\nHost: {host}\\r\\nConnection: close\\r\\n\\r\\n\" # Enviar a solicitação HTTP para o servidor client_socket.sendall(http_request.encode()) # Receber a resposta do servidor em partes (chunks) response = b\"\" while True: # Receber um chunk de dados do servidor chunk = client_socket.recv(4096) # Se não houver mais dados, interromper o loop if not chunk: # Se não houver mais dados, interromper o loop break # Adicionar o chunk recebido à resposta completa response += chunk # Exibir a resposta completa do servidor no console print(\"Resposta do Servidor:\") # Decodificar a resposta binária em texto print(response.decode()) except Exception as e: # Capturar e exibir qualquer erro que ocorra durante o teste print(f\"Erro ao testar a camada de aplicação: {e}\")# Testar a função com um servidor HTTP específicotest_application_layer(\"www.example.com\", 80)Output EsperadoQuando executado, o script realiza uma solicitação HTTP para www.example.com e exibe a resposta do servidor. O output será semelhante ao seguinte:$ python aplicacao.pyResposta do Servidor:HTTP/1.1 200 OKAge: 119377Cache-Control: max-age=604800Content-Type: text/html; charset=UTF-8Date: Sat, 14 Dec 2024 03:53:09 GMTEtag: \"3147526947+ident\"Expires: Sat, 21 Dec 2024 03:53:09 GMTLast-Modified: Thu, 17 Oct 2019 07:18:26 GMTServer: ECAcc (mid/8790)Vary: Accept-EncodingX-Cache: HITContent-Length: 1256Connection: close&lt;!doctype html&gt;&lt;html&gt;...Essa demonstração prática destaca como os protocolos na Camada de Aplicação, como HTTP, facilitam a comunicação entre clientes e servidores em redes modernas. Sem esta camada, o uso prático da internet seria impossível, pois não haveria um meio eficaz de traduzir as intenções humanas em solicitações processáveis pela rede.Referências Tanenbaum, A. S., &amp; Wetherall, D. J. (2011). Computer Networks. Baran, P. (1964). On Distributed Communications: Introduction to Distributed Communications Network. Roberts, L. (1967). Multiple Computer Networks and Intercomputer Communication. Braden, R. (1989). RFC 1122: Requirements for Internet Hosts - Communication Layers. Clark, D. D. (1988). The Design Philosophy of the DARPA Internet Protocols. Cerf, V., &amp; Kahn, R. E. (1974). A Protocol for Packet Network Intercommunication.Próximos PassosNos próximos artigos, exploraremos as camadas subsequentes do modelo TCP/IP, detalhando suas funções e protocolos associados. A próxima será a Camada de Transporte, onde examinaremos o papel do TCP e UDP na comunicação confiável e eficiente." }, { "title": "Running local AI with Instruct Lab and Skupper", "url": "/posts/running-local-ai-with-instruct-lab/", "categories": "skupper, instructlab, chatbot", "tags": "cloud, network, redhat", "date": "2024-08-01 00:00:00 -0300", "snippet": "Welcome to the Ollama Pilot.Problem to solveThe main goal of this project is to create a secure connection between two sites, enabling the communication between the engineer machine and an Instruct...", "content": "Welcome to the Ollama Pilot.Problem to solveThe main goal of this project is to create a secure connection between two sites, enabling the communication between the engineer machine and an Instruct Lab Model. The merlinite-7b-lab-Q4_K_M.gguf model will be used for the chatbot, and it is available in the Instruct Lab. The license of the model is available in the Instruct Labs.But, why the banner? Well, the engineer needs to know who is better, Lebron or Jordan. The chatbot will be responsible for answering this question. The chatbot will receive the user input and send it to the llama3 model. The response from the merlinite model will be sent back to the user.Disclaimer All the models used are available in the Hugging Face model hub. The models are not hosted in this project, they are hosted by Hugging Face. The models are used for educational purposes only.Why InstructLabThere are many projects rapidly embracing and extending permissively licensed AI models, but they are faced with three main challenges: Contribution to LLMs is not possible directly. They show up as forks, which forces consumers to choose a “best-fit” model that isn’t easily extensible. Also, the forks are expensive for model creators to maintain. The ability to contribute ideas is limited by a lack of AI/ML expertise. One has to learn how to fork, train, and refine models to see their idea move forward. This is a high barrier to entry. There is no direct community governance or best practice around review, curation, and distribution of forked models.This snippet was extracted from the Instruct Labs repository.Why SkupperHere the answer is simple, Skupper is a tool that enables secure communication between services in different environments. Skupper will be used to create a secure connection between the two sites, one of the sites has restricted access to the internet. Skupper will enable the communication between the two sites, allowing the Ollama Pilot application to send requests to the llama3 model thru the Instruct Lab chat.DescriptionThis project has the objective to create a VAN (Virtual Application Network) that enables the connection between two sites: Site A: A server that hosts the Instruct Lab chat model. This model will be responsible for receiving the user input and sending it to the llama3 model. The response from the llama3 model will be sent back to the user. Site B: An OpenShift site that exposes the Instruct Lab chat model. This site will be responsible for sending the user input to the Instruct Lab chat model and receiving the response from the Merlinite-7b-lab-Q4_K_M.gguf model. In order to connect the two sites, we will use Skupper, a tool that enables secure communication between services in different environments. Skupper will be used to create a secure connection between the two sites, allowing the Ollama Pilot application to send requests to the llama3 model and receive the response from the merlinite model.At the end of the project, you will be able to use your own CHATBOT with protected data.ArchitectureSummary AI model deployment with InstructLab Private Skupper deployment Public Skupper deployment Secure communication between the two sites with Skupper Chatbot with protected data1. AI model deployment with InstructLabThe first step is to deploy the InstructLab chat model in the InstructLab site. The InstructLab chat model will be responsible for receiving the user input and sending it to the llama3 model. The response from the llama3 model will be sent back to the user. This is based on the article: Getting started with InstructLab for generative AI model tuningmkdir instructlab &amp;&amp; cd instructlab python3.11 -m venv venv source venv/bin/activatepip install 'instructlab[cuda]' -C cmake.args=\"-DLLAMA_CUDA=on\" -C cmake.args=\"-DLLAMA_NATIVE=off\" IMPORTANT: This installation method will enable your Nvidia GPU to be used by instructlab. If you don’t have an Nvidia GPU, please check other options in: InstructLab 🐶 (ilab)ilab config initTo enable external access to your model, please modify the config.yaml file:chat: context: default greedy_mode: false logs_dir: data/chatlogs max_tokens: null model: models/merlinite-7b-lab-Q4_K_M.gguf session: null vi_mode: false visible_overflow: truegeneral: log_level: INFOgenerate: chunk_word_count: 1000 model: models/merlinite-7b-lab-Q4_K_M.gguf num_cpus: 10 num_instructions: 100 output_dir: generated prompt_file: prompt.txt seed_file: seed_tasks.json taxonomy_base: origin/main taxonomy_path: taxonomyserve: gpu_layers: -1 host_port: 0.0.0.0:8000 # HERE max_ctx_size: 4096 model_path: models/merlinite-7b-lab-Q4_K_M.ggufNow, you can download and start your server:ilab model downloadilab model serve# The output should be similar to:INFO 2024-07-30 18:59:01,199 serve.py:51: serve Using model 'models/merlinite-7b-lab-Q4_K_M.gguf' with -1 gpu-layers and 4096 max context size.INFO 2024-07-30 18:59:01,611 server.py:218: server Starting server process, press CTRL+C to shutdown server...INFO 2024-07-30 18:59:01,612 server.py:219: server After application startup complete see http://0.0.0.0:8000/docs for API.2. Private Skupper deploymentThe second step is to deploy the private Skupper in Site A. The private Skupper will be responsible for creating a secure connection between the two sites, allowing the Ollama Pilot application to send requests to the llama3 model and receive the response from the merlinite model. Open a new terminal and run the following commands:Install Skupperexport SKUPPER_PLATFORM=podmanskupper init --ingress noneExposing the InstructLab chat modelIn order to do this, we will bind the local service that is running the InstructLab chat model to the Skupper service.skupper expose host host.containers.internal --address instructlab --port 8000Let’s check the status of the Skupper service:skupper service statusServices exposed through Skupper:╰─ instructlab:8000 (tcp)Now, we are almost ready to connect the two sites. The next step is to deploy the public Skupper in Site B and create a connection between the two sites.3. Public Skupper deploymentThe third step is to deploy the public Skupper in Site B. The public Skupper will receive the connection from the private Skupper and create a secure connection between the two sites. Open a new terminal and run the following commands: Creating the project and deploying the public Skupper:oc new-project ollama-pilotskupper init --enable-console --enable-flow-collector --console-user admin --console-password admin Creating the token to allow the private Skupper to connect to the public Skupper:skupper token create token.yamlAt this point, you should have a token.yaml file with the token to connect the two sites. The next step is to link the two sites. For this, we will need to switch back to the terminal where the private Skupper is running.4. Secure communication between the two sites with SkupperThe fourth step is to connect the two sites. In the terminal where the private Skupper is running, run the following command:skupper link create token.yaml --name instructlab # Or any other name you wantLet’s check the status of the Skupper link:skupper link statusLinks created from this site: Link instructlab is connectedCurrent links from other sites that are connected: There are no connected links Before continuing, let’s hop back to the terminal where the public Skupper is running and check the status of the link:skupper link statusLinks created from this site: There are no links configured or connectedCurrent links from other sites that are connected: Incoming link from site b8ad86d5-9680-4fea-9c07-ea7ee394e0bd5. Chatbot with protected dataNow the last part is to expose the service in the public Skupper and create the Ollama Pilot application. Still on the terminal where the public Skupper is running, run the following command to expose the service. With the following command, we will create a Skupper service that matches the service exposed by the private Skupper. This will end up creating a Kubernetes service that will be used by the Ollama Pilot application.skupper service create instructlab 8000 Exposing the service to the internet:oc expose service instructlab Getting the public URL:oc get route instructlabNAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARDinstructlab instructlab-ollama-pilot.apps.your-cluster-url instructlab port8000 None The last step is to create the Ollama Pilot application. The Ollama Pilot application will be responsible for sending the user input to the Instruct Lab chat model and receiving the response from the Merlinite-7b-lab-Q4_K_M.gguf model. The Ollama Pilot application will be able to send requests to the Instruct Lab chat model through the secure connection created by Skupper.You can repeat all the instructions in step 1. AI model deployment with InstructLab to install the Instruct Lab chat model in Site B. The only difference is that you will not run the ilab model serve command because the Instruct Lab chat model is already running in Site A.The Ollama Pilot application will be responsible for sending the user input to the Instruct Lab chat model and receiving the response from the Merlinite-7b-lab-Q4_K_M.gguf model. The Ollama Pilot application will be able to send requests to the Instruct Lab chat model through the secure connection created by Skupper.ilab model chat --endpoint-url http://instructlab-ollama-pilot.apps.your-cluster-url/v1/╭─────────────────────────────────────────────── system ────────────────────────────────────────────────│ Welcome to InstructLab Chat w/ MODELS/MERLINITE-7B-LAB-Q4_K_M.GGUF (type /h for help)╰──────────────────────────────────────────────────────────────────────────────────────────────────────&gt;&gt;&gt; [S][default]THE question: Yes or No question. Don’t fool me. Is LeBron better than Jordan?Have fun with your new chatbot with protected data! If you don’t agree with the answer, you can always ask again and train your model, but King James is the best!" }, { "title": "Vim Motions: Navigating and Editing Code Efficiently", "url": "/posts/vim-motions/", "categories": "vim, productivity", "tags": "vim, developer", "date": "2024-07-02 14:31:00 -0300", "snippet": "Vim Motions: Your Keyboard Shortcut PowerhouseVim motions are a set of commands that empower you to navigate and edit code like a pro. This guide dives into different Vim motions and how to harness...", "content": "Vim Motions: Your Keyboard Shortcut PowerhouseVim motions are a set of commands that empower you to navigate and edit code like a pro. This guide dives into different Vim motions and how to harness them for lightning-fast coding.My Vim Journey: From VSCode and IntelliJ to NeovimAfter years of using VSCode and IntelliJ, I decided to make the switch to Neovim as my primary development tool. This series of posts will document my journey and share the tips, tricks, and configurations that have made Neovim an indispensable part of my workflow.Today, we’re starting with the foundation: Vim motions. Mastering these commands is key to unlocking the full potential of Vim’s editing power.Disclaimer: This is not meant to be a flamewar about editors. It’s simply a reflection of what has worked best for me and an invitation for you to explore if Vim might be a good fit for your own development style.Vim Plugins: My Productivity ArsenalOne of the things that makes Vim (and Neovim) so powerful is the ability to customize it with plugins. Here are some of the plugins I rely on for maximum productivity: “Vundle.vim” “undotree” “vim-fugitive” “gruvbox” “copilot.vim” “vim-log-highlighting” “nerdtree” “lightline.vim” “vim-gitbranch” “vim-terraform” “vim-go” “fzf” “ale” “fzf.vim” “vim-tmux-navigator”(Complete plugin setup and details will be covered in future posts.)The Vim Editor: More Than Meets the EyeVim is a highly customizable text editor known for its modal nature. Its modes – Normal, Insert, and Visual – cater to distinct tasks, allowing you to switch seamlessly between command input and text editing.Vim Plugins: Supercharge Your Vim ExperienceVim’s capabilities extend far beyond its core features. With a vast array of community-maintained plugins, you can transform Vim into a full-fledged Integrated Development Environment (IDE).Vim Motions in ActionBy mastering Vim motions, you’ll write and navigate code with impressive speed. Even popular IDEs like VS Code offer Vim plugins, enabling you to leverage Vim’s navigation within your preferred environment.Vim Modes: Normal Mode: Your command center for issuing instructions. Insert Mode: Where the actual code writing happens. Visual Mode: Select and manipulate text visually, with options for both normal and block selection.Vim also has a leader key for creating custom shortcuts, and a command mode for operations like saving files.Navigating Your CodebaseLet’s dive into a React app and explore how Vim motions streamline navigation: Basic Movements (h, j, k, l): Forget arrow keys! Use these for left, down, up, and right movement. Prefix with a number (e.g., 5j) to move multiple lines. Word Navigation (w, b, e): Jump forward (w), backward (b), or to the end (e) of words. Use a number prefix for multiple word jumps. Line Navigation (0, ^, g, $, f, F): Go to the start (0), first non-blank character (^), end ($), or search for a character (f forward, F backward). Vertical Navigation ((), {}, Ctrl+D/U, Ctrl+F/B, G): Navigate by sentences (( and )), paragraphs ({ and }), half pages (Ctrl+D, Ctrl+U), full pages (Ctrl+F, Ctrl+B), start of file (gg), and end of file (G). Entering Insert Mode: Multiple Entry PointsVim offers various ways to enter insert mode: Before cursor: i After cursor: a Beginning of line: I End of line: A Below current line: o Above current line: OOther insert mode triggers include c (change), s (substitute), y (yank/copy), and p (paste). You can even copy entire lines with yy.Learning MoreVim’s learning curve can be steep, but the rewards are immense. To deepen your knowledge: Vim Documentation: https://vimdoc.sourceforge.io/index.html Vim Tutorial: https://www.tutorialspoint.com/vim/vim_tutorial.htm Vim Cheat Sheet: https://www.vim.org/doc/vimtutor/vimtutor.pdfHappy Vimming!" }, { "title": "Workshop: Patient Portal, conectando um banco de dados a um cluster K8S com Skupper", "url": "/posts/workshop-skupper-patient-portal/", "categories": "skupper, multi, cloud, network, redhat", "tags": "cloud, network, redhat", "date": "2024-07-02 00:00:00 -0300", "snippet": "DescriçãoEste workshop tem como objetivo apresentar o Red Hat Service Interconnect, uma solução de integração de aplicações que permite a comunicação entre diferentes sistemas de forma eficiente e ...", "content": "DescriçãoEste workshop tem como objetivo apresentar o Red Hat Service Interconnect, uma solução de integração de aplicações que permite a comunicação entre diferentes sistemas de forma eficiente e segura.Arquitetura da SoluçãoTopologia de ServiçosResumo do Workshop Logar no Red Hat Developer. Criar um cluster Openshift. Acessar o cluster Openshift. No projeto do Red Hat Openshift Sandbox, acessar o seu projeto. Criar uma máquina virtual no Openshift Virtualization. Instalar pacotes na máquina virtual: podman kubernetes-client skupper oc wget Fazer o deploy do banco de dados com o podman. Fazer o deploy do frontend e do backend da aplicação. Configurar o Service Interconnect (Skupper) para fazer a comunicação do banco de dados rodando em um podman com a aplicação rodando no Openshift. Acessar a aplicação e verificar se a comunicação está funcionando. Considerações.Links Recurso Link [1] Red Hat Developer https://developers.redhat.com/ [2] OC https://docs.openshift.com/container-platform/4.15/cli_reference/openshift_cli/getting-started-cli.html [3] Skupper https://skupper.io/ Pré-requisitos Conta no Red Hat Developer Conhecimento básico em Kubernetes Conhecimento básico em Red Hat OpenShift Conhecimento básico em Podman Google Chrome, a preferência por ele é pela funcionalidade de colar comandos no console da máquina virtual pelo VNC via browser.Passo a passo1. Logar no Red Hat DeveloperAcesse o site do Red Hat Developer e faça o login com a sua conta.2. Criar um cluster Openshift Sandbox2.1. Acesse o Red Hat Openshift Sandbox e clique em “Start Cluster”.2.2. Inicie o cluster Openshift Sandbox.4. Acessar o cluster OpenshiftAcesse o cluster Openshift Sandbox e clique em “Open Console”.5. No projeto do Red Hat Openshift Sandbox, acessar o seu projetoClique no seu projeto e mude para a view “Administrator”.6. Criar uma máquina virtual no Openshift Virtualization Acesse Virtualization no menu do cluster Openshift e clique em Virtual Machines. Clique em Create Virtual Machine. Escolha From Template e selecione o template Fedora VM. Clique em Create VirtualMachine.7. Instalar pacotes na máquina virtual Acesse a máquina virtual e clique em Console. (Dê preferencia para o Google Chrome, pois ele tem a funcionalidade de colar comandos no console da máquina virtual pelo VNC via browser). Logue com as credenciais que estão no console. Execute os comandos abaixo para instalar os pacotes necessários: sudo dnf install -y podman kubernetes-client wget# Instalar o ocwget -qO- https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/openshift-client-linux.tar.gz | tar xz -C ~/.local/binexport PATH=\"$HOME/.local/bin:$PATH\"# Instalar o skuppercurl https://skupper.io/install.sh | sh 8. Fazer o deploy do banco de dados com o podman Execute o comando abaixo para fazer o deploy do banco de dados:podman network create skupperpodman run --name database-target --network skupper --detach --rm -p 5432:5432 quay.io/skupper/patient-portal-database9. Fazer o deploy do frontend e do backend da aplicação No seu console openshift, faça o deploy do seguinte yaml para o frontend:apiVersion: apps/v1kind: Deploymentmetadata: labels: app: frontend name: frontendspec: replicas: 3 selector: matchLabels: app: frontend template: metadata: labels: app: frontend spec: containers: - name: frontend image: quay.io/skupper/patient-portal-frontend env: - name: DATABASE_SERVICE_HOST value: database - name: DATABASE_SERVICE_PORT value: \"5432\" - name: PAYMENT_PROCESSOR_SERVICE_HOST value: payment-processor - name: PAYMENT_PROCESSOR_SERVICE_PORT value: \"8080\" ports: - containerPort: 8080 No seu console openshift, faça o deploy do seguinte yaml para o backend:apiVersion: apps/v1kind: Deploymentmetadata: labels: app: payment-processor name: payment-processorspec: replicas: 3 selector: matchLabels: app: payment-processor template: metadata: labels: app: payment-processor spec: containers: - name: payment-processor image: quay.io/skupper/patient-portal-payment-processor ports: - containerPort: 808010. Configurar o Service Interconnect (Skupper) para fazer a comunicação do banco de dados rodando em um podman com a aplicação rodando no Openshift.Para isso, vamos dividir em 3 etapas: Configuração do Cluster Kubernetes Configuração do Site Podman Expor o serviço do banco de dados para a VAN do Skupper Configuração do Cluster Kubernetes: Iniciar o skupper no cluster oenshift com o console habilitado skupper init --enable-console --enable-flow-collector --console-user admin --console-password admin Acessar o console do skupper, para isso acesse as rotas do seu cluster Openshift, a URL estará lá. Criando um token para conectar o site podman com o cluster Openshift skupper token create ./skupper-token.yaml Configuração do Site Podman: Acesse a máquina virtual e execute o comando abaixo para conectar o site podman com o cluster Openshift Ininie o skupper no site podman, sem ingress. skupper switch podman # para mudar o contexto para podman o padrão é kubernetes Conecte o site podman com o cluster Openshift skupper link create ./skupper-token.yaml Acesse o console do skupper no cluster Openshift e verifique se o site podman está conectado. Expor o serviço do banco de dados para a VAN do Skupper: Expor o serviço do banco de dados para a VAN do Skupper systemctl --user enable --now podman.socketskupper service create database 5432skupper service bind database host database-target --target-port 5432 No cluster Openshift, vamos criar um serviço Skupper para o banco de dados, esse serviço vai apontar para o serviço do banco de dados que está rodando no site podman, através da VAN do Skupper. skupper service create database 5432 Agora, a aplicação frontend e backend estão se comunicando com o banco de dados que está rodando em um site podman, através da VAN do Skupper.13. Acessar a aplicação e verificar se a comunicação está funcionandoPara isso, vamos precisar executar algumas tarefas para expor o frontend no cluster Openshift. Criar um serviço para o fronend que aponte para o deployment dele use o seguinte YAML:apiVersion: v1kind: Servicemetadata: name: frontend namespace: SEU-NAME-SPACEspec: selector: app: frontend ports: - protocol: TCP port: 8080 targetPort: 8080 Criar uma rota que aponte para o serviço do frontend.kind: RouteapiVersion: route.openshift.io/v1metadata: name: fronted namespace: SEU-NAME-SPACE labels: {}spec: to: kind: Service name: frontend tls: {} port: targetPort: 8080 alternateBackends: []14. Considerações O Red Hat Service Interconnect (Skupper):Oferece uma solução poderosa para integrar aplicações em diferentes ambientes, simplificando a comunicação entre serviços e proporcionando maior flexibilidade e escalabilidade. Ao abstrair a complexidade da rede subjacente, o Skupper permite que os desenvolvedores se concentrem na lógica de negócios de suas aplicações, sem se preocupar com os detalhes de conectividade. Com recursos como descoberta de serviços automática:O roteamento inteligente e segurança integrada, o Skupper garante que as aplicações possam se comunicar de forma eficiente e segura, independentemente de sua localização. Essa abordagem simplifica a gestão da infraestrutura e reduz a necessidade de configurações manuais, agilizando o desenvolvimento e a implantação de aplicações distribuídas. Além disso, o Skupper oferece uma interface de usuário intuitiva e ferramentas de linha de comando poderosas, facilitando a configuração e o monitoramento da comunicação entre serviços. Com sua arquitetura extensível e suporte a diversos protocolos, o Skupper se adapta a diferentes cenários de integração, atendendo às necessidades de projetos de todos os portes.ResumoNeste workshop, você aprendeu como usar o Red Hat Service Interconnect (Skupper) para conectar um banco de dados a um cluster Kubernetes, permitindo que aplicações distribuídas se comuniquem de forma eficiente e segura. Com o Skupper, você pode simplificar a integração de serviços em ambientes heterogêneos, facilitando o desenvolvimento e a implantação de aplicações modernas. Esperamos que este workshop tenha sido útil e que você possa aplicar esses conhecimentos em seus próprios projetos. Obrigado por participar!" }, { "title": "Using Skupper and OpenShift AI/ML to Prevent Insurance Fraud", "url": "/posts/AI-com-skupper-para-previnir-fraudes/", "categories": "AI, Skupper", "tags": "zago, rafael", "date": "2024-06-17 00:00:00 -0300", "snippet": "DescriptionThis workshop demonstrates how to use Skupper to connect local data services to cloud-based AI/ML environments. The workshop includes a Go application in a podman container that exposes ...", "content": "DescriptionThis workshop demonstrates how to use Skupper to connect local data services to cloud-based AI/ML environments. The workshop includes a Go application in a podman container that exposes internal data for Skupper connection. The AI/ML model training is performed in an OpenShift AI cluster on AWS using Openshift AI/ML services.DisclaimerThis lab uses the example from the AI/ML Workshop created by the Red Hat AI Services team. The original workshop is available on GitHub and includes all the necessary information to run the lab. The lab was adapted to use Skupper to connect the local data services to the cloud-based AI/ML environment.In order to faciliate the execution, for those who have access to the demo.redhat.com environment, you can start the lab by clicking here. If you don’t have access to the demo environment, you can follow the steps at the gitub repository mentioned above.References Red Hat AI/ML Workshop GO Application to expose internal data Modified examples for the workshop The Developers Conference Workshop Repository SkupperWorkshop OverviewThis lab demonstrates how AI/ML technologies can solve a business problem. The information, code, and techniques presented illustrate a prototype solution. Key steps include: Storing raw claim data within the company. Using a Go application in a podman container to expose internal data for Skupper connection. Setting up AI/ML model training in an OpenShift AI cluster on AWS. Connecting local data to cloud-based AI/ML services using Skupper.Skupper RoleSkupper provides secure, efficient connections between different environments. In this workshop, it connects local data services containing sensitive insurance claim information to a cloud-based AI/ML environment. This secure connection allows remote data access and processing while maintaining data integrity and security.Process Structure Context Connection and Setup LLM for Text Summarization LLM for Information Extraction LLM for Sentiment AnalysisScenarioWe are a multinational insurance company undergoing digital transformation. A small team has analyzed the claims process and proposed improvements. The goal is to integrate the claims processing solution with text analysis using our API in a Kubernetes cluster on AWS.ChallengesUsing Skupper to Ensure Data Security and Integrity Maintaining data integrity and security: Skupper encrypts all data traffic, ensuring sensitive data protection during transmission. Processing emails with OpenShift AI in the on-premises datacenter. Keeping applications with sensitive data within the company. Ensuring secure connections between data services and datacenters.Prototyping Work ExamplesUsing an LLM for Text SummarizationAn LLM can summarize long emails, allowing insurance adjusters to quickly understand key details.Using an LLM for Information ExtractionAn LLM extracts key information from emails and automatically populates structured forms.Using an LLM for Sentiment AnalysisAn LLM identifies customer sentiment, allowing for prompt action based on text tone.How to Use LLMs? Notebook for using LLM Notebook for text summarization with LLM Notebook for information extraction with LLM Notebook for comparing LLM modelsPart 2: Hands-OnActivities Install Skupper binary Install Skupper locally Install Skupper on the OpenShift Cluster Linking the sites Run the application inside the podman site and expose the service Execute the workshop with modified examplesSteps Installing the Skupper binary curl https://skupper.io/install.sh | sh Installing Skupper on the podman site export SKUPPER_PLATFORM=podman podman network create skupper skupper init --ingress none Install Skupper on the OpenShift Cluster skupper init --enable-console --enable-flow-collector --console-user admin --console-password admin Linking the sites Creating the token on the most exposed cluster skupper token create /tmp/insurance-claim Linking the podman site to the most exposed cluster skupper link create /tmp/insurance-claim --name ai Running the application inside the podman site and exposing the service podman run -d --network skupper -p 8080:8080 -v /home/rzago/Code/go-flp/data:/app/data --name insurance-claim-data quay.io/rzago/insurance-claim-data:latest skupper service create backend 8080 skupper service bind backend host insurance-claim-data --target-port 8080 skupper service create backend 8080 Successful ConnectionFinal TopologyTesting the connection to the podman site service from the OpenShift clusteroc exec deploy/skupper-router -c router -- curl http://backend:8080/claim/claim1.jsonNext StepsNow you can continue with the workshop until generating the sentiments of the emails.ConclusionThis workshop demonstrates how to use Skupper to connect local data services to cloud-based AI/ML environments. The workshop includes a Go application in a podman container that exposes internal data for Skupper connection. The AI/ML model training is performed in an OpenShift AI cluster on AWS using Openshift AI/ML services." }, { "title": "TemPy: An IoT Architecture with Raspberry Pi and Skupper", "url": "/posts/tempi-com-skupper-e-grafana/", "categories": "skupper, raspberry, grafana, opensource, english", "tags": "skupper, raspberry, grafana, opensource, english", "date": "2024-02-15 00:00:00 -0300", "snippet": "DescriptionThis project is a proof of concept for an IoT architecture using a Raspberry Pi and a temperature sensor that exposes the temperature data through a REST API. Along with the REST API, th...", "content": "DescriptionThis project is a proof of concept for an IoT architecture using a Raspberry Pi and a temperature sensor that exposes the temperature data through a REST API. Along with the REST API, there is a cloud integration with any cloud provider using Skupper that enables the data to be visualized in a Grafana dashboard. Clone the repository and follow the instructions to run the project. https://github.com/rafaelvzago/skupper-tempygit clone https://github.com/rafaelvzago/skupper-tempy.gitTable of Contents Hardware Raspberry Configuration Temperature Capture Skupper Role Connection to a cluster using skupper and storage data into prometheus Prometheus Grafana RepositoryArchitectureThe architecture of the project can be divided into the following parts:HardwareThis part involves the physical components used in the project, such as the Raspberry Pi and the temperature sensor. Raspberry Pi 3 Model B+ Raspberry Pi 3 Model B+ DS18B20 Temperature Sensor DS18B20 Temperature Sensor 4.7kΩ Resistor 4.7kΩ Resistor Breadboard Breadboard Jumper Wires Jumper WiresRaspberry ConfigurationThis part focuses on the setup and configuration of the Raspberry Pi, including installing the necessary software and libraries. Ubuntu 23.04 server for Raspberry Pi Ubuntu Installation GoLang 1.18+ GoLang Installation Skupper Main Skupper Installation Podman &gt; 4.3 Podman InstallationTemperature Capture Credits: Raspberry Pi DS18B20 Temperature Sensor TutorialIn this part, the temperature sensor is connected to the Raspberry Pi, and the code for capturing temperature readings is implemented.Configuration: Raspberry Pi GPIO Pins: Pin 1 (3.3V) is connected to the VDD pin of the DS18B20. Pin 7 (GPIO 4) is connected to the DQ pin of the DS18B20. Pin 9 (GND) is connected to the GND pin of the DS18B20. DS18B20: The VDD pin is powered by 3.3V from the Raspberry Pi. The DQ pin is connected to GPIO 4 with a pull-up resistor. The GND pin is grounded to the Raspberry Pi. Connections: A 4.7kΩ pull-up resistor (R1) is placed between the VDD and DQ lines. The VDD line from the DS18B20 is connected to a red wire representing 3.3V from the Raspberry Pi. The DQ line is connected to a white wire representing data and is connected to GPIO 4 on the Raspberry Pi. The GND line is connected to a black wire representing ground from the Raspberry Pi.Functionality: The DS18B20 temperature sensor reports temperature data through the 1-Wire interface, which requires only one data line (and ground) for communication with the Raspberry Pi. The pull-up resistor is necessary for the 1-Wire protocol used by the DS18B20 to function correctly.REST API: To expose the temperature data, a REST API is implemented using GoLang. The API is used to capture the temperature data and expose it to the cloud provider.go build tempy/tempy.go Find a way to run the tempy binary on the Raspberry Pi, for this example I will use a simple nohup command to run the tempy binary in the background.nohup ./tempy &amp; The REST API is exposed on port 5000/temperature, and the temperature data can be accessed using the following command:curl localhost:5000/temperatureSkupper RoleWe will use Skupper to establish communication between the Raspberry Pi and the cloud provider, and to expose the temperature data to the cloud. This part covers the setup and configuration of Skupper.Skupper is a layer 7 service interconnect that enables secure communication across Kubernetes clusters, including network and application layer protocols. Skupper is designed to connect services that are running on different infrastructure, and it is based on the idea of a service bus. Skupper In this example we will be using skupper gateway to expose the temperature data to the cloud, for this we will need to have a skupper site running on the cloud and a skupper gateway running on the Raspberry Pi. Skupper gateway is a component that allows non-kubernetes services to be exposed to the skupper network, in this case we will use the skupper gateway to expose the temperature data to the cloud.Skupper site: A namespace running skupper, for this example we will borrow the prometheus service to store the temperature data, so we will init skupper on the cluster with the following command: skupper init --site-name site1 --enable-console --enable-flow-collector Skuper gateway on the Raspberry Pi: To expose the temperature data to the cloud, we will use a skupper gateway to expose the temperature data to the cloud, for this we will use the following command: skupper gateway expose tempy localhost 5000 --type podmanConnection to a cluster using skupper and storage data into prometheusThe temperature data captured by the Raspberry Pi is stored in the cloud using the chosen cloud provider. This part explains how the data is stored and managed.For this example, we will deploy a prometheus service to store the temperature data, and a prometheus-adapter to scrape the temperature data from the REST API and store it in the prometheus service. In order to facilitate the prometheus role, we will configure the prometheus service discovery to scrape the temperature data from the prometheus-adapter or any other service labeled as app=metric. with this approach, we can easily add more temperature sensors to the architecture and the prometheus service will automatically scrape the temperature data from the new sensors.In order to achive this, the service will be labeled as app=metric, and the prometheus-adapter will add the temperature data to the service, so the prometheus service will scrape the temperature data from the prometheus-adapter.apiVersion: v1kind: Servicemetadata: name: tempy-prometheus-adapter-servicespec: type: ClusterIP selector: app: metricsPrometheus Adapter: Build the TemPy prometheus-adapter image: podman build -t quay.io/YOUR-USER/tempy-prometheus-adapter:0.1 -f prometheus-adapter/Dockerfile-TempyPrometheusAdapter . Push the image to the quay.io registry: podman push quay.io/YOUR-USER/tempy-prometheus-adapter:0.1 Deploy the prometheus-adapter: kubectl apply -f prometheus-adapter/TempyPrometheusAdapter-deployment.yaml Expose the prometheus-adapter: kubectl apply -f prometheus-adapter/TempyPrometheusAdapter-service.yaml Verify the prometheus-adapter is running: kubectl run -i --tty --rm curl-pod --image=curlimages/curl -- shcurl tempy-prometheus-adapter:9090/metrics...# TYPE temperature_celsius gaugetemperature_celsius 19.81# HELP temperature_fahrenheit Current temperature in Fahrenheit# TYPE temperature_fahrenheit gaugetemperature_fahrenheit 67.66 CHeck the prometheus-adapter sservice to check if the labels are being added to the service: kubectl get svc tempy-prometheus-adapter-service -o wideNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTORtempy-prometheus-adapter-service ClusterIP 10.43.154.250 &lt;none&gt; 9090/TCP 11h app=metrics PrometheusThe temperature data is stored in a prometheus service. This part covers the setup and configuration of the prometheus service. We need to persist the data, so we will use a PVC, in my case I will use the longhorn storage class, but you can use any storage class that you have available in your cluster.This is a part of the prometheus configuration file, it is configured to scrape the temperature data from any service labeled as app=metrics, so the prometheus service will scrape the temperature data from the prometheus-adapter. Note that this configuration will only look for services labeled as app=metrics in the skupper-pi namespace, so if you are using a different namespace, you will need to change the configuration file accordingly.... - job_name: 'metrics-targets' scrape_interval: 5s kubernetes_sd_configs: - role: service namespaces: names: ['skupper-pi'] relabel_configs: - source_labels: [__meta_kubernetes_service_label_app] regex: metrics action: keep... Create prometheus PVC: kubectl apply -f prometheus/prometheus-pvc.yaml Create prometheus deployment: kubectl apply -f prometheus/prometheus-deployment.yaml Configuring the prometheus service discovery to scrape the temperature data from any service labeled as app=metrics: kubectl apply -f prometheus/prometheus-cm.yaml Deploy the prometheus: kubectl apply -f prometheus/prometheus-deployment.yaml Create prometheus service: kubectl apply -f prometheus/prometheus-service.yaml Verify the prometheus is running, from this point on, the prometheus service should be scraping the temperature data from the prometheus-adapter or any other service labeled as app=metrics, let’s query all the services discovered by prometheus: kubectl run -i --tty --rm curl-pod --image=curlimages/curl -- sh -c 'curl -G --data-urlencode \"query=up\" http://prometheus:9090/api/v1/query' | jq .If you don't see a command prompt, try pressing enter.warning: couldn't attach to pod/curl-pod, falling back to streaming logs: Internal error occurred: error attaching to container: container is in CONTAINER_EXITED state{ \"status\": \"success\", \"data\": { \"resultType\": \"vector\", \"result\": [ { \"metric\": { \"__name__\": \"up\", \"instance\": \"localhost:9090\", \"job\": \"prometheus\" }, \"value\": [ 1708523706.121, \"1\" ] }, { \"metric\": { \"__name__\": \"up\", \"instance\": \"promock.skupper-pi.svc:80\", \"job\": \"metrics-targets\" }, \"value\": [ 1708523706.121, \"1\" ] }, { \"metric\": { \"__name__\": \"up\", \"instance\": \"tempy-prometheus-adapter-service.skupper-pi.svc:9090\", \"job\": \"metrics-targets\" }, \"value\": [ 1708523706.121, \"1\" ] } ] }}... GrafanaThe stored temperature data is visualized in a Grafana dashboard. This part covers the setup and configuration of the dashboard. To visualize the temperature data, we will use a Grafana dashboard. The dashboard is configured to scrape the temperature data from the prometheus service and visualize it in a graph. The grafana deployment is done using the following command: For the data persistence, we will use a PVC to store the grafana data, in my case I have longhorn installed on my cluster, so I will use it to store the grafana data, but you can use any other storage class that you have available on your cluster. Create grafana PVC: kubectl apply -f grafana/grafana-pvc.yaml Create grafana deployment: kubectl apply -f grafana/grafana-deployment.yaml Create grafana service: kubectl apply -f grafana/grafana-service.yaml Important: My cluster is configrued to use the ingress controller, so I have to create an ingress to expose the grafana service, if your cluster is not configured to use the ingress controller, you will neeed either to expose the grafana service using a nodeport or a loadbalancer. Create a data source connection in grafana that points to the prometheus service: http://skupper-prometheus:9090 Import the grafana dashboard: grafana/dashboard.json FINALY, you should be able to visualize the temperature data in the grafana dashboard.RepositoryThe complete code for the project can be found in the following GitHub repository: TemPy" }, { "title": "Carreira com Software Livre - O que é e como começar?", "url": "/posts/carreira-com-softeware-livre/", "categories": "carreira, opensource", "tags": "carreira, opensource", "date": "2023-12-07 00:00:00 -0300", "snippet": "Carreira com Software Livre - O que é e como começar?IntroduçãoSoftware Livre é um movimento que tem como objetivo promover a liberdade de uso, estudo, modificação e distribuição de software. O mov...", "content": "Carreira com Software Livre - O que é e como começar?IntroduçãoSoftware Livre é um movimento que tem como objetivo promover a liberdade de uso, estudo, modificação e distribuição de software. O movimento do Software Livre é baseado em quatro liberdades essenciais: A liberdade de executar o programa, para qualquer propósito (liberdade nº 0). A liberdade de estudar como o programa funciona e adaptá-lo para as suas necessidades (liberdade nº 1). O acesso ao código-fonte é um pré-requisito para esta liberdade. A liberdade de redistribuir cópias de modo que você possa ajudar ao seu próximo (liberdade nº 2). A liberdade de aperfeiçoar o programa, e liberar os seus aperfeiçoamentos, de modo que toda a comunidade se beneficie (liberdade nº 3). O acesso ao código-fonte é um pré-requisito para esta liberdade.Tipos de licenças para software livreExistem diversos tipos de licenças para software livre, sendo as mais populares a GPL, LGPL, MIT, Apache, BSD e a Mozilla. Cada uma dessas licenças possui suas próprias características e restrições, porém, todas elas garantem as quatro liberdades essenciais do movimento do Software Livre. GPL: A GPL é uma licença copyleft, o que significa que qualquer software que utilize uma biblioteca licenciada sob a GPL também deve ser licenciado sob a GPL. A GPL é uma licença muito popular entre os desenvolvedores de software livre, pois garante que o software permaneça livre e aberto para todos. LGPL: A LGPL é uma licença copyleft, o que significa que qualquer software que utilize uma biblioteca licenciada sob a LGPL também deve ser licenciado sob a LGPL. A LGPL é uma licença muito popular entre os desenvolvedores de software livre, pois garante que o software permaneça livre e aberto para todos. MIT: A MIT é uma licença permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a MIT pode ser licenciado sob qualquer outra licença. A MIT é uma licença muito popular entre os desenvolvedores de software livre, pois garante que o software permaneça livre e aberto para todos. Apache: A Apache é uma licença permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a Apache pode ser licenciado sob qualquer outra licença. A Apache é uma licença muito popular entre os desenvolvedores de software livre, pois garante que o software permaneça livre e aberto para todos. BSD: A BSD é uma licença permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a BSD pode ser licenciado sob qualquer outra licença. A BSD é uma licença muito popular entre os desenvolvedores de software livre, pois garante que o software permaneça livre e aberto para todos. Mozilla: A Mozilla é uma licença permissiva, o que significa que qualquer software que utilize uma biblioteca licenciada sob a Mozilla pode ser licenciado sob qualquer outra licença. A Mozilla é uma licença muito popular entre os desenvolvedores de software livre, pois garante que o software permaneça livre e aberto para todos.Como começar a contribuir com software livre?Existem diversas formas de contribuir com software livre, sendo as mais populares a contribuição de código, a contribuição de documentação e a contribuição de tradução. Cada uma dessas formas de contribuição possui suas próprias características e restrições, porém, todas elas garantem as quatro liberdades essenciais do movimento do Software Livre.A Importância do Software Livre na Indústria de TecnologiaO Software Livre é um movimento que tem como objetivo promover a liberdade de uso, estudo, modificação e distribuição de software. Hoje existem vários projetos que são pilares da indústria e são mantidos por comunidades de desenvolvedores que trabalham de forma voluntária. Esses projetos são essenciais para o desenvolvimento de novas tecnologias e para a evolução da indústria de tecnologia como um todo. Por isso, é importante que os desenvolvedores se envolvam com o movimento do Software Livre e contribuam com projetos que são essenciais para a indústria de tecnologia.Exemplos de software livre que são essenciais para a indústria de tecnologia: Linux: O Linux é um sistema operacional de código aberto que é utilizado por milhões de pessoas em todo o mundo. https://www.kernel.org/. Apache: O Apache é um servidor web de código aberto que é utilizado por milhões de pessoas em todo o mundo. https://httpd.apache.org/. MariaDB: O MariaDB é um sistema de gerenciamento de banco de dados de código aberto derivado do MySQL. https://mariadb.org/. Docker: O Docker é uma plataforma de código aberto que permite que os desenvolvedores empacotem seus aplicativos em contêineres. https://www.docker.com/. Kubernetes: O Kubernetes é uma plataforma de código aberto que permite que os desenvolvedores gerenciem seus aplicativos em contêineres. https://kubernetes.io/. Ansible: O Ansible é uma ferramenta de código aberto que permite que os desenvolvedores automatizem a implantação de seus aplicativos. https://www.ansible.com/. Jenkins: O Jenkins é uma ferramenta de código aberto que permite que os desenvolvedores automatizem a construção e o teste de seus aplicativos. https://www.jenkins.io/. Git: O Git é uma ferramenta de código aberto que permite que os desenvolvedores controlem as versões de seus aplicativos. https://git-scm.com/.Software livre em números: Atualmente existem mais de 1.000.000 de projetos de software livre no GitHub. O GitHub é a maior plataforma de desenvolvimento de software livre do mundo. GitHub O Linux é o sistema operacional mais utilizado no mundo. Linux Existem mais de projetos 1861 projetos na CNCf. Tanto projetos graduaos, incubados, sabdbvox e arquivados. CNCf Existem mais de 300 projetos na Apache. ApacheCNCF - Cloud Native Computing Foundation CNCF (Cloud Native Computing Foundation): Uma organização sem fins lucrativos. Objetivo: Promover o desenvolvimento de software livre para a nuvem. Características: Foco em Cloud Native: Concentra-se em tecnologias que empoderam sistemas escaláveis, resilientes e agéis baseados em contêineres. Comunidade Aberta e Colaborativa: Encoraja a colaboração e contribuição abertas entre membros da indústria, desenvolvedores e usuários finais. Padrões e Práticas de Governança: Estabelece padrões e melhores práticas para garantir interoperabilidade e eficiência. Apoio à Inovação e Sustentabilidade: Fomenta a inovação e sustentabilidade de projetos e comunidades de software livre. Eventos e Educação: Organiza eventos, webinars e programas educacionais para promover conhecimento e colaboração na comunidade cloud native. Projetos Chave: Kubernetes: Um sistema de orquestração de contêineres. Prometheus: Sistema de monitoramento e alerta. Envoy: Um proxy de serviço de código aberto. Links: Site Oficial Kubernetes Prometheus Envoy CNCF Projects Apache Software Foundation ASF (Apache Software Foundation): Uma organização sem fins lucrativos. Objetivo: O objetivo da ASF é fornecer software livre para o público em geral. Principais Projetos da Apache Software Foundation: Apache Hadoop: Framework para processamento distribuído de grandes conjuntos de dados. Apache Kafka: Plataforma de streaming distribuído para construção de pipelines de dados em tempo real. Apache Cassandra: Banco de dados distribuído para lidar com grandes quantidades de dados. Apache Spark: Motor de análise unificado para processamento de dados em larga escala. Apache Lucene: Biblioteca de software para recuperação de informações e pesquisa de texto completo. Apache Tomcat: Contêiner de servlets para aplicações web Java. Apache Maven: Ferramenta de automação de compilação para projetos Java. Apache HBase: Banco de dados não relacional distribuído para grandes conjuntos de dados. Apache Flink: Framework e mecanismo de processamento de fluxo distribuído. Apache Airflow: Plataforma para programar, coordenar e monitorar fluxos de trabalho. Links: Site Oficial Apache Hadoop Apache Kafka Apache Cassandra Apache Spark Apache Lucene Apache Tomcat Apache Maven Apache HBase Apache Flink Apache Airflow Linux FoundationA Linux Foundation é conhecida por seu apoio a vários projetos importantes de código aberto, incluindo o Linux Kernel, Kubernetes, Hyperledger e Node.js. Eles se concentram em fornecer um lar neutro e apoio para a colaboração em tecnologias de código aberto, priorizando inovação, inclusão e desenvolvimento sustentável.Para obter informações detalhadas e uma lista completa dos projetos, recomendo visitar diretamente o site da Linux Foundation: Linux Foundation Projects.Principais Projetos da Linux Foundation: CNCF: Cloud Native Computing Foundation. LF AI: Linux Foundation Artificial Intelligence. LF Edge: Linux Foundation Edge. LF Energy: Linux Foundation Energy. LF Public Health: Linux Foundation Public Health. OpenJS Foundation: OpenJS Foundation. RISC-V: RISC-V. Links: Site Oficial Linux Foundation Projects ResumoEsse artigo discute a carreira em Software Livre, enfatizando a importância das quatro liberdades essenciais do movimento: executar, estudar, redistribuir e aperfeiçoar programas. Ele explora diferentes tipos de licenças, como GPL, LGPL, MIT, Apache, BSD e Mozilla, destacando suas características únicas. O texto sugere formas de contribuir com software livre, incluindo código, documentação e tradução. Destaca a relevância do Software Livre na indústria de tecnologia, citando exemplos como Linux, Apache e Docker. Além disso, menciona projetos e iniciativas de organizações como CNCF, Apache Software Foundation e Linux Foundation, fornecendo links úteis e informações sobre seus projetos e objetivos." }, { "title": "Quem sou eu?", "url": "/posts/quem-sou-eu/", "categories": "sobre, off-topic", "tags": "zago, rafael", "date": "2023-12-04 00:00:00 -0300", "snippet": "ApresentaçãoQué pasa?Olá! Não me leve muito a sério, ok? Eu criei esse espaço para compartilhar um pouco do conhecimento que eu tenho e que 90% dele, eu ganhei na internet. Então já passou da hora ...", "content": "ApresentaçãoQué pasa?Olá! Não me leve muito a sério, ok? Eu criei esse espaço para compartilhar um pouco do conhecimento que eu tenho e que 90% dele, eu ganhei na internet. Então já passou da hora de devolver um pouco para o mundo.Hoje sou senior software automation engineer na Red Hat, mas já passei por algumas empresas (pequenas e grandes) fazendo de tudo um pouco: DevOps de coração e SysAdmin de vocação. Criando métodos de aprendizagem e estruturando treinamentos. Trabalhei, por muitos anos, com suporte de aplicações de vários tamanhos e complexidade. Sou instrutor da Caelum/Alura. Sou padrinho do carinha mais dahora da terra! Sem clubismo…ComunidadesSou devops de coração e também membro da organização do DevOpsDays SP Organização do DevOpsDays 2020Abaixo estão as poucas contribuições que já fiz:Podcasts Hipsters Ponto Tech #239 DNE 224 - Trabalhar para GringaTalks/Palestras Uma estratégia upstream e downstream para entrega contínua - Mini DebConf Brasília!, 2023. Skupper, a cloud híbrida com 3 comandos - DevOpsDays Fortaleza, 2022. Take out the rust, transformando time com responsabilidade - DevOpsDays São Paulo, 2019. Desenvolvendo Aplicações na Nuvem: Uma Abordagem Prática - LinuxDay Limeira, 2014 Palestra Linux 101 - Unisal Campinas, 2018 IHC and Security Talk - Unisal Campinas 2018Vídeos O que é Openshift? - Alura" }, { "title": "CI/CD Upstream vs Downstream", "url": "/posts/ci-cd-downstream-upstream/", "categories": "pipeline", "tags": "pipeline, ci, cd", "date": "2023-06-02 00:00:00 -0300", "snippet": "Integrando Skupper com Skupper: Uma abordagem upstream e downstreamQuando se trata de desenvolvimento de software, integrar projetos upstream e downstream pode ser um desafio. Neste artigo, vamos e...", "content": "Integrando Skupper com Skupper: Uma abordagem upstream e downstreamQuando se trata de desenvolvimento de software, integrar projetos upstream e downstream pode ser um desafio. Neste artigo, vamos explorar uma abordagem eficaz para integrar o Skupper e o Skupper, utilizando ferramentas populares para cada lado do desenvolvimento.IntroduçãoO Skupper é um projeto de software livre que fornece uma solução de rede de serviço para Kubernetes. O Skupper é desenvolvido pela Red Hat e está disponível sob a licença Apache 2.0. Essa é a versão upstream do Skupper, o que significa que é a versão que está sendo desenvolvida ativamente pela Red Hat.Para os usuários que desejam implantar o Skupper em um ambiente de produção, a Red Hat oferece o Skupper, uma versão comercial do Skupper que é fornecida pela Red Hat sob o nome de Red Hat AMQ Interconnect. Essa é a versão downstream do Skupper, o que significa que é a versão portada para o Red Hat Enterprise Linux e como Opera com o Red Hat OpenShift. Apesar de serem projetos diferentes, o Skupper e o Skupper compartilham uma base de código comum e, portanto, é importante que as alterações feitas no Skupper sejam integradas ao RHSI (Red HaT Application Interconnect). Para isso, é necessário estabelecer um fluxo de trabalho eficiente que permita a integração contínua entre o Skupper e o RHSI.Definindo o ambiente e as ferramentasAntes de começarmos, vamos configurar nosso ambiente de desenvolvimento. Para o lado downstream, faremos uso das seguintes ferramentas: Jira: uma ferramenta de gerenciamento de projetos que nos ajudará a rastrear e organizar as tarefas relacionadas ao desenvolvimento downstream. Confluence: uma plataforma de colaboração que usaremos para documentar informações importantes sobre o projeto. Git: um sistema de controle de versão que nos permitirá gerenciar nosso código fonte e colaborar com outros desenvolvedores. Quay.io: um registro de contêineres que nos ajudará a armazenar e distribuir nossas imagens de contêineres. Jenkins: uma ferramenta de automação de integração contínua que nos permitirá construir, testar e implantar nosso software de forma automatizada.Por outro lado, para o desenvolvimento upstream, faremos uso das seguintes ferramentas: GitHub Issues: um recurso do GitHub que nos ajudará a rastrear e gerenciar problemas e solicitações de recursos relacionados ao desenvolvimento upstream. CircleCI: uma plataforma de integração contínua que nos permitirá construir, testar e validar nosso código de forma automatizada.Fluxo de trabalhoAgora que nosso ambiente está configurado, vamos explorar um fluxo de trabalho básico para a integração contínua entre o Skupper e o Skupper. Desenvolvimento Upstream Utilize o GitHub Issues para rastrear e gerenciar problemas e solicitações de recursos. Faça uso do CircleCI para construir e testar o código do Skupper de forma automatizada. Integração Upstream-Downstream Após o desenvolvimento upstream estar pronto, abra uma solicitação de pull no repositório do Skupper. Uma vez que a solicitação de pull seja aprovada, uma nova versão do Skupper é criada e publicada no Quay.io. Desenvolvimento Downstream Utilize o Jira para criar tarefas relacionadas às funcionalidades downstream. Utilize o Git para clonar o código fonte do Skupper e iniciar o desenvolvimento downstream. Use o Jenkins para automatizar a construção, teste e implantação do Skupper. Integração Downstream-Upstream Quando necessário, faça alterações no código do Skupper e abra uma solicitação de pull no repositório. Após a aprovação da solicitação de pull, uma nova versão do Skupper é publicada. Exemplo práticoPara ilustrar o fluxo de trabalho descrito acima, vamos considerar um cenário em que estamos adicionando suporte para um novo protocolo de comunicação no Skupper e integrando essa funcionalidade ao Skupper. Desenvolvimento Upstream Abra um problema no GitHub Issues para rastrear a solicitação de suporte ao novo protocolo. Escreva o código necessário para adicionar o suporte no Skupper. Utilize o CircleCI para construir e testar o código automaticamente. Integração Upstream-Downstream Abra uma solicitação de pull no repositório do Skupper para incorporar as alterações. Após a aprovação da solicitação de pull, uma nova versão do Skupper é publicada no Quay.io. Desenvolvimento Downstream No Jira, crie uma tarefa para adicionar suporte ao novo protocolo no Skupper. Clone o repositório do Skupper usando o Git. Adicione o suporte ao novo protocolo no código do Skupper. Use o Jenkins para automatizar a construção, teste e implantação do Skupper com as novas alterações. Integração Downstream-Upstream Se necessário, faça alterações adicionais no código do Skupper e abra uma solicitação de pull. Após a aprovação da solicitação de pull, uma nova versão do Skupper é publicada. ConclusãoA integração contínua entre o Skupper e o Skupper é essencial para garantir que as atualizações do software cheguem aos usuários de forma eficiente, mantendo a viabilidade comercial. Utilizando ferramentas como Jira, Confluence, Git, Quay.io, Jenkins, GitHub Issues e CircleCI, é possível estabelecer um fluxo de trabalho robusto e automatizado que agiliza o desenvolvimento upstream e downstream, permitindo a entrega contínua de software de alta qualidade.Esperamos que este artigo tenha fornecido insights valiosos sobre a integração upstream e downstream e tenha demonstrado como essas ferramentas podem ser usadas em conjunto para um processo de desenvolvimento mais eficiente.Obrigado por ler e continue explorando as possibilidades de integração contínua entre projetos de software livre e produtos comerciais!" }, { "title": "Criando uma rede de aplicativos multicloud com Skupper", "url": "/posts/multicloud-com-skupper/", "categories": "cloud, k8s, skupper", "tags": "k8s, skupper, could, RedHat", "date": "2022-10-01 00:00:00 -0300", "snippet": "Referências e tecnologias utilizadas: https://skupper.io https://minikube.sigs.k8s.io Repositório com os Códigos Qpid-dispatch ActiveMQ Kubectl Kubernetes MTLS Open-source Skupper-router ...", "content": "Referências e tecnologias utilizadas: https://skupper.io https://minikube.sigs.k8s.io Repositório com os Códigos Qpid-dispatch ActiveMQ Kubectl Kubernetes MTLS Open-source Skupper-router SkupperFerramentas Um computador com o minikube [2] instalado; Um terminal para executar os comandos; kubectl &gt; 1.15 [6] ou mais nova.Descrição da soluçãoO Skupper [1] é uma ferramenta que permite conectar dois ou mais ambientes de cloud de uma maneira não intrusiva e segura. Tais ambientes podem ser de diferentes provedores de serviço em nuvem como: AWS, GCP, AZURE entre outras, e, inclusive, clusters kubernetes nativos.tl;drPara quem está começando com cloud: O Skupper é uma ferramenta que permite conectar diferentes ambientes de computação em nuvem de maneira segura e sem complicações. Imagine que você tem duas salas diferentes, cada uma com seu próprio conjunto de ferramentas. Skupper é como uma porta segura que permite que essas salas “conversem” entre si, compartilhando ferramentas conforme necessário. Isso é útil quando você tem diferentes partes de um aplicativo rodando em diferentes lugares, mas elas precisam trabalhar juntas como se estivessem no mesmo lugar.Para quem tem algum conheciemento de cloud: O Skupper é uma solução de rede de serviço para Kubernetes que permite a comunicação segura e fácil entre clusters. Ele cria uma camada de rede virtual que conecta pods em diferentes clusters como se estivessem na mesma rede local. Isso é feito sem a necessidade de privilégios de administrador do cluster e sem a necessidade de expor serviços à Internet pública. Além disso, o Skupper não é intrusivo com sua aplicação, pois não cria side-cars ou outros containers dentro dos Pods. Ele é open-source e oferece criptografia de ponta a ponta usando certificados digitais.Para quem gosta de escovar bits: O Skupper pode ser dividido em duas partes: o skupper-router e o control-plane chamado skupper-service-controller. O skupper-router é um roteador de rede de serviço baseado no Qpid-dispatch [4] e no ActiveMQ [5]. O skupper-service-controller é um controlador Kubernetes que gerencia o skupper-router e fornece uma API para configurar e gerenciar a rede de serviço. Existem outros containers que são usados para configurar e gerenciar o skupper-router, mas eles são apenas auxiliares e não são necessários para o funcionamento do Skupper. Mas isso vai ficar para outro post.SoluçãoEsse exemplo consiste em dois serviços:1. Frontend Um serviço de backend que expõe um endpoint /api/hello. Que tem como resposta Oi, &lt;seu-nome&gt;. Eu sou &lt;meu-nome&gt; (&lt;nome-pod&gt;). O deploy será feito no namespace confi_oeste;2. Backend Um serviço de frontend que expõe um endpoint /api/hello que faz uma chamada para o serviço de backend e retorna a resposta, mas nesse caso o serviço esta rodando em outro namespace chama config_leste, este por sua vez pode estar em outro cluster ou namespace.Por que usar o Skupper? Com o Skupper, você pode colocar o back-end em um cluster e o front-end em outro e manter a conectividade entre os dois serviços sem expor o back-end à Internet pública.Detalhes: Não é necessário ter privilégios de administrador do cluster, já que a solução é no nível do namespace; Não é intrusivo com a sua aplicação, pois não cria side-cars ou outros containers dentro dos Pods; É open-source; Você pode conectar, em seu cluster, serviços externos como: Bancos de dados, aplicações legadas e ainda de alta criticidade; Criptografado de ponta a ponta usando certificados digitais; Baixa curva de aprenddizagem. MTLS [9] por padrão. MTLS é um protocolo de segurança que garante que a comunicação entre dois pontos seja feita de maneira segura e criptografada. Utilização de certificados próprios caso necessário, ou seja, você pode usar os certificados da sua empresa ou gerar novos certificados para o Skupper ( que é o padrão e são criados automaticamente).Agora vamos preparar nosso ambiente de teste, que consiste no seguinte: Um serviço de backend que está rodando em um namespace que vai prover a lógica para outro serviço de frontend que obviamente está e outro namespace*. Nesse caso, cada serviço está rodando em namespaces diferentes, mas o mesmo exemplo pode (e deve) ser testado com provedores diferentes.1. Nesse exemplo vamos utilizar dois namespaces chamados:1.1. config_oeste onde ficará o frontend. Lembre-se de abrir uma aba do seu terminal para cada namespaceexport KUBECONFIG=~/.kube/config-oeste1.2. config_leste onde ficará o backend agora, no outro terminal:export KUBECONFIG=~/.kube/config-lesteObs: Você pode usar o nome que quiser para os namespaces, mas lembre-se de usar o mesmo nome no arquivo de configuração do skupper.2. Configurando cada namespace:2.1.config_oeste:kubectl create namespace oestekubectl config set-context --current --namespace oeste2.2.config_leste:kubectl create namespace lestekubectl config set-context --current --namespace leste3. Instalando o Skupper:Você possui algumas maneiras de instalar o skupper, como por exemplo: Compilar a partir do repositório Fazer o download do executável direto do repositório [1] do projeto Usar o script de instalação disponibilizado pelo site skupper.io e vamos utilizar esse método, por ser mais fácil de fazer e você não precisará se preocupar com dependências.4. Instaçação do CLI do Skupper: curl https://skupper.io/install.sh | sh5. Iniciando o skupper nos dois namespaces:5.1.config_oeste:skupper init5.2.config_leste:skupper init6. Conectando os namespaces:A criação de um link requer o uso de dois comandos skupper em conjunto: skupper token create e skupper link create.O comando skupper token create gera um token secreto que significa permissão para criar um link. O token também carrega os detalhes do link. Em seguida, em um namespace remoto, o comando skupper link create usa o token para criar um link para o namespace que o gerou. Nota: O token de link é realmente um segredo. Qualquer pessoa que tenha o token pode vincular ao seu namespace. Certifique-se de que apenas aqueles em quem você confia tenham acesso a ele. Porém sua utilização pode ser controlada por número de usos e tempo de vida. Veja a documentação do skupper [1] para mais detalhes.6.1. Criando o token no namespace config_oeste:skupper token create ~/secret.tokenToken written to ~/secret.token6.2. Fazendo o link no namespace config_leste ao namespace config_oeste com o token gerado:skupper link create ~/secret.token7. Fazendo o deploy do frontend e do backend:7.1. Applicando o YAML para fazer o deploy do frontend no namespace config_oeste:kubectl create deployment frontend --image quay.io/skupper/hello-world-frontenddeployment.apps/frontend created7.2. Applicando o YAML para fazer o deploy do backend no namespace config_leste:kubectl create deployment backend --image quay.io/skupper/hello-world-backend --replicas 3deployment.apps/backend created8. Expondo os serviços de backend:Agora que os serviços estão rodando, vamos expor os serviços para que possamos acessá-los. Nesse caso, vamos expor o serviço de backend para que o frontend possa acessá-lo, independente de onde ele esteja rodando.8.1. Expondo o serviço de backend no namespace config_leste:skupper expose deployment/backend --port 8080deployment backend exposed as backend9. Expondo os serviços de frontend:Agora que os serviços estão rodando, vamos expor os serviços para que possamos acessá-los. Nesse caso, vamos expor o serviço de frontend para que possamos acessá-lo, independente de onde ele esteja rodando.9.1. Expondo o serviço de frontend no namespace config_oeste:kubectl expose deployment frontend --port 8080 --type LoadBalancerservice/frontend exposed10. Testando a aplicação:Agora que os serviços estão rodando, vamos testar a aplicação. Nesse caso, vamos acessar o serviço de frontend e verificar se ele consegue acessar o serviço de backend. Para isso, vamos fazer uma chamada para o endpoint /api/health do serviço de frontend e verificar se ele consegue acessar o serviço de backend.10.1.config_oeste:kubectl get service/frontendNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEfrontend LoadBalancer 10.103.232.28 &lt;external-ip&gt; 8080:30407/TCP 15scurl http://&lt;external-ip&gt;:8080/api/healthOK11. Apagando tudo:Pronto! Agora que você já testou o Skupper, vamos apagar tudo para que você possa testar novamente ou fazer outras experiências.11.1. Apagando tudo no namespace config_oeste:skupper deletekubectl delete service/frontendkubectl delete deployment/frontend11.2. Apagando tudo no namespace config_leste:skupper deletekubectl delete deployment/backendResumoEste exemplo localiza os serviços de front-end e back-end em namespaces diferentes, em clusters diferentes. Normalmente isso significa que eles não tem como se comunicar, a menos que sejam expostos à Internet pública.A introdução do Skupper em cada namespace nos permite criar uma rede de aplicativos virtuais que pode conectar serviços em diferentes clusters. Qualquer serviço exposto na rede de aplicativos é representado como um serviço local em todos os namespaces vinculados.O serviço de back-end está localizado no leste, mas o serviço de front-end no oeste pode “vê-lo” como se fosse local. Quando o front-end envia uma solicitação ao back-end, o Skupper encaminha a solicitação para o namespace em que o back-end está sendo executado e roteia a resposta de volta ao front-end.Nâo foi necessário expor o serviço de back-end à Internet pública. O Skupper criou uma rede de aplicativos que conecta os serviços em diferentes clusters. O serviço de back-end está localizado no leste, mas o serviço de front-end no oeste pode “vê-lo” como se fosse local. Quando o front-end envia uma solicitação ao back-end, o Skupper encaminha a solicitação para o namespace em que o back-end está sendo executado e roteia a resposta de volta ao front-end.Nenhuma VPN ou conexão Layer 3 foi necessária. O Skupper cria uma rede de aplicativos que conecta os serviços em diferentes clusters. O serviço de back-end está localizado no leste, mas o serviço de front-end no oeste pode “vê-lo” como se fosse local. Quando o front-end envia uma solicitação ao back-end, o Skupper encaminha a solicitação para o namespace em que o back-end está sendo executado e roteia a resposta de volta ao front-end." } ]
